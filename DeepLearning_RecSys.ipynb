{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/jiangzl2016/yelp-rating-prediction/blob/master/DeepLearning_RecSys.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7a0PQGQjwC1B"
   },
   "source": [
    "## Deep Learning Models\n",
    "#### DeepFM\n",
    "\n",
    "![DeepFM Model Architecture](https://d2l.ai/_images/rec-deepfm.svg)\n",
    "\n",
    "It is a model which integrates the feature representation learning of a neural network with factorization machines.\n",
    "\n",
    "Adding nonlinear transformation layers to factorization machines gives it the capability to model both low-order feature combinations and high-order feature combinations. Moreover, non-linear inherent structures from inputs can also be captured with neural networks.\n",
    "\n",
    "#### Wide and Deep Learning\n",
    "\n",
    "![Wide and Deep Model](https://2.bp.blogspot.com/-wkrmRibw_GM/V3Mg3O3Q0-I/AAAAAAAABG0/Jm3Nl4-VcYIJ44dA5nSz6vpTyCKF2KWQgCKgB/s640/image03.png)\n",
    "\n",
    "The Wide part of the model tries to capture the co-occurrence of a query-item feature pair correlates with the target label. The Deep model generalizes the query-item interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "NW95ttnU-3ed",
    "outputId": "c1101d84-e388-4386-91c7-b78bf7061f9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')#, force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 700
    },
    "colab_type": "code",
    "id": "OSPql3L9d3qx",
    "outputId": "ebe6f8eb-5d36-4fd6-818b-a349394bf8d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: deepctr[gpu] in /usr/local/lib/python3.6/dist-packages (0.7.0)\n",
      "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from deepctr[gpu]) (2.8.0)\n",
      "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from deepctr[gpu]) (2.21.0)\n",
      "Requirement already satisfied, skipping upgrade: tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\" in /usr/local/lib/python3.6/dist-packages (from deepctr[gpu]) (2.0.0)\n",
      "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from h5py->deepctr[gpu]) (1.12.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from h5py->deepctr[gpu]) (1.17.4)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->deepctr[gpu]) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->deepctr[gpu]) (1.24.3)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->deepctr[gpu]) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->deepctr[gpu]) (2019.11.28)\n",
      "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (0.8.1)\n",
      "Requirement already satisfied, skipping upgrade: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (0.2.2)\n",
      "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (0.8.1)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (3.10.0)\n",
      "Requirement already satisfied, skipping upgrade: tensorboard<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (2.0.2)\n",
      "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (1.11.2)\n",
      "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (0.33.6)\n",
      "Requirement already satisfied, skipping upgrade: tensorflow-estimator<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (2.0.1)\n",
      "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (0.1.8)\n",
      "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (1.0.8)\n",
      "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (3.1.0)\n",
      "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (42.0.2)\n",
      "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (0.16.0)\n",
      "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (3.1.1)\n",
      "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (0.4.1)\n",
      "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (1.10.0)\n",
      "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (4.0.0)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (0.2.7)\n",
      "Requirement already satisfied, skipping upgrade: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (4.0)\n",
      "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (3.1.0)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (0.4.8)\n",
      "Requirement already up-to-date: scikit-learn in /usr/local/lib/python3.6/dist-packages (0.22)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.3.3)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (0.14.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.17.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U deepctr[gpu]\n",
    "!pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j4lubeylyJLF"
   },
   "source": [
    "The GPU being used for the deep learning models is a Tesla P100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "RIgViUOV9WQl",
    "outputId": "bd1e1569-1c61-4881-ce3b-7ea280d72281"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Dec 20 14:14:03 2019       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.44       Driver Version: 418.67       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   33C    P0    25W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C1j6rJwyyOzN"
   },
   "source": [
    "#### Importing packages and reading the dataset ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pICvjmggcnoI"
   },
   "outputs": [],
   "source": [
    "## data handling\n",
    "# setup libraries and env\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sn\n",
    "sn.set()\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from deepctr.models import DeepFM, CCPM, FNN, PNN, WDL, MLR, NFM, AFM, DCN, DIN, DIEN, DSIN, xDeepFM, AutoInt, NFFM, FGCNN, FiBiNET\n",
    "from deepctr.inputs import SparseFeat,get_feature_names\n",
    "\n",
    "import itertools as it\n",
    "\n",
    "training =  pd.read_csv('/content/drive/My Drive/final_project_datasets/ratings_sample_train_20.csv', index_col = 0)\n",
    "validation = pd.read_csv('/content/drive/My Drive/final_project_datasets/ratings_sample_validation_20.csv', index_col = 0)\n",
    "test = pd.read_csv('/content/drive/My Drive/final_project_datasets/ratings_sample_test_20.csv', index_col = 0)\n",
    "\n",
    "businesses = pd.read_csv('/content/drive/My Drive/final_project_datasets/businesses.csv')\n",
    "users = pd.read_csv('/content/drive/My Drive/final_project_datasets/active_users.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "slD0osLPVmN1"
   },
   "outputs": [],
   "source": [
    "# training.dropna(inplace = True)\n",
    "# validation.dropna(inplace = True)\n",
    "# test.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jajtKWzSySTR"
   },
   "source": [
    "##### Include cities as a feature in the deep learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8fFyOfYm_Stb"
   },
   "outputs": [],
   "source": [
    "businesses['business_city_state'] = businesses['business_city'] + businesses['business_state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "W90pYEhiVCxo",
    "outputId": "7e04e41c-8738-4f5d-dce0-f9bed277781b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(803897, 5) (57229, 5) (57223, 5)\n"
     ]
    }
   ],
   "source": [
    "print(training.shape, validation.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "58mUcfi7BFyY"
   },
   "outputs": [],
   "source": [
    "training = training.merge(right = businesses[['business_id', 'business_city_state']], how = 'left', on = 'business_id')\n",
    "validation = validation.merge(right = businesses[['business_id', 'business_city_state']], how = 'left', on = 'business_id')\n",
    "test = test.merge(right = businesses[['business_id', 'business_city_state']], how = 'left', on = 'business_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NJmXuQftBuz9"
   },
   "outputs": [],
   "source": [
    "column_sequence = ['user_id', 'business_id', 'business_city_state', 'text', 'rating', 'date']\n",
    "training = training[column_sequence]\n",
    "validation = validation[column_sequence]\n",
    "test = test[column_sequence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "Yk_DkOyO8A3V",
    "outputId": "585e9993-05e4-437c-a8d9-e36777c28f66"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>business_city_state</th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n6-Gk65cPZL6Uz8qRm3NYw</td>\n",
       "      <td>hk5wpV-_pi5jmDDVPeG8DA</td>\n",
       "      <td>MesaAZ</td>\n",
       "      <td>I highly recommend Arizona Pet Mortuary, David...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2018-09-14 18:50:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d6xvYpyzcfbF_AZ8vMB7QA</td>\n",
       "      <td>qdCwzhJ5Yo_Sdm_bYDIfOQ</td>\n",
       "      <td>AhwatukeeAZ</td>\n",
       "      <td>I found Kathy's from yelp.  I love to support ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2011-09-11 06:09:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sG_h0dIzTKWa3Q6fmb4u-g</td>\n",
       "      <td>XS1Zx6GzjtKPKmhDuVw5Jg</td>\n",
       "      <td>ClevelandOH</td>\n",
       "      <td>I had the Saison infused with grapefruit which...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2017-06-19 22:55:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FIk4lQQu1eTe2EpzQ4xhBA</td>\n",
       "      <td>jLxeBgWhLRbII2ACkgH1Sg</td>\n",
       "      <td>Las VegasNV</td>\n",
       "      <td>First time for me to come inside at least! Hav...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2018-09-30 18:00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TpyOT5E16YASd7EWjLQlrw</td>\n",
       "      <td>U_yacPCk8HgE1ywATmQUrg</td>\n",
       "      <td>EtobicokeON</td>\n",
       "      <td>Ordered for lunch with a few colleagues throug...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2018-10-13 00:10:59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  user_id             business_id  ... rating                 date\n",
       "0  n6-Gk65cPZL6Uz8qRm3NYw  hk5wpV-_pi5jmDDVPeG8DA  ...    5.0  2018-09-14 18:50:19\n",
       "1  d6xvYpyzcfbF_AZ8vMB7QA  qdCwzhJ5Yo_Sdm_bYDIfOQ  ...    2.0  2011-09-11 06:09:33\n",
       "2  sG_h0dIzTKWa3Q6fmb4u-g  XS1Zx6GzjtKPKmhDuVw5Jg  ...    3.0  2017-06-19 22:55:06\n",
       "3  FIk4lQQu1eTe2EpzQ4xhBA  jLxeBgWhLRbII2ACkgH1Sg  ...    4.0  2018-09-30 18:00:41\n",
       "4  TpyOT5E16YASd7EWjLQlrw  U_yacPCk8HgE1ywATmQUrg  ...    5.0  2018-10-13 00:10:59\n",
       "\n",
       "[5 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert object to datetime\n",
    "# training.date = pd.to_datetime(training.date)\n",
    "# validation.date = pd.to_datetime(validation.date)\n",
    "# test.date = pd.to_datetime(test.date)\n",
    "\n",
    "# find hour from datetime\n",
    "# training['hour'] = training.date.dt.hour\n",
    "# validation['hour'] = validation.date.dt.hour\n",
    "# test['hour'] = test.date.dt.hour\n",
    "\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_IXUwUgTyb4R"
   },
   "source": [
    "##### Data Quality check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "v0viHy3k8EFt",
    "outputId": "a046d41a-1963-48b9-8786-9421320bf645"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# quality check\n",
    "print(len(set(test.user_id) - set(training.user_id)))\n",
    "print(len(set(validation.user_id) - set(training.user_id)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BetkE-yUgym-"
   },
   "outputs": [],
   "source": [
    "test = test.loc[test.business_id.isin(training.business_id)]\n",
    "validation = validation.loc[validation.business_id.isin(training.business_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1vkFO-bV4rJb"
   },
   "outputs": [],
   "source": [
    "# map each user_id, business_id to an index\n",
    "# user_mapping = {}\n",
    "# for n,i in enumerate(training.user_id.unique()):\n",
    "#   user_mapping[i] = n\n",
    "\n",
    "# business_mapping = {}\n",
    "# for n,i in enumerate(training.business_id.unique()):\n",
    "#   business_mapping[i] = n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vwqf8DZ66Z8r"
   },
   "outputs": [],
   "source": [
    "# for training\n",
    "# training['user_id'] = training['user_id'].map(user_mapping)\n",
    "# training['business_id'] = training['business_id'].map(business_mapping)\n",
    "# for validation\n",
    "# validation['user_id'] = validation['user_id'].map(user_mapping)\n",
    "# validation['business_id'] = validation['business_id'].map(business_mapping)\n",
    "# for test\n",
    "# test['user_id'] = test['user_id'].map(user_mapping)\n",
    "# test['business_id'] = test['business_id'].map(business_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "ZCTJonRY6j7s",
    "outputId": "89db0376-12ac-4354-ae9e-6973e9ebb804"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>business_city_state</th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d6xvYpyzcfbF_AZ8vMB7QA</td>\n",
       "      <td>qdCwzhJ5Yo_Sdm_bYDIfOQ</td>\n",
       "      <td>AhwatukeeAZ</td>\n",
       "      <td>I found Kathy's from yelp.  I love to support ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2011-09-11 06:09:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sG_h0dIzTKWa3Q6fmb4u-g</td>\n",
       "      <td>XS1Zx6GzjtKPKmhDuVw5Jg</td>\n",
       "      <td>ClevelandOH</td>\n",
       "      <td>I had the Saison infused with grapefruit which...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2017-06-19 22:55:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FIk4lQQu1eTe2EpzQ4xhBA</td>\n",
       "      <td>jLxeBgWhLRbII2ACkgH1Sg</td>\n",
       "      <td>Las VegasNV</td>\n",
       "      <td>First time for me to come inside at least! Hav...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2018-09-30 18:00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TpyOT5E16YASd7EWjLQlrw</td>\n",
       "      <td>U_yacPCk8HgE1ywATmQUrg</td>\n",
       "      <td>EtobicokeON</td>\n",
       "      <td>Ordered for lunch with a few colleagues throug...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2018-10-13 00:10:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>_N7Ndn29bpll_961oPeEfw</td>\n",
       "      <td>O-b5osM0NO4f31dp6_DatQ</td>\n",
       "      <td>TorontoON</td>\n",
       "      <td>I can only comment on their macarons, which I'...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2014-08-01 01:55:23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  user_id             business_id  ... rating                 date\n",
       "1  d6xvYpyzcfbF_AZ8vMB7QA  qdCwzhJ5Yo_Sdm_bYDIfOQ  ...    2.0  2011-09-11 06:09:33\n",
       "2  sG_h0dIzTKWa3Q6fmb4u-g  XS1Zx6GzjtKPKmhDuVw5Jg  ...    3.0  2017-06-19 22:55:06\n",
       "3  FIk4lQQu1eTe2EpzQ4xhBA  jLxeBgWhLRbII2ACkgH1Sg  ...    4.0  2018-09-30 18:00:41\n",
       "4  TpyOT5E16YASd7EWjLQlrw  U_yacPCk8HgE1ywATmQUrg  ...    5.0  2018-10-13 00:10:59\n",
       "5  _N7Ndn29bpll_961oPeEfw  O-b5osM0NO4f31dp6_DatQ  ...    3.0  2014-08-01 01:55:23\n",
       "\n",
       "[5 rows x 6 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vAW_-RGWlge5"
   },
   "outputs": [],
   "source": [
    "# validation = validation.loc[~validation.business_id.isin(['WpC53SqwoCY5AuYIFr_1eA'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W9rQWXdEyhPj"
   },
   "source": [
    "#### Preparation for input into deep learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UPZ-2X6hj_e6"
   },
   "outputs": [],
   "source": [
    "# 1.Label Encoding for sparse features,and do simple Transformation for dense features\n",
    "training = training.loc[training.business_city_state.apply(type) != float]\n",
    "training_deep = training.copy()\n",
    "validation_deep = validation.copy()\n",
    "test_deep = test.copy()\n",
    "\n",
    "sparse_features = [\"user_id\", \"business_id\", \"business_city_state\"]#, \"hour\"]\n",
    "target = ['rating']\n",
    "for feat in sparse_features:\n",
    "  lbe = LabelEncoder()\n",
    "  training_deep[feat] = lbe.fit_transform(training_deep[feat])\n",
    "  validation_deep[feat] = lbe.transform(validation_deep[feat])\n",
    "  test_deep[feat] = lbe.transform(test_deep[feat])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1EneZP-byvEy"
   },
   "source": [
    "##### Grid Search - Hyperparameter Tuning\n",
    "\n",
    "We have tuned 3 parameters for both the models,\n",
    "1. Embedding dimension - 8, 16, 32\n",
    "2. Hidden Units - (128, 128), (256, 256), (256, 128)\n",
    "3. Dropout - 0.1, 0.3, 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B61Aov2Hs3r6"
   },
   "source": [
    "#### Grid Search for DeepFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "colab_type": "code",
    "id": "c73rkdvjI70c",
    "outputId": "66a24171-9da1-4763-f396-eefebb3e7b71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 803897 samples, validate on 53225 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "803897/803897 - 70s - loss: 1.7237 - mse: 1.7062 - val_loss: 1.7827 - val_mse: 1.7481\n",
      "validation MSE 1.7481\n",
      "Train on 803897 samples, validate on 53225 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'embedding_dim' : [8, 16, 32],\n",
    "    'dnn_hidden_units': [(128, 128), (256, 256), (256, 128)],\n",
    "    'dnn_dropout': [0.1, 0.3, 0.5]\n",
    "}\n",
    "allNames = sorted(params)\n",
    "combinations = it.product(*(params[Name] for Name in allNames))\n",
    "\n",
    "best_params = None\n",
    "best_mse = 1000\n",
    "\n",
    "# grid search for DeepFM\n",
    "for i in list(combinations):\n",
    "  dropout, dnn_hidden_units, embedding_dim = i\n",
    "\n",
    "  # 2.count #unique features for each sparse field\n",
    "  fixlen_feature_columns = [SparseFeat(feat, training_deep[feat].nunique(), embedding_dim = embedding_dim) for feat in sparse_features]\n",
    "  linear_feature_columns = fixlen_feature_columns\n",
    "  dnn_feature_columns = fixlen_feature_columns\n",
    "  feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns)\n",
    "  \n",
    "  # 3.define model inputs   \n",
    "  train_model_input = {name:training_deep[name].values for name in feature_names}\n",
    "  valid_model_input = {name:validation_deep[name].values for name in feature_names}\n",
    "  test_model_input = {name:test_deep[name].values for name in feature_names}\n",
    "\n",
    "  # 4.Define Model,train,predict and evaluate\n",
    "  model = DeepFM(linear_feature_columns, dnn_feature_columns, fm_group=['business_city_state'], task='regression', dnn_hidden_units = dnn_hidden_units, dnn_dropout = dropout, l2_reg_embedding=1e-05, l2_reg_dnn=1e-05, l2_reg_linear=1e-05, seed = 42)\n",
    "  model.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "  # only one epoch because it overfits after the first epoch\n",
    "  history = model.fit(train_model_input, training_deep[target].values, batch_size=256, epochs=1, verbose=2, validation_data= (valid_model_input, validation[target].values))\n",
    "\n",
    "  validation_predictions = model.predict(valid_model_input, batch_size=256)\n",
    "  val_mse = mean_squared_error(validation_deep[target].values, validation_predictions)\n",
    "  print(\"validation MSE\", round(val_mse, 4))\n",
    "  if val_mse < best_mse:\n",
    "    best_mse = val_mse\n",
    "    best_params = [dropout, dnn_hidden_units, embedding_dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kRBnLR47PGW4"
   },
   "outputs": [],
   "source": [
    "best_mse, best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7Cqr0e7ds9Ga"
   },
   "source": [
    "#### Grid Search for WDL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QIIAcVo4PSON"
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'embedding_dim' : [8, 16, 32],\n",
    "    'dnn_hidden_units': [(128, 128), (256, 256), (256, 128)],\n",
    "    'dnn_dropout': [0.1, 0.3, 0.5]\n",
    "}\n",
    "allNames = sorted(params)\n",
    "combinations = it.product(*(params[Name] for Name in allNames))\n",
    "\n",
    "best_params_wdl = None\n",
    "best_mse_wdl = 1000\n",
    "\n",
    "# grid search for WDL\n",
    "for i in list(combinations):\n",
    "  dropout, dnn_hidden_units, embedding_dim = i\n",
    "\n",
    "  # 2.count #unique features for each sparse field\n",
    "  fixlen_feature_columns = [SparseFeat(feat, training_deep[feat].nunique(), embedding_dim = embedding_dim) for feat in sparse_features]\n",
    "  linear_feature_columns = fixlen_feature_columns\n",
    "  dnn_feature_columns = fixlen_feature_columns\n",
    "  feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns)\n",
    "  \n",
    "  # 3.define model inputs   \n",
    "  train_model_input = {name:training_deep[name].values for name in feature_names}\n",
    "  valid_model_input = {name:validation_deep[name].values for name in feature_names}\n",
    "  test_model_input = {name:test_deep[name].values for name in feature_names}\n",
    "\n",
    "  # 4.Define Model,train,predict and evaluate\n",
    "  model = WDL(linear_feature_columns, dnn_feature_columns, task='regression', dnn_hidden_units = dnn_hidden_units, dnn_dropout = dropout, l2_reg_embedding=1e-05, l2_reg_dnn=1e-05, l2_reg_linear=1e-05, seed = 42)\n",
    "  model.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "  # only one epoch because it overfits after the first epoch\n",
    "  history = model.fit(train_model_input, training_deep[target].values, batch_size=256, epochs=1, verbose=2, validation_data= (valid_model_input, validation[target].values))\n",
    "\n",
    "  validation_predictions = model.predict(valid_model_input, batch_size=256)\n",
    "  val_mse = mean_squared_error(validation_deep[target].values, validation_predictions)\n",
    "  print(\"validation MSE\", round(val_mse, 4))\n",
    "  if val_mse < best_mse_wdl:\n",
    "    best_mse_wdl = val_mse\n",
    "    best_params_wdl = [dropout, dnn_hidden_units, embedding_dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6uXv2eFIPSL8"
   },
   "outputs": [],
   "source": [
    "best_mse_wdl, best_params_wdl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g-iSvuv1zGS3"
   },
   "source": [
    "#### Refitting the model on the best parameters for each of the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "colab_type": "code",
    "id": "4YwMQt-8pIPT",
    "outputId": "2f25c438-8bab-4fdd-cc65-8ee7c9f007e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 857122 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "857122/857122 - 72s - loss: 1.7143 - mse: 1.6955\n",
      "Train on 857122 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "857122/857122 - 71s - loss: 1.7126 - mse: 1.6932\n"
     ]
    }
   ],
   "source": [
    "# 1.Label Encoding for sparse features,and do simple Transformation for dense features\n",
    "training_combined = pd.concat([training, validation], axis = 0)\n",
    "training_combined_deep = training_combined.copy()\n",
    "test_deep = test.copy()\n",
    "\n",
    "sparse_features = [\"user_id\", \"business_id\", \"business_city_state\"]#, \"hour\"]\n",
    "target = ['rating']\n",
    "\n",
    "for feat in sparse_features:\n",
    "  lbe = LabelEncoder()\n",
    "  training_combined_deep[feat] = lbe.fit_transform(training_combined_deep[feat])\n",
    "  test_deep[feat] = lbe.transform(test_deep[feat])\n",
    "\n",
    "# best DeepFM Model\n",
    "dropout_deepfm = 0.1\n",
    "dnn_hidden_units_deepfm = (128, 128)\n",
    "embedding_dim_deepfm = 8\n",
    "\n",
    "# 2.count #unique features for each sparse field\n",
    "fixlen_feature_columns = [SparseFeat(feat, training_combined_deep[feat].nunique(), embedding_dim = embedding_dim_deepfm) for feat in sparse_features]\n",
    "linear_feature_columns = fixlen_feature_columns\n",
    "dnn_feature_columns = fixlen_feature_columns\n",
    "feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns)\n",
    "\n",
    "# 3.define model inputs   \n",
    "train_model_input = {name:training_combined_deep[name].values for name in feature_names}\n",
    "test_model_input = {name:test_deep[name].values for name in feature_names}\n",
    "\n",
    "# 4.Define Model,train,predict and evaluate\n",
    "model_deepfm = DeepFM(linear_feature_columns, dnn_feature_columns, fm_group=['business_city_state'], task='regression', dnn_hidden_units = dnn_hidden_units_deepfm, dnn_dropout = dropout_deepfm, l2_reg_embedding=1e-05, l2_reg_dnn=1e-05, l2_reg_linear=1e-05, seed = 42)\n",
    "model_deepfm.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "# only one epoch because it overfits after the first epoch\n",
    "history = model_deepfm.fit(train_model_input, training_combined_deep[target].values, batch_size=256, epochs=1, verbose=2)\n",
    "\n",
    "test_predictions_deepfm = model_deepfm.predict(test_model_input, batch_size=255)\n",
    "test_mse_deepfm = mean_squared_error(test_deep[target].values, test_predictions_deepfm)\n",
    "\n",
    "\n",
    "# best WDL Model\n",
    "dropout_wdl = 0.3\n",
    "dnn_hidden_units_wdl = (256, 256)\n",
    "embedding_dim_wdl = 8\n",
    "\n",
    "# 2.count #unique features for each sparse field\n",
    "fixlen_feature_columns = [SparseFeat(feat, training_combined_deep[feat].nunique(), embedding_dim = embedding_dim_wdl) for feat in sparse_features]\n",
    "linear_feature_columns = fixlen_feature_columns\n",
    "dnn_feature_columns = fixlen_feature_columns\n",
    "feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns)\n",
    "\n",
    "# 3.define model inputs   \n",
    "train_model_input = {name:training_combined_deep[name].values for name in feature_names}\n",
    "test_model_input = {name:test_deep[name].values for name in feature_names}\n",
    "\n",
    "# 4.Define Model,train,predict and evaluate\n",
    "model_wdl = WDL(linear_feature_columns, dnn_feature_columns, task='regression', dnn_hidden_units = dnn_hidden_units_wdl, dnn_dropout = dropout_wdl, l2_reg_embedding=1e-05, l2_reg_dnn=1e-05, l2_reg_linear=1e-05, seed = 42)\n",
    "model_wdl.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "# only one epoch because it overfits after the first epoch\n",
    "history = model_wdl.fit(train_model_input, training_combined_deep[target].values, batch_size=256, epochs=1, verbose=2)\n",
    "\n",
    "test_predictions_wdl = model_wdl.predict(test_model_input, batch_size=256)\n",
    "test_mse_wdl = mean_squared_error(test_deep[target].values, test_predictions_wdl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "m9r7HJH_u_qc",
    "outputId": "16921fe0-56a2-4d8e-82ee-bbd0e1177041"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.7833152958561953, 1.784929756718987)"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_mse_deepfm, test_mse_wdl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4ntPEspLzQfk"
   },
   "source": [
    "#### R2 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "3gxa_XCvQHPO",
    "outputId": "efbf621b-9687-4fa8-d077-e2e6687233e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: 0.204\n",
      "R2 Score: 0.203\n"
     ]
    }
   ],
   "source": [
    "print(\"R2 Score: %0.3f\" %r2_score(y_true = test_deep[target], y_pred = test_predictions_deepfm))\n",
    "print(\"R2 Score: %0.3f\" %r2_score(y_true = test_deep[target], y_pred = test_predictions_wdl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WAPdjZHTzT9L"
   },
   "source": [
    "#### Mean Absolute Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "eXVSUJR1FtIQ",
    "outputId": "a9756783-66e1-48fe-95d1-d406644d251f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 1.082\n",
      "Mean Absolute Error: 1.079\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean Absolute Error: %0.3f\" %mean_absolute_error(y_true = test_deep[target], y_pred = test_predictions_deepfm))\n",
    "print(\"Mean Absolute Error: %0.3f\" %mean_absolute_error(y_true = test_deep[target], y_pred = test_predictions_wdl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vq62aTXfzWKX"
   },
   "source": [
    "#### Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "Mx18EHNdFtsy",
    "outputId": "defa932b-6f58-4169-d68a-df4eb9c20eb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Square Error: 1.335\n",
      "Root Mean Square Error: 1.336\n"
     ]
    }
   ],
   "source": [
    "print(\"Root Mean Square Error: %0.3f\" %mean_squared_error(y_true = test_deep[target], y_pred = test_predictions_deepfm, squared = False))\n",
    "print(\"Root Mean Square Error: %0.3f\" %mean_squared_error(y_true = test_deep[target], y_pred = test_predictions_wdl, squared = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HviC2U69-cvT"
   },
   "source": [
    "#### Rest of the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KJaZIbgdFtx4"
   },
   "outputs": [],
   "source": [
    "def process(df):\n",
    "    # df = df.drop(df.columns[0], axis =1)\n",
    "    df['date']  = pd.to_datetime(df['date'])\n",
    "    df['week_day'] = df['date'].dt.weekday\n",
    "    df['month'] = df['date'].dt.month\n",
    "    df['hour'] = df['date'].dt.hour\n",
    "    df = df.merge(users, on = 'user_id')\n",
    "    df = df.merge(businesses, on = 'business_id')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-AgdF0vOFtwd"
   },
   "outputs": [],
   "source": [
    "ratings_train = process(training.copy())\n",
    "ratings_validation = process(validation.copy())\n",
    "ratings_test = process(test.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "44J-_bemFtqn"
   },
   "outputs": [],
   "source": [
    "ratings_train_final = ratings_train.append(ratings_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R3wqepVHQC54"
   },
   "outputs": [],
   "source": [
    "unique_city_businesses = ratings_train_final[['business_city','business_id']].drop_duplicates()\n",
    "unique_cities = unique_city_businesses.groupby('business_city').count()['business_id']\n",
    "unique_cities = unique_cities[unique_cities > 100]\n",
    "out = pd.DataFrame()\n",
    "for city in unique_cities.index:\n",
    "    tmp = ratings_train_final[(ratings_train_final['business_city'] ==city) &\n",
    "                              (ratings_train_final['rating'] >ratings_train_final['average_stars'])]\n",
    "    if len(tmp['user_id'].unique())>4:\n",
    "        np.random.seed(42)\n",
    "        ###this weird sampling technique is to ensure we dont' sample the same user twice in a same city\n",
    "        five_users = np.random.choice(tmp['user_id'].unique(),5, replace = False)\n",
    "        row = tmp[tmp['user_id'].isin(five_users)].groupby('user_id', group_keys=False).apply(lambda df: df.sample(1))\n",
    "        out = out.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "XbttGKw7i4OF",
    "outputId": "f7458a6c-0035-4f81-84c7-fd0f79969f56"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all(out.groupby('business_city').count()['user_id']==5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nJ2MUDxni4TG"
   },
   "outputs": [],
   "source": [
    "predict_df = out[['user_id','business_city','business_state']]\n",
    "predict_df = predict_df.merge(unique_city_businesses, on = 'business_city')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "2rWcE5DHi4Ri",
    "outputId": "d1ff79de-df74-45f8-9aac-2e525476cc36"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all(predict_df.groupby('business_city')['user_id'].nunique()==5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HIB3gLs1mzaS"
   },
   "outputs": [],
   "source": [
    "# remove businesses not in training\n",
    "predict_df = predict_df.loc[predict_df.business_id.isin(training.business_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "colab_type": "code",
    "id": "87I2AzH2i4Lp",
    "outputId": "9b779b9c-63f1-47f3-8f87-7829c113cd4b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7kfJk_NtOslC9jPk2Koz3g</td>\n",
       "      <td>8AW0koYMDa1PlJMOE-b2-g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7kfJk_NtOslC9jPk2Koz3g</td>\n",
       "      <td>-YGQwikbX2fXUIjyegR7pw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7kfJk_NtOslC9jPk2Koz3g</td>\n",
       "      <td>5Kh5i4VhXj-Leg8gujIzjQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7kfJk_NtOslC9jPk2Koz3g</td>\n",
       "      <td>Wl1oOVbtK4I9vRKoaSKYiQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7kfJk_NtOslC9jPk2Koz3g</td>\n",
       "      <td>OxSaGGTmIujsjDpDqwyGPQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567480</th>\n",
       "      <td>gWbXQg0rPLDCRNR0HbImvA</td>\n",
       "      <td>nkLUGjzFNPCrClbT1UIZaw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567481</th>\n",
       "      <td>gWbXQg0rPLDCRNR0HbImvA</td>\n",
       "      <td>r0U1aexkjoUKoTuXlisjng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567482</th>\n",
       "      <td>gWbXQg0rPLDCRNR0HbImvA</td>\n",
       "      <td>KfuHr7dYyEaDrHtQpFdNUw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567483</th>\n",
       "      <td>gWbXQg0rPLDCRNR0HbImvA</td>\n",
       "      <td>41xuKlIuZTLu6qTbpqTY-A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567484</th>\n",
       "      <td>gWbXQg0rPLDCRNR0HbImvA</td>\n",
       "      <td>PWSMRc9FW9fbUa1WJ0mhDQ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>567485 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       user_id             business_id\n",
       "0       7kfJk_NtOslC9jPk2Koz3g  8AW0koYMDa1PlJMOE-b2-g\n",
       "1       7kfJk_NtOslC9jPk2Koz3g  -YGQwikbX2fXUIjyegR7pw\n",
       "2       7kfJk_NtOslC9jPk2Koz3g  5Kh5i4VhXj-Leg8gujIzjQ\n",
       "3       7kfJk_NtOslC9jPk2Koz3g  Wl1oOVbtK4I9vRKoaSKYiQ\n",
       "4       7kfJk_NtOslC9jPk2Koz3g  OxSaGGTmIujsjDpDqwyGPQ\n",
       "...                        ...                     ...\n",
       "567480  gWbXQg0rPLDCRNR0HbImvA  nkLUGjzFNPCrClbT1UIZaw\n",
       "567481  gWbXQg0rPLDCRNR0HbImvA  r0U1aexkjoUKoTuXlisjng\n",
       "567482  gWbXQg0rPLDCRNR0HbImvA  KfuHr7dYyEaDrHtQpFdNUw\n",
       "567483  gWbXQg0rPLDCRNR0HbImvA  41xuKlIuZTLu6qTbpqTY-A\n",
       "567484  gWbXQg0rPLDCRNR0HbImvA  PWSMRc9FW9fbUa1WJ0mhDQ\n",
       "\n",
       "[567485 rows x 2 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_df[['user_id', 'business_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mm_osHNri4KK"
   },
   "outputs": [],
   "source": [
    "predict_df['business_city_state'] = predict_df['business_city'] + predict_df['business_state']\n",
    "metric_test_deep = predict_df[['user_id', 'business_id', 'business_city_state']].copy()\n",
    "\n",
    "for feat in sparse_features:\n",
    "  lbe = LabelEncoder()\n",
    "  lbe.fit(training[feat])\n",
    "  metric_test_deep[feat] = lbe.transform(metric_test_deep[feat])\n",
    "  \n",
    "metric_test_input = {name:metric_test_deep[name].values for name in feature_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qIGGwTB5i4Ev"
   },
   "outputs": [],
   "source": [
    "metric_test_predictions_deepfm = model_deepfm.predict(metric_test_input, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RVpeNfgFBAJO"
   },
   "outputs": [],
   "source": [
    "metric_test_predictions_wdl = model_wdl.predict(metric_test_input, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y_y1tyX2qnci"
   },
   "outputs": [],
   "source": [
    "predict_df['predictions'] = metric_test_predictions_wdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FyT-eH8Zi4CD"
   },
   "outputs": [],
   "source": [
    "top_10_recs = predict_df.groupby(['user_id','business_city'])['predictions'].nlargest(10).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "c-OQeKTKqu0c",
    "outputId": "2edfcf56-5289-44e1-8613-57009001eac4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all(top_10_recs.groupby('business_city')['user_id'].count()==50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fSLYCDXIqxxz"
   },
   "outputs": [],
   "source": [
    "cnt =0\n",
    "serendipity = 0\n",
    "for row in out.iterrows():\n",
    "    row_values = row[1]\n",
    "    top_10 = predict_df.loc[top_10_recs[top_10_recs['user_id'] == row_values['user_id']].level_2]['business_id']\n",
    "    ###In top 10\n",
    "    if row_values['business_id'] in top_10.values:\n",
    "        cnt+=1\n",
    "    user_history = ratings_train_final[ratings_train_final['user_id'] == row_values['user_id']]    \n",
    "    been_there = [i for i in top_10.values if i in  user_history.business_id.values]\n",
    "    serendipity += 1-len(been_there)/10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2ylHkaMQzpo0"
   },
   "source": [
    "##### Inclusion of Last Review in Top 10 Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "3qnqgccSqz8N",
    "outputId": "1a0815da-26af-4de4-a340-5c49a3c60269"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15421686746987953"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt/len(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-npOsGnLzylw"
   },
   "source": [
    "#### Novelty(% of new restaurants in top 10 recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "nLVvzmSgq0F3",
    "outputId": "935e64f8-eee4-4b77-ebb8-a57c396c769e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9710843373493965"
      ]
     },
     "execution_count": 39,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serendipity/len(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OdU5aij8q0Jz"
   },
   "outputs": [],
   "source": [
    "predict_df = predict_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "OhWnlJlRq0D0",
    "outputId": "4fe44004-326d-4071-bdea-f512b496425c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'user_id', 'business_city', 'business_state', 'business_id',\n",
       "       'business_city_state', 'predictions'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 41,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "colab_type": "code",
    "id": "d8NoYo-_q0BZ",
    "outputId": "4d290edc-7111-43b1-d554-a16b1658e109"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_city</th>\n",
       "      <th>level_2</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>--3WaS23LcIXtxyFULJHTA</td>\n",
       "      <td>Scottsdale</td>\n",
       "      <td>442142</td>\n",
       "      <td>5.031378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  user_id business_city  level_2  predictions\n",
       "0  --3WaS23LcIXtxyFULJHTA    Scottsdale   442142     5.031378"
      ]
     },
     "execution_count": 42,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_10_recs.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "colab_type": "code",
    "id": "x_3vNgyZqz_b",
    "outputId": "092d2277-10ae-490b-bf0f-d53925fa8d32"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_city</th>\n",
       "      <th>business_state</th>\n",
       "      <th>business_id</th>\n",
       "      <th>business_city_state</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7kfJk_NtOslC9jPk2Koz3g</td>\n",
       "      <td>Ajax</td>\n",
       "      <td>ON</td>\n",
       "      <td>8AW0koYMDa1PlJMOE-b2-g</td>\n",
       "      <td>AjaxON</td>\n",
       "      <td>3.028969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                 user_id  ... business_city_state predictions\n",
       "0      0  7kfJk_NtOslC9jPk2Koz3g  ...              AjaxON    3.028969\n",
       "\n",
       "[1 rows x 7 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VINNqvNPrDMZ"
   },
   "outputs": [],
   "source": [
    "analysis_df = predict_df.merge(top_10_recs, left_on = ['user_id','business_city','index'], right_on = ['user_id','business_city','level_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "lI8JXFnqrDjc",
    "outputId": "a5dcb26b-c000-4761-eed3-a39f60143192"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all(analysis_df.groupby('business_city')['business_id'].count() ==50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1BzHo5qVz33g"
   },
   "source": [
    "#### Coverage(% of unique recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "_zvl2iWirD0Q",
    "outputId": "bf129774-0c4e-4e1d-88e1-55b4349c970e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23156626506024094"
      ]
     },
     "execution_count": 46,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(analysis_df.groupby('business_city')['business_id'].nunique()/50).values.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZwJxLq7frD37"
   },
   "outputs": [],
   "source": [
    "predict_df['rankings']=predict_df.groupby(['business_city','user_id'])['predictions'].rank(\"first\",ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zqBgeEyJrDyS"
   },
   "outputs": [],
   "source": [
    "running_rankings =0\n",
    "for row in out.iterrows():\n",
    "    row_values = row[1]\n",
    "    user_recs = predict_df[(predict_df['user_id']==row_values['user_id'])\n",
    "                        &(predict_df['business_city']==row_values['business_city'])\n",
    "                         & (predict_df['business_id']==row_values['business_id'])\n",
    "                          ]\n",
    "    assert len(user_recs)==1\n",
    "    running_rankings += user_recs['rankings'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K2LHBqYGz6sh"
   },
   "source": [
    "#### Average Ranking of Last Positive Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "g5xr4-MorDwG",
    "outputId": "7ccdb76c-32dc-4135-defc-146be2190035"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "449.69397590361444"
      ]
     },
     "execution_count": 49,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "running_rankings / len(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7wb0n8qfrDtc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n-mj7Wj5rDq1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Uo_CQ3G8rDpP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uPG9zj1HrDn4"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "DeepLearning_RecSys.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
