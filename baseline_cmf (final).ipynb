{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yelp Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset Documentation: <br>\n",
    "https://www.yelp.com/dataset/documentation/main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from cmfrec import CMF\n",
    "import pycmf\n",
    "\n",
    "import time\n",
    "from copy import deepcopy\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from surprise import SVD\n",
    "from surprise import accuracy\n",
    "from surprise import Reader\n",
    "from surprise.model_selection import GridSearchCV\n",
    "from surprise import Dataset\n",
    "from surprise import BaselineOnly\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tarfile\n",
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 192609/192609 [00:02<00:00, 72168.99it/s]\n"
     ]
    }
   ],
   "source": [
    "# load business.json\n",
    "# 192609 unique businesses?\n",
    "line_count = len(open(\"./yelp_dataset/business.json\").readlines())\n",
    "business_ids, cities, states, latitudes, longitudes, stars, review_counts, attributes, categories = [], [], [], [], [], [], [], [], []\n",
    "with open(\"./yelp_dataset/business.json\") as f:\n",
    "    for line in tqdm(f, total=line_count):\n",
    "        blob = json.loads(line)\n",
    "        business_ids += [blob[\"business_id\"]]\n",
    "        cities += [blob[\"city\"]]\n",
    "        states += [blob[\"state\"]]\n",
    "        latitudes += [blob[\"latitude\"]]\n",
    "        longitudes += [blob[\"longitude\"]]\n",
    "        stars += [blob[\"stars\"]]\n",
    "        review_counts += [blob[\"review_count\"]]\n",
    "        attributes += [blob[\"attributes\"]]\n",
    "        categories += [blob[\"categories\"]]\n",
    "        \n",
    "businesses = pd.DataFrame(\n",
    "    {\"business_id\": business_ids, \"city\": cities, \"state\": states, \"latitude\": latitudes, \"longitude\": longitudes, \"stars\": stars, \"review_counts\": review_counts, \"attributes\": attributes, \"categories\":categories }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1637138/1637138 [00:21<00:00, 75685.86it/s]\n"
     ]
    }
   ],
   "source": [
    "# load user.json\n",
    "# 1637138 unique users?\n",
    "line_count = len(open(\"./yelp_dataset/user.json\").readlines())\n",
    "users, review_counts, elites, average_stars, friends = [], [], [], [], []\n",
    "with open(\"./yelp_dataset/user.json\") as f:\n",
    "    for line in tqdm(f, total=line_count):\n",
    "        blob = json.loads(line)\n",
    "        users += [blob[\"user_id\"]]\n",
    "        review_counts += [blob[\"review_count\"]]\n",
    "        elites += [blob[\"elite\"]]\n",
    "        average_stars += [blob[\"average_stars\"]]\n",
    "        friends += [blob[\"friends\"]]\n",
    "        \n",
    "users = pd.DataFrame(\n",
    "    {\"user_id\": users, \"review_count\": review_counts,\"elite\": elites, \"average_stars\": average_stars, \"friends\": friends}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6685900/6685900 [00:58<00:00, 113366.86it/s]\n"
     ]
    }
   ],
   "source": [
    "# load review.json\n",
    "# 6685900 unique reviews?\n",
    "line_count = len(open(\"./yelp_dataset/review.json\").readlines())\n",
    "user_ids, business_ids, stars, dates, texts = [], [], [], [], []\n",
    "with open(\"./yelp_dataset/review.json\") as f:\n",
    "    for line in tqdm(f, total=line_count):\n",
    "        blob = json.loads(line)\n",
    "        user_ids += [blob[\"user_id\"]]\n",
    "        business_ids += [blob[\"business_id\"]]\n",
    "        stars += [blob[\"stars\"]]\n",
    "        dates += [blob[\"date\"]]\n",
    "        texts += [blob[\"text\"]]\n",
    "reviews = pd.DataFrame(\n",
    "    {\"user_id\": user_ids, \"business_id\": business_ids, \"rating\": stars, \"date\": dates, \"text\": texts}\n",
    ")\n",
    "user_counts = reviews[\"user_id\"].value_counts()\n",
    "active_users = user_counts.loc[user_counts >= 5].index.tolist()\n",
    "reviews = reviews.loc[reviews.user_id.isin(active_users)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(df):\n",
    "    df = df.drop(df.columns[0], axis =1)\n",
    "    df['date']  = pd.to_datetime(df['date'])\n",
    "    df['week_day'] = df['date'].dt.weekday\n",
    "    df['month'] = df['date'].dt.month\n",
    "    df['hour'] = df['date'].dt.hour\n",
    "    df = df.merge(users, on = 'user_id')\n",
    "    df = df.merge(businesses, on = 'business_id')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data: 20%, 50%, 100%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bowenzhou/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3049: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "ratings_holdout_20 = pd.read_csv('data/ratings_sample_holdout_20.csv')\n",
    "ratings_train_20 = pd.read_csv('data/ratings_sample_train_20.csv')\n",
    "ratings_val_20 = pd.read_csv('data/ratings_sample_cv_20.csv')\n",
    "\n",
    "ratings_holdout_50 = pd.read_csv('data/ratings_sample_holdout_50.csv')\n",
    "ratings_val_50 = pd.read_csv('data/ratings_sample_cv_50.csv')\n",
    "ratings_train_50 = pd.read_csv('data/ratings_sample_train_50.csv')\n",
    "\n",
    "ratings_holdout_100 = pd.read_csv('data/ratings_sample_holdout_100.csv')\n",
    "ratings_train_100 = pd.read_csv('data/ratings_sample_train_100.csv')\n",
    "ratings_val_100 = pd.read_csv('data/ratings_sample_cv_100.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_train_20 = process(ratings_train_20.copy())\n",
    "ratings_holdout_20 = process(ratings_holdout_20.copy())\n",
    "ratings_val_20 = process(ratings_val_20.copy())\n",
    "\n",
    "ratings_train_50 = process(ratings_train_50.copy())\n",
    "ratings_holdout_50 = process(ratings_holdout_50.copy())\n",
    "ratings_val_50 = process(ratings_val_50.copy())\n",
    "\n",
    "ratings_val_100 = process(ratings_val_100.copy())\n",
    "ratings_train_100 = process(ratings_train_100.copy())\n",
    "ratings_holdout_100 = process(ratings_holdout_100.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_test_20 = ratings_holdout_20.loc[ratings_holdout_20.business_id.isin(ratings_train_20.business_id)]\n",
    "ratings_val_20 = ratings_val_20.loc[ratings_val_20.business_id.isin(ratings_train_20.business_id)]\n",
    "\n",
    "ratings_test_50 = ratings_holdout_50.loc[ratings_holdout_50.business_id.isin(ratings_train_50.business_id)]\n",
    "ratings_val_50 = ratings_val_50.loc[ratings_val_50.business_id.isin(ratings_train_50.business_id)]\n",
    "\n",
    "ratings_test_100 = ratings_holdout_100.loc[ratings_holdout_100.business_id.isin(ratings_train_100.business_id)]\n",
    "ratings_val_100 = ratings_val_100.loc[ratings_val_100.business_id.isin(ratings_train_100.business_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset_20 = ratings_train_20.iloc[:,0:3]\n",
    "trainset_20.columns = ['userID', 'itemID','rating']\n",
    "valset_20 = ratings_val_20.iloc[:, 0:3]\n",
    "valset_20.columns = ['userID', 'itemID','rating']\n",
    "testset_20 = ratings_holdout_20.iloc[:, 0:3]\n",
    "testset_20.columns = ['userID', 'itemID','rating']\n",
    "\n",
    "trainset_50 = ratings_train_50.iloc[:,0:3]\n",
    "trainset_50.columns = ['userID', 'itemID','rating']\n",
    "valset_50 = ratings_val_50.iloc[:, 0:3]\n",
    "valset_50.columns = ['userID', 'itemID','rating']\n",
    "testset_50 = ratings_holdout_50.iloc[:, 0:3]\n",
    "testset_50.columns = ['userID', 'itemID','rating']\n",
    "\n",
    "trainset_100 = ratings_train_100.iloc[:,0:3]\n",
    "trainset_100.columns = ['userID', 'itemID','rating']\n",
    "valset_100 = ratings_val_100.iloc[:, 0:3]\n",
    "valset_100.columns = ['userID', 'itemID','rating']\n",
    "testset_100 = ratings_holdout_100.iloc[:, 0:3]\n",
    "testset_100.columns = ['userID', 'itemID','rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform to work with surprise, 20%, 50% and full dataset\n",
    "reader = Reader(rating_scale = (0.0, 5.0))\n",
    "train_data_20 = Dataset.load_from_df(trainset_20[['userID','itemID','rating']], reader)\n",
    "val_data_20 = Dataset.load_from_df(valset_20[['userID','itemID','rating']], reader)\n",
    "test_data_20 = Dataset.load_from_df(testset_20[['userID','itemID','rating']], reader)\n",
    "\n",
    "train_data_50 = Dataset.load_from_df(trainset_50[['userID','itemID','rating']], reader)\n",
    "val_data_50 = Dataset.load_from_df(valset_50[['userID','itemID','rating']], reader)\n",
    "test_data_50 = Dataset.load_from_df(testset_50[['userID','itemID','rating']], reader)\n",
    "\n",
    "train_data_100 = Dataset.load_from_df(trainset_100[['userID','itemID','rating']], reader)\n",
    "val_data_100 = Dataset.load_from_df(valset_100[['userID','itemID','rating']], reader)\n",
    "test_data_100 = Dataset.load_from_df(testset_100[['userID','itemID','rating']], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sr_20 = train_data_20.build_full_trainset()\n",
    "val_sr_before_20 = val_data_20.build_full_trainset()\n",
    "val_sr_20 = val_sr_before_20.build_testset()\n",
    "test_sr_before_20 = test_data_20.build_full_trainset()\n",
    "test_sr_20 = test_sr_before_20.build_testset()\n",
    "\n",
    "train_sr_50 = train_data_50.build_full_trainset()\n",
    "val_sr_before_50 = val_data_20.build_full_trainset()\n",
    "val_sr_50 = val_sr_before_20.build_testset()\n",
    "test_sr_before_50 = test_data_50.build_full_trainset()\n",
    "test_sr_50 = test_sr_before_50.build_testset()\n",
    "\n",
    "train_sr_100 = train_data_100.build_full_trainset()\n",
    "val_sr_before_100 = val_data_100.build_full_trainset()\n",
    "val_sr_100 = val_sr_before_100.build_testset()\n",
    "test_sr_before_100 = test_data_100.build_full_trainset()\n",
    "test_sr_100 = test_sr_before_100.build_testset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### evaluation set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_train_final_20 = ratings_train_20.append(ratings_val_20)\n",
    "ratings_train_final_50 = ratings_train_50.append(ratings_val_50)\n",
    "ratings_train_final_100 = ratings_train_100.append(ratings_val_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_entire_df_20 = ratings_train_20.append(ratings_val_20).append(ratings_holdout_20)\n",
    "ratings_entire_df_50 = ratings_train_50.append(ratings_val_50).append(ratings_holdout_50)\n",
    "ratings_entire_df_100 = ratings_train_100.append(ratings_val_100).append(ratings_holdout_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_city_businesses_20 = ratings_entire_df_20[['city','business_id']].drop_duplicates()\n",
    "unique_cities_20 = unique_city_businesses_20.groupby('city').count()['business_id']\n",
    "unique_cities_20 = unique_cities_20[unique_cities_20 > 100]\n",
    "out_20 = pd.DataFrame()\n",
    "for city in unique_cities_20.index:\n",
    "    tmp = ratings_holdout_20[(ratings_holdout_20['city'] ==city) &\n",
    "                              (ratings_holdout_20['rating'] >ratings_holdout_20['average_stars'])]\n",
    "    if len(tmp['user_id'].unique())>4:\n",
    "        \n",
    "        ###this weird sampling technique is to ensure we dont' sample the same user twice in a same city\n",
    "        five_users = np.random.choice(tmp['user_id'].unique(),5, replace = False)\n",
    "        row = tmp[tmp['user_id'].isin(five_users)].groupby('user_id', group_keys=False).apply(lambda df: df.sample(1))\n",
    "        out_20 = out_20.append(row)\n",
    "        \n",
    "unique_city_businesses_50 = ratings_entire_df_50[['city','business_id']].drop_duplicates()\n",
    "unique_cities_50 = unique_city_businesses_50.groupby('city').count()['business_id']\n",
    "unique_cities_50 = unique_cities_50[unique_cities_50 > 100]\n",
    "out_50 = pd.DataFrame()\n",
    "for city in unique_cities_50.index:\n",
    "    tmp = ratings_holdout_50[(ratings_holdout_50['city'] ==city) &\n",
    "                              (ratings_holdout_50['rating'] >ratings_holdout_50['average_stars'])]\n",
    "    if len(tmp['user_id'].unique())>4:\n",
    "        \n",
    "        ###this weird sampling technique is to ensure we dont' sample the same user twice in a same city\n",
    "        five_users = np.random.choice(tmp['user_id'].unique(),5, replace = False)\n",
    "        row = tmp[tmp['user_id'].isin(five_users)].groupby('user_id', group_keys=False).apply(lambda df: df.sample(1))\n",
    "        out_50 = out_50.append(row)\n",
    "        \n",
    "unique_city_businesses_100 = ratings_entire_df_100[['city','business_id']].drop_duplicates()\n",
    "unique_cities_100 = unique_city_businesses_100.groupby('city').count()['business_id']\n",
    "unique_cities_100 = unique_cities_100[unique_cities_100 > 100]\n",
    "out_100 = pd.DataFrame()\n",
    "for city in unique_cities_100.index:\n",
    "    tmp = ratings_holdout_100[(ratings_holdout_100['city'] ==city) &\n",
    "                              (ratings_holdout_100['rating'] >ratings_holdout_100['average_stars'])]\n",
    "    if len(tmp['user_id'].unique())>4:\n",
    "        \n",
    "        ###this weird sampling technique is to ensure we dont' sample the same user twice in a same city\n",
    "        five_users = np.random.choice(tmp['user_id'].unique(),5, replace = False)\n",
    "        row = tmp[tmp['user_id'].isin(five_users)].groupby('user_id', group_keys=False).apply(lambda df: df.sample(1))\n",
    "        out_100 = out_100.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_df_20 = out_20[['user_id','city','state']]\n",
    "predict_df_20 = predict_df_20.merge(unique_city_businesses_20, on = 'city')\n",
    "predict_df_20['predictions'] = 25\n",
    "\n",
    "predict_df_50 = out_50[['user_id','city','state']]\n",
    "predict_df_50 = predict_df_50.merge(unique_city_businesses_50, on = 'city')\n",
    "predict_df_50['predictions'] = 25\n",
    "\n",
    "predict_df_100 = out_50[['user_id','city','state']]\n",
    "predict_df_100 = predict_df_100.merge(unique_city_businesses_100, on = 'city')\n",
    "predict_df_100['predictions'] = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_20 = Dataset.load_from_df(predict_df_20[['user_id','business_id','predictions']], reader)\n",
    "eval_50 = Dataset.load_from_df(predict_df_50[['user_id','business_id','predictions']], reader)\n",
    "eval_100 = Dataset.load_from_df(predict_df_100[['user_id','business_id','predictions']], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_before_20 = eval_20.build_full_trainset()\n",
    "eval_sr_20 = eval_before_20.build_testset()\n",
    "eval_pred_20 = algo.test(eval_sr_20)\n",
    "#accuracy.rmse(eval_pred_20)\n",
    "baseline_20 = pd.DataFrame(eval_pred_20, columns = ['userId','itemId','rating','pred_rating','x'])\n",
    "predict_df_20['predictions'] = baseline_20.pred_rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias Baseline\n",
    "\n",
    "$\\sum_{r_{ui} \\in R_{train}} \\left(r_{ui} - (\\mu + b_u + b_i)\\right)^2 +\n",
    "\\lambda \\left(b_u^2 + b_i^2 \\right)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.3492\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.3491711762452891"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bsl_options = {'method': 'als', 'n_epochs':3}\n",
    "bias_baseline = BaselineOnly(bsl_options)\n",
    "algo.fit(train_sr_20)\n",
    "predictions = algo.test(val_sr_20)\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.3492\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.3491711762452891"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bsl_options = {'method': 'als', 'n_epochs':5}\n",
    "bias_baseline = BaselineOnly(bsl_options)\n",
    "algo.fit(train_sr_20)\n",
    "predictions = algo.test(val_sr_20)\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.3492\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.3491711762452891"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bsl_options = {'method': 'als', 'n_epochs':7}\n",
    "bias_baseline = BaselineOnly(bsl_options)\n",
    "algo.fit(train_sr_20)\n",
    "predictions = algo.test(val_sr_20)\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.3492\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.3491711762452891"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bsl_options = {'method': 'als', 'n_epochs':9}\n",
    "bias_baseline = BaselineOnly(bsl_options)\n",
    "algo.fit(train_sr_20)\n",
    "predictions = algo.test(val_sr_20)\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thus, they are all the same; we will just use default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "--- 2.0564420223236084 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# 20%\n",
    "start_time = time.time()\n",
    "bias_baseline.fit(train_sr_20)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.3545\n",
      "R^2 (with 20% data):  0.19799189125456051\n",
      "MAE (with 20% data):  1.127068744947832\n",
      "--- 0.08617496490478516 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# 20%\n",
    "bbase_p = bias_baseline.test(test_sr_20)\n",
    "start_time = time.time()\n",
    "bbase_20_df = pd.DataFrame(bbase_p, columns = ['userId','itemId','rating','pred_rating','x'])\n",
    "accuracy.rmse(bbase_p)\n",
    "print('R^2 (with 20% data): ', r2_score(bbase_20_df.rating , bbase_20_df.pred_rating))\n",
    "print('MAE (with 20% data): ', mean_absolute_error(bbase_20_df.rating, bbase_20_df.pred_rating))\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "--- 9.076530933380127 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# 50%\n",
    "start_time = time.time()\n",
    "bias_baseline.fit(train_sr_50)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.3607\n",
      "R^2 (with 20% data):  0.19814212228616024\n",
      "MAE (with 20% data):  1.133596632127378\n",
      "--- 0.2215869426727295 seconds ---\n"
     ]
    }
   ],
   "source": [
    "bbase_p_50 = bias_baseline.test(test_sr_50)\n",
    "start_time = time.time()\n",
    "bbase_50_df = pd.DataFrame(bbase_p_50, columns = ['userId','itemId','rating','pred_rating','x'])\n",
    "accuracy.rmse(bbase_p_50)\n",
    "print('R^2 (with 20% data): ', r2_score(bbase_50_df.rating , bbase_50_df.pred_rating))\n",
    "print('MAE (with 20% data): ', mean_absolute_error(bbase_50_df.rating, bbase_50_df.pred_rating))\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "--- 14.368994951248169 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# 100%\n",
    "start_time = time.time()\n",
    "bias_baseline.fit(train_sr_100)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.4015\n",
      "R^2 (with 20% data):  0.1507091690943303\n",
      "MAE (with 20% data):  1.1735826826580384\n",
      "--- 0.412855863571167 seconds ---\n"
     ]
    }
   ],
   "source": [
    "bbase_p_100 = bias_baseline.test(test_sr_100)\n",
    "start_time = time.time()\n",
    "bbase_100_df = pd.DataFrame(bbase_p_100, columns = ['userId','itemId','rating','pred_rating','x'])\n",
    "accuracy.rmse(bbase_p_100)\n",
    "print('R^2 (with 20% data): ', r2_score(bbase_100_df.rating , bbase_100_df.pred_rating))\n",
    "print('MAE (with 20% data): ', mean_absolute_error(bbase_100_df.rating, bbase_100_df.pred_rating))\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n"
     ]
    }
   ],
   "source": [
    "algo = BaselineOnly()\n",
    "eval_before_50 = eval_20.build_full_trainset()\n",
    "eval_sr_20 = eval_before_20.build_testset()\n",
    "algo.fit(train_sr_20)\n",
    "eval_pred_20 = algo.test(eval_sr_20)\n",
    "#accuracy.rmse(predictions_50)\n",
    "baseline_20 = pd.DataFrame(eval_pred_20, columns = ['userId','itemId','rating','pred_rating','x'])\n",
    "\n",
    "algo = BaselineOnly()\n",
    "eval_before_50 = eval_50.build_full_trainset()\n",
    "eval_sr_50 = eval_before_50.build_testset()\n",
    "algo.fit(train_sr_50)\n",
    "eval_pred_50 = algo.test(eval_sr_50)\n",
    "#accuracy.rmse(predictions_50)\n",
    "baseline_50 = pd.DataFrame(eval_pred_50, columns = ['userId','itemId','rating','pred_rating','x'])\n",
    "\n",
    "algo = BaselineOnly()\n",
    "eval_before_100 = eval_100.build_full_trainset()\n",
    "eval_sr_100 = eval_before_100.build_testset()\n",
    "algo.fit(train_sr_100)\n",
    "eval_pred_100 = algo.test(eval_sr_100)\n",
    "#accuracy.rmse(predictions_100)\n",
    "baseline_100 = pd.DataFrame(eval_pred_100, columns = ['userId','itemId','rating','pred_rating','x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10714285714285714 0.503095238095238 0.9697619047619042 528.3333333333334\n"
     ]
    }
   ],
   "source": [
    "top_10, coverage, serendipity, avg_rank = get_all_metrics(predict_df_20, out_20, ratings_train_final_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18035714285714285 0.20553571428571435 0.9794642857142847 440.3589285714286\n"
     ]
    }
   ],
   "source": [
    "top_10, coverage, serendipity, avg_rank = get_all_metrics(predict_df_50, out_50, ratings_train_final_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.014516129032258065 0.2 0.9983870967741933 6.670967741935484\n"
     ]
    }
   ],
   "source": [
    "top_10, coverage, serendipity, avg_rank = get_all_metrics(predict_df_100, out_100, ratings_train_final_100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Factorization (Baseline)\n",
    "\n",
    "Matrix factorization is a class of collaborative filtering algorithms. The general idea behind matrix factorization is that there can exist a lower dimensional latent space of features in which users and items can be represented such that the interaction between them can be obtained by simply dot producing the corresponding dense vectors in that space. In short, it decomposes a m*n user-item interaction matrix into two m*k and k*n matrices, sharing a joint latent vector space, where m represents the number of users, and n represents the number of items. In terms of its outcome, we are likely to observe that close users in terms of preferences as well as close items in terms of characteristics can have close representations in the latent space.\n",
    "\n",
    "The mathematical overview is as follows:\n",
    "Given a n*m matrix, such that . X is the user matrix where rows represent the n users and Y is the item matrix where rows represent the m items. We want to search for the dot product of matrices X and Y that best approximate the existing interactions; i.e., we want to find X and Y that minimize the “rating reconstruction error”:\n",
    "\n",
    "$$ (X,Y) = argmin_{X,Y} \\sum_{(i,j) \\in E} [(X_i)(Y_j)^T − M_{ij}]^2$$\n",
    "\n",
    "Adding a regularization term, we can also get:\n",
    "\n",
    "$$(X,Y) = argmin_{X,Y} ½ \\sum_{(i,j) \\in E} [(X_i)(Y_j)^T − M_{ij}]^2 + \\lambda/2(\\sum_{i,k}(X_{ik})^2 + \\sum_{j,k}(Y_{jk})^2)$$\n",
    "\n",
    "In general, we obtain the matrices X and Y following a gradient descent optimization process. And once the matrices are obtained, we can predict the ratings simply by multiplying the user vector by any item vector.\n",
    "\n",
    "In this Yelp Rating Challenge, we used the python surprise package to implement MF. The MF algorithm there uses the SVD approach, which is essentially \n",
    "\n",
    "$$ P_{m * n} = U_{m * m} \\sum_{m * n} V_{n * n}$$\n",
    "\n",
    "There, the prediction is\n",
    " $$\\hat(r_{ui}) = \\mu + b_u + b_i + (q_i)^T p_u $$\n",
    " \n",
    "and the regularized squared error that needs to be minimized is \n",
    "\n",
    "$$\\sum_{r_{ui} \\in R_{train}} (r_{ui} − \\hat(r_{ui}))^2 + \\lambda(b^2_{i} + b^2_{u} + ||q_i||^2 + ||p_u||^2)$$\n",
    "\n",
    "As the way the package is designed, we tuned on n_epochs, lr_all and leg_all to get an optimal hyperparameter set, where n_epochs is the number of iterations of the SGD (stochastic gradient descent) procedure, lr_all is the learning rate for all parameters, and reg_all is the regularization term for all parameters.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform to work with surprise, 20%, 50% and full dataset\n",
    "reader = Reader(rating_scale = (0.0, 5.0))\n",
    "train_data_20 = Dataset.load_from_df(trainset_20[['userID','itemID','rating']], reader)\n",
    "val_data_20 = Dataset.load_from_df(valset_20[['userID','itemID','rating']], reader)\n",
    "test_data_20 = Dataset.load_from_df(testset_20[['userID','itemID','rating']], reader)\n",
    "\n",
    "train_data_50 = Dataset.load_from_df(trainset_50[['userID','itemID','rating']], reader)\n",
    "val_data_50 = Dataset.load_from_df(valset_50[['userID','itemID','rating']], reader)\n",
    "test_data_50 = Dataset.load_from_df(testset_50[['userID','itemID','rating']], reader)\n",
    "\n",
    "train_data_100 = Dataset.load_from_df(trainset_100[['userID','itemID','rating']], reader)\n",
    "val_data_100 = Dataset.load_from_df(valset_100[['userID','itemID','rating']], reader)\n",
    "test_data_100 = Dataset.load_from_df(testset_100[['userID','itemID','rating']], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sr_20 = train_data_20.build_full_trainset()\n",
    "val_sr_before_20 = val_data_20.build_full_trainset()\n",
    "val_sr_20 = val_sr_before_20.build_testset()\n",
    "test_sr_before_20 = test_data_20.build_full_trainset()\n",
    "test_sr_20 = test_sr_before_20.build_testset()\n",
    "\n",
    "train_sr_50 = train_data_50.build_full_trainset()\n",
    "val_sr_before_50 = val_data_20.build_full_trainset()\n",
    "val_sr_50 = val_sr_before_20.build_testset()\n",
    "test_sr_before_50 = test_data_50.build_full_trainset()\n",
    "test_sr_50 = test_sr_before_50.build_testset()\n",
    "\n",
    "train_sr_100 = train_data_100.build_full_trainset()\n",
    "val_sr_before_100 = val_data_100.build_full_trainset()\n",
    "val_sr_100 = val_sr_before_100.build_testset()\n",
    "test_sr_before_100 = test_data_100.build_full_trainset()\n",
    "test_sr_100 = test_sr_before_100.build_testset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE_tune = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = [5, 7, 10]  # the number of iteration of the SGD procedure\n",
    "lr_all = [0.002, 0.003, 0.005] # the learning rate for all parameters\n",
    "reg_all =  [0.4, 0.5, 0.6] # the regularization term for all parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.4159\n",
      "RMSE: 1.4173\n",
      "RMSE: 1.4174\n",
      "RMSE: 1.4012\n",
      "RMSE: 1.4016\n",
      "RMSE: 1.4032\n",
      "RMSE: 1.3798\n",
      "RMSE: 1.3807\n",
      "RMSE: 1.3821\n",
      "RMSE: 1.4042\n",
      "RMSE: 1.4047\n",
      "RMSE: 1.4058\n",
      "RMSE: 1.3873\n",
      "RMSE: 1.3885\n",
      "RMSE: 1.3900\n",
      "RMSE: 1.3650\n",
      "RMSE: 1.3665\n",
      "RMSE: 1.3672\n",
      "RMSE: 1.3895\n",
      "RMSE: 1.3903\n",
      "RMSE: 1.3918\n",
      "RMSE: 1.3714\n",
      "RMSE: 1.3735\n",
      "RMSE: 1.3747\n",
      "RMSE: 1.3497\n",
      "RMSE: 1.3508\n",
      "RMSE: 1.3527\n"
     ]
    }
   ],
   "source": [
    "for n in n_epochs:\n",
    "    for l in lr_all:\n",
    "        for r in reg_all:\n",
    "            algo = SVD(n_epochs = n, lr_all = l, reg_all = r)\n",
    "            algo.fit(train_sr_20)\n",
    "            predictions = algo.test(val_sr_20)\n",
    "            RMSE_tune[n,l,r] = accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(5, 0.002, 0.4): 1.415933676012248,\n",
       " (5, 0.002, 0.5): 1.4173365973852405,\n",
       " (5, 0.002, 0.6): 1.417370198820145,\n",
       " (5, 0.003, 0.4): 1.4011758726577428,\n",
       " (5, 0.003, 0.5): 1.4016120313912452,\n",
       " (5, 0.003, 0.6): 1.4031618552800484,\n",
       " (5, 0.005, 0.4): 1.3798484285012471,\n",
       " (5, 0.005, 0.5): 1.3806636393067282,\n",
       " (5, 0.005, 0.6): 1.3821350022120953,\n",
       " (7, 0.002, 0.4): 1.4042009585091328,\n",
       " (7, 0.002, 0.5): 1.4047180140602467,\n",
       " (7, 0.002, 0.6): 1.405780300835095,\n",
       " (7, 0.003, 0.4): 1.3872838266494933,\n",
       " (7, 0.003, 0.5): 1.3885483890855905,\n",
       " (7, 0.003, 0.6): 1.3900448377490269,\n",
       " (7, 0.005, 0.4): 1.3649676001324043,\n",
       " (7, 0.005, 0.5): 1.3665228974538999,\n",
       " (7, 0.005, 0.6): 1.3671758260897764,\n",
       " (10, 0.002, 0.4): 1.3894940834924787,\n",
       " (10, 0.002, 0.5): 1.3903377177304177,\n",
       " (10, 0.002, 0.6): 1.3917867965697626,\n",
       " (10, 0.003, 0.4): 1.3714281812046991,\n",
       " (10, 0.003, 0.5): 1.3734950396997587,\n",
       " (10, 0.003, 0.6): 1.3746840315086657,\n",
       " (10, 0.005, 0.4): 1.3497144262970868,\n",
       " (10, 0.005, 0.5): 1.3507892432826967,\n",
       " (10, 0.005, 0.6): 1.3527005637847467}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RMSE_tune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so the best is when n_epochs = 10, lr_all = 0.005, reg_all = 0.4,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x1c1a0f4b70>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo = SVD(n_epochs = 10, lr_all = 0.005, reg_all = 0.4, random_state = 1)\n",
    "start_time = time.time()\n",
    "algo.fit(train_sr_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 22.90842628479004 seconds ---\n"
     ]
    }
   ],
   "source": [
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.3985\n",
      "R^2 (with 50% data):  -0.0005168104941091212\n",
      "MAE (with 50% data):  1.3130548262648378\n",
      "--- 0.058664798736572266 seconds ---\n"
     ]
    }
   ],
   "source": [
    "prediction_20 = algo.test(test_sr_20)\n",
    "prediction_20_df = pd.DataFrame(prediction_20, columns = ['userId','itemId','rating','pred_rating','x'])\n",
    "start_time = time.time()\n",
    "accuracy.rmse(predictions_20)\n",
    "print('R^2 (with 50% data): ', r2_score(prediction_20_df.rating , prediction_20_df.pred_rating))\n",
    "print('MAE (with 50% data): ', mean_absolute_error(prediction_20_df.rating, prediction_20_df.pred_rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.38172292709350586 seconds ---\n"
     ]
    }
   ],
   "source": [
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x1be7d1b390>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo = SVD(n_epochs = 10, lr_all = 0.005, reg_all = 0.4, random_state = 1)\n",
    "start_time = time.time()\n",
    "algo.fit(train_sr_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 60.414530754089355 seconds ---\n"
     ]
    }
   ],
   "source": [
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.3795\n",
      "R^2 (with 50% data):  0.17579827157194183\n",
      "MAE (with 50% data):  1.1636053411757143\n",
      "--- 0.22292780876159668 seconds ---\n"
     ]
    }
   ],
   "source": [
    "prediction_50 = algo.test(test_sr_50)\n",
    "start_time = time.time()\n",
    "prediction_50_df = pd.DataFrame(prediction_50, columns = ['userId','itemId','rating','pred_rating','x'])\n",
    "accuracy.rmse(predictions_50)\n",
    "print('R^2 (with 50% data): ', r2_score(prediction_50_df.rating , prediction_50_df.pred_rating))\n",
    "print('MAE (with 50% data): ', mean_absolute_error(prediction_50_df.rating, prediction_50_df.pred_rating))\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x1be7d1bb00>"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo = SVD(n_epochs = 10, lr_all = 0.005, reg_all = 0.4, random_state = 1)\n",
    "start_time = time.time()\n",
    "algo.fit(train_sr_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 112.2750883102417 seconds ---\n"
     ]
    }
   ],
   "source": [
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.4097\n",
      "R^2 (with 100% data):  0.14071587483799064\n",
      "MAE (with 100% data):  1.1899410508462416\n",
      "--- 0.39083409309387207 seconds ---\n"
     ]
    }
   ],
   "source": [
    "prediction_100 = algo.test(test_sr_100)\n",
    "start_time = time.time()\n",
    "prediction_100_df = pd.DataFrame(prediction_100, columns = ['userId','itemId','rating','pred_rating','x'])\n",
    "accuracy.rmse(prediction_100)\n",
    "print('R^2 (with 100% data): ', r2_score(prediction_100_df.rating , prediction_100_df.pred_rating))\n",
    "print('MAE (with 100% data): ', mean_absolute_error(prediction_100_df.rating, prediction_100_df.pred_rating))\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = SVD(n_epochs = 10, lr_all = 0.005, reg_all = 0.4, random_state = 1)\n",
    "eval_before_50 = eval_50.build_full_trainset()\n",
    "eval_sr_50 = eval_before_50.build_testset()\n",
    "algo.fit(train_sr_50)\n",
    "eval_pred_50 = algo.test(eval_sr_50)\n",
    "#accuracy.rmse(predictions_50)\n",
    "baseline_50 = pd.DataFrame(eval_pred_50, columns = ['userId','itemId','rating','pred_rating','x'])\n",
    "\n",
    "algo = SVD(n_epochs = 10, lr_all = 0.005, reg_all = 0.4, random_state = 1)\n",
    "eval_before_100 = eval_100.build_full_trainset()\n",
    "eval_sr_100 = eval_before_100.build_testset()\n",
    "algo.fit(train_sr_100)\n",
    "eval_pred_100 = algo.test(eval_sr_100)\n",
    "#accuracy.rmse(predictions_100)\n",
    "baseline_100 = pd.DataFrame(eval_pred_100, columns = ['userId','itemId','rating','pred_rating','x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_metrics(predict_df, validation_subsample, ratings_train_final):\n",
    "    top_10_recs = predict_df.groupby(['user_id','city'])['predictions'].nlargest(10).reset_index()\n",
    "    out = validation_subsample\n",
    "    cnt =0\n",
    "    serendipity = 0\n",
    "    \n",
    "    \n",
    "    for row in out.iterrows():\n",
    "        row_values = row[1]\n",
    "        top_10 = predict_df.loc[top_10_recs[top_10_recs['user_id'] == row_values['user_id']].level_2]['business_id']\n",
    "        ###In top 10\n",
    "        if row_values['business_id'] in top_10.values:\n",
    "            cnt+=1\n",
    "        user_history = ratings_train_final[ratings_train_final['user_id'] == row_values['user_id']]    \n",
    "        been_there = [i for i in top_10.values if i in  user_history.business_id.values]\n",
    "        serendipity += 1-len(been_there)/10\n",
    "    \n",
    "    top_10 = cnt/len(out)\n",
    "    serendipity = serendipity/len(out)\n",
    "    \n",
    "    predict_df = predict_df.reset_index()\n",
    "    \n",
    "    analysis_df = predict_df.merge(top_10_recs, left_on = ['user_id','city','index'], right_on = ['user_id','city','level_2'])\n",
    "    \n",
    "    coverage = (analysis_df.groupby('city')['business_id'].nunique()/50).values.mean()\n",
    "    \n",
    "    predict_df['rankings']=predict_df.groupby(['city','user_id'])['predictions'].rank(\"first\",ascending = False)\n",
    "    running_rankings =0\n",
    "    for row in out.iterrows():\n",
    "        row_values = row[1]\n",
    "        user_recs = predict_df[(predict_df['user_id']==row_values['user_id'])\n",
    "                            &(predict_df['city']==row_values['city'])\n",
    "                             & (predict_df['business_id']==row_values['business_id'])\n",
    "                              ]\n",
    "        #assert len(user_recs)==1\n",
    "        running_rankings += user_recs['rankings'].sum()\n",
    "\n",
    "    avg_rank = running_rankings / len(out)\n",
    "    print(top_10, coverage, serendipity, avg_rank)\n",
    "    \n",
    "    return top_10, coverage, serendipity, avg_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10714285714285714 0.503095238095238 0.9697619047619042 528.3333333333334\n"
     ]
    }
   ],
   "source": [
    "top_10, coverage, serendipity, avg_rank = get_all_metrics(predict_df_20, out_20, ratings_train_final_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12678571428571428 0.2 0.9799999999999989 422.8767857142857\n"
     ]
    }
   ],
   "source": [
    "top_10, coverage, serendipity, avg_rank = get_all_metrics(predict_df_50, out_50, ratings_train_final_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.014516129032258065 0.2 0.9983870967741933 6.670967741935484\n"
     ]
    }
   ],
   "source": [
    "top_10, coverage, serendipity, avg_rank = get_all_metrics(predict_df_100, out_100, ratings_train_final_100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collective Matrix Factorization\n",
    "\n",
    "To best the baseline (which in our case, is Matrix Factorization), we first tried the Collective Matrix Factorization technique. This means that, in addition to the ratings, we also want to include additional features on either the items or the users, to see how the model perform. Before we discussed what additional features we included, we might say a few words on the method and its mathematical intuition.\n",
    "\n",
    "Similar to Matrix Factorization, Collective Matrix Factorization also aims to decompose, but in this time, we are decomposing two matrices $X$ and $Y$ into three matrices $U$, $V$, and $Z$, such that $X \\approx f(UV^T)$ and $Y \\approx f(VZ^T)$. Here, X can be the same matrix we see in the case of Matrix Factorization, i.e., a simple user-item matrix filled by ratings. And matrix Y is the matrix of additional features. It can be on user or on item. And the features can be one-hot encoded (i.e., categorical) or numerical. For example, in our case, we both involved state location for businesses (which is a categorical feature) and the average rating (which is a numerical feature).\n",
    "\n",
    "Collective Matrix Factorization also has a function to minimize, and we will explain the function through the lens of the python cmfrec package, which is the package that we used to implement Collective Matrix Factorization. The function to minimize is as follows:\n",
    "\n",
    "$ argmin_{A, B, C, D, U_b, I_b} \\lVert (X − \\mu − U_b − I_b − AB^T)I_{x} \\lVert^2 + \\lVert U − AC^T \\lVert^2 + \\lVert I − BD^T \\lVert^2 + \\lambda (\\lVert A\\lVert^2 + \\lVert B \\lVert^2 + \\lVert C \\lVert^2 + \\lVert D \\lVert^2  + \\lVert U_b \\lVert^2 + \\lVert I_b \\lVert^2)$\n",
    "\n",
    "Where X is the ratings matrix, I is the item-attribute matrix, U is the user-attribute matrix, and A,B,C,D are lower-dimensional matrices. $ |X| $, $|I|$, $|U|$ are the number of non-missing entries in each matrix. And $ Ubias_{u}$ and $Ibias_{i}$ are user and item biases. Thus, for such a reason, when tuning, we tune w_main and w_item when we are including additional item features and we tune w_main and w_user when we are including additional user features.\n",
    "\n",
    "Now, with CMF, we implemented three approaches in total- state average rating, state location, and user average rating. The idea is as follows:\n",
    "We first included state average rating as an item additional feature. Since our objective here is to predict the last rating for each active user, we wanted to see if location can be a useful means to bring closer the predicted ratings to the actual ones. To better utilize the location feature though, we came up with two approaches. One is to calculate the state average rating, and the other is to use state location as a categorical feature. With the state average rating, we wanted to observe if some states can have a higher average rating than others. This means that either the restaurants in that state are significantly better or the users in that state are more lenient and friendly. From EDA alone, the average rating seems to make some sense, as we observed that California has the highest state average rating (though with much fewer data observations) and New York has the lowest (same, with much fewer data observations than AZ and NV). This might suggest that, even though New York (especially manhattan area) is known as a food hub, the yelp users here can be a little picky and critical, whereas the users in CA can be more friendly. By all means though, we wanted to see if this “secondary” information that we generated for ourselves can help better predict the result.\n",
    "\n",
    "With the second approach on the location feature, we simply fed in the one-hot encoded columns. This time, we just want to see if the location itself, as a categorical feature, can bring us any closer to the actual value.\n",
    "\n",
    "Lastly, we also did a user average rating for the user info. This is similar to the state average rating approach, but we just wanted to see if by directly analyzing the users’ behaviors, that normally how critical they are with the restaurants, can help us better understand them and have a better predicted result than other approaches. To notice here though, we didn’t use the given average rating, since that would include the last rating that we were trying to predict; thus, we had to hand-calculated the average rating again on the training set. We also wanted to include the yelp spending time, that is the time they been using yelp and see if this can help us better predict the result. But due to the time constraint, we are not able to implement. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for cmfrec package\n",
    "# universal X_train_20, 50, 100\n",
    "X_train_20 = trainset_20\n",
    "X_train_20.columns = ['UserId','ItemId','Rating']\n",
    "\n",
    "X_train_50 = trainset_50\n",
    "X_train_50.columns = ['UserId','ItemId','Rating']\n",
    "\n",
    "X_train_100 = trainset_100\n",
    "X_train_100.columns = ['UserId','ItemId','Rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# universal X_test_20, 50, 100\n",
    "X_test_20 = testset_20\n",
    "X_test_20.columns = ['UserId','ItemId','Rating']\n",
    "\n",
    "X_test_50 = testset_50\n",
    "X_test_50.columns = ['UserId','ItemId','Rating']\n",
    "\n",
    "X_test_100 = testset_100\n",
    "X_test_100.columns = ['UserId','ItemId','Rating']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 1: State Average Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get state average rating\n",
    "state_avg_20 = pd.DataFrame(ratings_train_20.groupby(\"state\").rating.mean())\n",
    "state_avg_20.columns = ['state_avg']\n",
    "train_state_avg_20 = ratings_train_20.merge(state_avg_20, on = \"state\")\n",
    "\n",
    "state_avg_50 = pd.DataFrame(ratings_train_50.groupby(\"state\").rating.mean())\n",
    "state_avg_50.columns = ['state_avg']\n",
    "train_state_avg_50 = ratings_train_50.merge(state_avg_50, on = \"state\")\n",
    "\n",
    "state_avg_100 = pd.DataFrame(ratings_train_100.groupby(\"state\").rating.mean())\n",
    "state_avg_100.columns = ['state_avg']\n",
    "train_state_avg_100 = ratings_train_100.merge(state_avg_100, on = \"state\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# item additional info: state average\n",
    "item_avg_20 = train_state_avg_20.loc[:,['business_id','state_avg']]\n",
    "item_avg_20.columns = ['ItemId','state_avg']\n",
    "\n",
    "item_avg_50 = train_state_avg_50.loc[:,['business_id','state_avg']]\n",
    "item_avg_50.columns = ['ItemId','state_avg']\n",
    "\n",
    "item_avg_100 = train_state_avg_100.loc[:,['business_id','state_avg']]\n",
    "item_avg_100.columns = ['ItemId','state_avg']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "tune = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_main = [0.5, 5.0, 10.0] # weight assign to the MRSE in factorization of the ratings matrix\n",
    "w_item = [0.5, 5.0, 10.0][::-1] # weight assign to the MRSE in factorization of the item attributes matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "  Objective function value: 0.951550\n",
      "  Number of iterations: 378\n",
      "  Number of functions evaluations: 429\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "  Objective function value: 0.951519\n",
      "  Number of iterations: 307\n",
      "  Number of functions evaluations: 351\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.950972\n",
      "  Number of iterations: 99\n",
      "  Number of functions evaluations: 110\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
      "  Objective function value: 6.175318\n",
      "  Number of iterations: 1000\n",
      "  Number of functions evaluations: 1077\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
      "  Objective function value: 6.163224\n",
      "  Number of iterations: 1000\n",
      "  Number of functions evaluations: 1067\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
      "  Objective function value: 6.151421\n",
      "  Number of iterations: 1000\n",
      "  Number of functions evaluations: 1050\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
      "  Objective function value: 8.763368\n",
      "  Number of iterations: 1000\n",
      "  Number of functions evaluations: 1060\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
      "  Objective function value: 8.714961\n",
      "  Number of iterations: 1000\n",
      "  Number of functions evaluations: 1053\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
      "  Objective function value: 8.669455\n",
      "  Number of iterations: 1000\n",
      "  Number of functions evaluations: 1043\n"
     ]
    }
   ],
   "source": [
    "# tuning\n",
    "for m in w_main:\n",
    "    for i in w_item:\n",
    "        model = CMF(w_main = m, w_item = i, random_seed = 1)\n",
    "        model.fit(ratings = deepcopy(X_train_20), item_info = deepcopy(item_avg_20))\n",
    "        prediction = model.predict(X_val_20.UserId, X_val_20.ItemId)\n",
    "        X_val_20['pred_rating'] = prediction\n",
    "        tune[m,i] = np.sqrt(np.mean((X_val_20.pred_rating - X_val_20.Rating)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0.5, 10.0): 1.4095315793715344,\n",
       " (0.5, 5.0): 1.4095280852831702,\n",
       " (0.5, 0.5): 1.4095288030679354,\n",
       " (5.0, 10.0): 1.325081092000988,\n",
       " (5.0, 5.0): 1.3249653813051294,\n",
       " (5.0, 0.5): 1.325319757480712,\n",
       " (10.0, 10.0): 1.3303194326966257,\n",
       " (10.0, 5.0): 1.3291943801778212,\n",
       " (10.0, 0.5): 1.329444185787565}"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Best param: w_main = 5.0, w_item = 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
      "  Objective function value: 6.163018\n",
      "  Number of iterations: 1000\n",
      "  Number of functions evaluations: 1048\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<cmfrec.CMF at 0x1b80676f60>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 20%\n",
    "model = CMF(w_main = 5.0, w_item = 5.0, random_seed = 1)\n",
    "start_time = time.time()\n",
    "model.fit(ratings = deepcopy(X_train_20), item_info = deepcopy(item_avg_20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 824.5971691608429 seconds ---\n"
     ]
    }
   ],
   "source": [
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_20 = X_test_20.loc[X_test_20.ItemId.isin(X_train_20.ItemId)]\n",
    "X_test_50 = X_test_50.loc[X_test_50.ItemId.isin(X_train_50.ItemId)]\n",
    "X_test_100 = X_test_100.loc[X_test_100.ItemId.isin(X_train_100.ItemId)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE (with 20% data):  1.3495188130540272\n",
      "R^2 (with 20% data):  0.18677513147304292\n",
      "MAE (with 20% data):  1.1202827761356042\n"
     ]
    }
   ],
   "source": [
    "state_prediction_20 = model.predict(X_test_20.UserId, X_test_20.ItemId)\n",
    "X_test_20['pred_rating'] = state_prediction_20\n",
    "print('RMSE (with 20% data): ', np.sqrt(np.mean((X_test_20.pred_rating - X_test_20.Rating)**2)))\n",
    "print('R^2 (with 20% data): ', r2_score(X_test_20.Rating ,X_test_20.pred_rating))\n",
    "print('MAE (with 20% data): ', mean_absolute_error(X_test_20.Rating, X_test_20.pred_rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
      "  Objective function value: 7.329828\n",
      "  Number of iterations: 1000\n",
      "  Number of functions evaluations: 1070\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<cmfrec.CMF at 0x2089df7a90>"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 50%\n",
    "model = CMF(w_main = 5.0, w_item = 5.0, random_seed = 1)\n",
    "start_time = time.time()\n",
    "model.fit(ratings = deepcopy(X_train_50), item_info = deepcopy(item_avg_50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1569.4463019371033 seconds ---\n"
     ]
    }
   ],
   "source": [
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE (with 50% data):  1.3721222242704587\n",
      "R^2 (with 50% data):  0.1782666934054964\n",
      "MAE (with 50% data):  1.1524687846675643\n"
     ]
    }
   ],
   "source": [
    "state_prediction_50 = model.predict(X_test_50.UserId, X_test_50.ItemId)\n",
    "X_test_50['pred_rating'] = state_prediction_50\n",
    "print('RMSE (with 50% data): ', np.sqrt(np.mean((X_test_50.pred_rating - X_test_50.Rating)**2)))\n",
    "print('R^2 (with 50% data): ', r2_score(X_test_50.Rating, X_test_50.pred_rating))\n",
    "print('MAE (with 50% data): ', mean_absolute_error(X_test_50.Rating,X_test_50.pred_rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bowenzhou/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gradients_impl.py:107: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 123108660 elements. This may consume a large amount of memory.\n",
      "  num_elements)\n"
     ]
    }
   ],
   "source": [
    "# 100%\n",
    "model = CMF(w_main = 5.0, w_item = 5.0, random_seed = 1)\n",
    "start_time = time.time()\n",
    "model.fit(ratings = deepcopy(X_train_100), item_info = deepcopy(item_avg_100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_prediction_100 = model.predict(X_test_100.UserId, X_test_100.ItemId)\n",
    "X_test_100['pred_rating'] = state_prediction_100\n",
    "print('RMSE (with 100% data): ', np.sqrt(np.mean((X_test_100.pred_rating - X_test_100.Rating)**2)))\n",
    "print('R^2 (with 100% data): ', r2_score(X_test_100.Rating , X_test_100.pred_rating))\n",
    "print('MAE (with 100% data): ', mean_absolute_error(X_test_100.Rating , X_test_100.pred_rating))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>business_id</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4_rUho9z3p91M1r9hqA7Bg</td>\n",
       "      <td>Ajax</td>\n",
       "      <td>ON</td>\n",
       "      <td>8AW0koYMDa1PlJMOE-b2-g</td>\n",
       "      <td>3.237104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4_rUho9z3p91M1r9hqA7Bg</td>\n",
       "      <td>Ajax</td>\n",
       "      <td>ON</td>\n",
       "      <td>-YGQwikbX2fXUIjyegR7pw</td>\n",
       "      <td>3.680566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4_rUho9z3p91M1r9hqA7Bg</td>\n",
       "      <td>Ajax</td>\n",
       "      <td>ON</td>\n",
       "      <td>5Kh5i4VhXj-Leg8gujIzjQ</td>\n",
       "      <td>3.642935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4_rUho9z3p91M1r9hqA7Bg</td>\n",
       "      <td>Ajax</td>\n",
       "      <td>ON</td>\n",
       "      <td>Wl1oOVbtK4I9vRKoaSKYiQ</td>\n",
       "      <td>3.359295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4_rUho9z3p91M1r9hqA7Bg</td>\n",
       "      <td>Ajax</td>\n",
       "      <td>ON</td>\n",
       "      <td>OxSaGGTmIujsjDpDqwyGPQ</td>\n",
       "      <td>3.437118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  user_id  city state             business_id  predictions\n",
       "0  4_rUho9z3p91M1r9hqA7Bg  Ajax    ON  8AW0koYMDa1PlJMOE-b2-g     3.237104\n",
       "1  4_rUho9z3p91M1r9hqA7Bg  Ajax    ON  -YGQwikbX2fXUIjyegR7pw     3.680566\n",
       "2  4_rUho9z3p91M1r9hqA7Bg  Ajax    ON  5Kh5i4VhXj-Leg8gujIzjQ     3.642935\n",
       "3  4_rUho9z3p91M1r9hqA7Bg  Ajax    ON  Wl1oOVbtK4I9vRKoaSKYiQ     3.359295\n",
       "4  4_rUho9z3p91M1r9hqA7Bg  Ajax    ON  OxSaGGTmIujsjDpDqwyGPQ     3.437118"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_df_20.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/bowenzhou/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/bowenzhou/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/losses/losses_impl.py:667: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /Users/bowenzhou/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
      "  Objective function value: 6.163224\n",
      "  Number of iterations: 1000\n",
      "  Number of functions evaluations: 1067\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
      "  Objective function value: 7.329798\n",
      "  Number of iterations: 1000\n",
      "  Number of functions evaluations: 1069\n"
     ]
    }
   ],
   "source": [
    "model = CMF(w_main = 5.0, w_item = 5.0, random_seed = 1)\n",
    "model.fit(ratings = deepcopy(X_train_20), item_info = deepcopy(item_avg_20))\n",
    "predict_df_20['predictions'] = model.predict(predict_df_20.user_id, predict_df_20.business_id)\n",
    "\n",
    "model = CMF(w_main = 5.0, w_item = 5.0, random_seed = 1)\n",
    "model.fit(ratings = deepcopy(X_train_50), item_info = deepcopy(item_avg_50))\n",
    "predict_df_50['predictions'] = model.predict(predict_df_50.user_id, predict_df_50.business_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CMF(w_main = m, w_item = i, random_seed = 1)\n",
    "model.fit(ratings = deepcopy(X_train_100), item_info = deepcopy(item_avg_100))\n",
    "predict_df_100['predictions'] = model.predict(predict_df_100.user_id, predict_df_100.business_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13095238095238096 0.2609523809523809 0.9695238095238087 484.93809523809523\n"
     ]
    }
   ],
   "source": [
    "top_10, coverage, serendipity, avg_rank = get_all_metrics(predict_df_20, out_20, ratings_train_final_20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18035714285714285 0.2041071428571429 0.9792857142857132 448.2767857142857\n"
     ]
    }
   ],
   "source": [
    "top_10, coverage, serendipity, avg_rank = get_all_metrics(predict_df_50, out_50, ratings_train_final_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-211-e6d22498687e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtop_10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoverage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserendipity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_rank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_all_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict_df_100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mratings_train_final_100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-210-031c8badda4b>\u001b[0m in \u001b[0;36mget_all_metrics\u001b[0;34m(predict_df, validation_subsample, ratings_train_final)\u001b[0m\n\u001b[1;32m     31\u001b[0m         user_recs = predict_df[(predict_df['user_id']==row_values['user_id'])\n\u001b[1;32m     32\u001b[0m                             \u001b[0;34m&\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'city'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mrow_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'city'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                              \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredict_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'business_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mrow_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'business_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m                               ]\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m#assert len(user_recs)==1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, other, axis)\u001b[0m\n\u001b[1;32m   1764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1765\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1766\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mna_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1767\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1768\u001b[0m                 raise TypeError('Could not compare {typ} type with Series'\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mna_op\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1624\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1625\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_comp_method_OBJECT_ARRAY\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1626\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1627\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_datetimelike_v_numeric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36m_comp_method_OBJECT_ARRAY\u001b[0;34m(op, x, y)\u001b[0m\n\u001b[1;32m   1601\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvec_compare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1602\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1603\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscalar_compare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1604\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1605\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "top_10, coverage, serendipity, avg_rank = get_all_metrics(predict_df_100, out_100, ratings_train_final_100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 2: State Location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Transforming Data and Tunning for Surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encode\n",
    "df_state_20 = pd.get_dummies(ratings_train_20.state)\n",
    "df_state_50 = pd.get_dummies(ratings_train_50.state)\n",
    "df_state_100 = pd.get_dummies(ratings_train_100.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_loc_20 = ratings_train_20.loc[:,['business_id']]\n",
    "state_loc_20.columns = ['ItemId']\n",
    "state_loc_20 = state_loc_20.join(df_state_20)\n",
    "\n",
    "state_loc_50 = ratings_train_50.loc[:,['business_id']]\n",
    "state_loc_50.columns = ['ItemId']\n",
    "state_loc_50 = state_loc_50.join(df_state_50)\n",
    "\n",
    "state_loc_100 = ratings_train_100.loc[:,['business_id']]\n",
    "state_loc_100.columns = ['ItemId']\n",
    "state_loc_100 = state_loc_100.join(df_state_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "tune_2 = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_main = [0.5, 5.0, 10.0] # weight assign to the MRSE in factorization of the ratings matrix\n",
    "w_item = [0.5, 5.0, 10.0][::-1] # weight assign to the MRSE in factorization of the item attributes matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 1.502233\n",
      "  Number of iterations: 48\n",
      "  Number of functions evaluations: 59\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 1.345407\n",
      "  Number of iterations: 49\n",
      "  Number of functions evaluations: 61\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.946406\n",
      "  Number of iterations: 46\n",
      "  Number of functions evaluations: 58\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
      "  Objective function value: 6.707548\n",
      "  Number of iterations: 1000\n",
      "  Number of functions evaluations: 1050\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
      "  Objective function value: 6.544841\n",
      "  Number of iterations: 1000\n",
      "  Number of functions evaluations: 1054\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
      "  Objective function value: 6.147314\n",
      "  Number of iterations: 1000\n",
      "  Number of functions evaluations: 1050\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
      "  Objective function value: 9.238955\n",
      "  Number of iterations: 1000\n",
      "  Number of functions evaluations: 1047\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
      "  Objective function value: 9.068397\n",
      "  Number of iterations: 1000\n",
      "  Number of functions evaluations: 1045\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
      "  Objective function value: 8.660084\n",
      "  Number of iterations: 1000\n",
      "  Number of functions evaluations: 1044\n"
     ]
    }
   ],
   "source": [
    "# tuning\n",
    "for m in w_main:\n",
    "    for i in w_item:\n",
    "        model = CMF(w_main = m, w_item = i, random_seed = 1)\n",
    "        model.fit(ratings = deepcopy(X_train_20), item_info = deepcopy(state_loc_20),\\\n",
    "            cols_bin_item=[cl for cl in state_loc_20.columns if cl != 'ItemId'])\n",
    "        prediction = model.predict(X_val_20.UserId, X_val_20.ItemId)\n",
    "        X_val_20['pred_rating'] = prediction\n",
    "        tune_2[m,i] = np.sqrt(np.mean((X_val_20.pred_rating - X_val_20.Rating)**2))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0.5, 10.0): 1.4091453521706512,\n",
       " (0.5, 5.0): 1.4093103607696387,\n",
       " (0.5, 0.5): 1.4096837868418028,\n",
       " (5.0, 10.0): 1.3255848781332549,\n",
       " (5.0, 5.0): 1.3253454951331827,\n",
       " (5.0, 0.5): 1.3255074066479042,\n",
       " (10.0, 10.0): 1.3287372061500575,\n",
       " (10.0, 5.0): 1.3285188529615481,\n",
       " (10.0, 0.5): 1.3288867514741107}"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the best param: w_main = 5.0, w_item = 5.0\n",
    "tune_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_20 = X_test_20.loc[X_test_20.ItemId.isin(X_train_20.ItemId)]\n",
    "X_test_50 = X_test_50.loc[X_test_50.ItemId.isin(X_train_50.ItemId)]\n",
    "X_test_100 = X_test_100.loc[X_test_100.ItemId.isin(X_train_100.ItemId)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ItemId</th>\n",
       "      <th>AB</th>\n",
       "      <th>AL</th>\n",
       "      <th>AR</th>\n",
       "      <th>AZ</th>\n",
       "      <th>BC</th>\n",
       "      <th>CA</th>\n",
       "      <th>CT</th>\n",
       "      <th>FL</th>\n",
       "      <th>GA</th>\n",
       "      <th>...</th>\n",
       "      <th>NY</th>\n",
       "      <th>OH</th>\n",
       "      <th>ON</th>\n",
       "      <th>PA</th>\n",
       "      <th>QC</th>\n",
       "      <th>SC</th>\n",
       "      <th>TX</th>\n",
       "      <th>VA</th>\n",
       "      <th>WA</th>\n",
       "      <th>WI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WTqjgwHlXbSFevF32_DJVw</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WTqjgwHlXbSFevF32_DJVw</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WTqjgwHlXbSFevF32_DJVw</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WTqjgwHlXbSFevF32_DJVw</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WTqjgwHlXbSFevF32_DJVw</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ItemId  AB  AL  AR  AZ  BC  CA  CT  FL  GA  ...  NY  OH  \\\n",
       "0  WTqjgwHlXbSFevF32_DJVw   0   0   0   1   0   0   0   0   0  ...   0   0   \n",
       "1  WTqjgwHlXbSFevF32_DJVw   0   0   0   1   0   0   0   0   0  ...   0   0   \n",
       "2  WTqjgwHlXbSFevF32_DJVw   0   0   0   1   0   0   0   0   0  ...   0   0   \n",
       "3  WTqjgwHlXbSFevF32_DJVw   0   0   0   1   0   0   0   0   0  ...   0   0   \n",
       "4  WTqjgwHlXbSFevF32_DJVw   0   0   0   1   0   0   0   0   0  ...   0   0   \n",
       "\n",
       "   ON  PA  QC  SC  TX  VA  WA  WI  \n",
       "0   0   0   0   0   0   0   0   0  \n",
       "1   0   0   0   0   0   0   0   0  \n",
       "2   0   0   0   0   0   0   0   0  \n",
       "3   0   0   0   0   0   0   0   0  \n",
       "4   0   0   0   0   0   0   0   0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_loc_50.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
      "  Objective function value: 6.545013\n",
      "  Number of iterations: 1000\n",
      "  Number of functions evaluations: 1050\n",
      "--- 846.5123789310455 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# 20%\n",
    "model = CMF(w_main = 5.0, w_item = 5.0, random_seed = 1)\n",
    "start_time = time.time()\n",
    "model.fit(ratings = deepcopy(X_train_20), item_info = deepcopy(state_loc_20),\\\n",
    "            cols_bin_item=[cl for cl in state_loc_20.columns if cl != 'ItemId'])\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE (with 20% data):  1.3496651740914456\n",
      "R^2 (with 20% data):  0.18659872653728782\n",
      "MAE (with 20% data):  1.1201697481001782\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "loc_prediction_20 = model.predict(X_test_20.UserId, X_test_20.ItemId)\n",
    "X_test_20['pred_rating'] = loc_prediction_20\n",
    "print('RMSE (with 20% data): ', np.sqrt(np.mean((X_test_20.pred_rating - X_test_20.Rating)**2)))\n",
    "print('R^2 (with 20% data): ', r2_score(X_test_20.Rating , X_test_20.pred_rating))\n",
    "print('MAE (with 20% data): ', mean_absolute_error(X_test_20.Rating , X_test_20.pred_rating))\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "  Objective function value: 7.754635\n",
      "  Number of iterations: 424\n",
      "  Number of functions evaluations: 457\n",
      "--- 890.4706201553345 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# 50%\n",
    "model = CMF(w_main = 5.0, w_item = 5.0, random_seed = 1)\n",
    "start_time = time.time()\n",
    "model.fit(ratings = deepcopy(X_train_50), item_info = deepcopy(state_loc_50),\\\n",
    "            cols_bin_item=[cl for cl in state_loc_50.columns if cl != 'ItemId'])\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE (with 50% data):  1.3718431111368456\n",
      "R^2 (with 50% data):  0.17860096862767105\n",
      "MAE (with 50% data):  1.152111041520463\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "loc_prediction_50 = model.predict(X_test_50.UserId, X_test_50.ItemId)\n",
    "X_test_50['pred_rating'] = loc_prediction_50\n",
    "print('RMSE (with 50% data): ', np.sqrt(np.mean((X_test_50.pred_rating - X_test_50.Rating)**2)))\n",
    "print('R^2 (with 50% data): ', r2_score(X_test_50.Rating , X_test_50.pred_rating))\n",
    "print('MAE (with 50% data): ', mean_absolute_error(X_test_50.Rating , X_test_50.pred_rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.23462414741516113 seconds ---\n"
     ]
    }
   ],
   "source": [
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100%\n",
    "model = CMF(w_main = m, w_item = i, random_seed = 1)\n",
    "start_time = time.time()\n",
    "model.fit(ratings = deepcopy(X_train_100), item_info = deepcopy(item_state_avg_100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_prediction_100 = model.predict(X_test_100.user_id, X_test_100.business_id)\n",
    "X_test_100['pred_rating'] = loc_prediction_100\n",
    "print('RMSE (with 100% data): ', np.sqrt(np.mean((X_test_100.pred_rating - X_test_100.rating)**2)))\n",
    "print('R^2 (with 100% data): ', r2_score(X_test_100.rating - X_test_100.pred_rating))\n",
    "print('MAE (with 100% data): ', mean_absolute_error((X_test_100.rating - X_test_100.pred_rating))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
      "  Objective function value: 6.545013\n",
      "  Number of iterations: 1000\n",
      "  Number of functions evaluations: 1050\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "  Objective function value: 7.754635\n",
      "  Number of iterations: 424\n",
      "  Number of functions evaluations: 457\n"
     ]
    }
   ],
   "source": [
    "model = CMF(w_main = 5.0, w_item = 5.0, random_seed = 1)\n",
    "model.fit(ratings = deepcopy(X_train_20), item_info = deepcopy(state_loc_20),\\\n",
    "            cols_bin_item=[cl for cl in state_loc_20.columns if cl != 'ItemId'])\n",
    "predict_df_20['predictions'] = model.predict(predict_df_20.user_id, predict_df_20.business_id)\n",
    "\n",
    "model = CMF(w_main = 5.0, w_item = 5.0, random_seed = 1)\n",
    "model.fit(ratings = deepcopy(X_train_50), item_info = deepcopy(state_loc_50),\\\n",
    "            cols_bin_item=[cl for cl in state_loc_50.columns if cl != 'ItemId'])\n",
    "predict_df_50['predictions'] = model.predict(predict_df_50.user_id, predict_df_50.business_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13095238095238096 0.2602380952380952 0.9692857142857138 473.73571428571427\n"
     ]
    }
   ],
   "source": [
    "top_10, coverage, serendipity, avg_rank = get_all_metrics(predict_df_20, out_20, ratings_train_final_20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18035714285714285 0.20500000000000004 0.979285714285713 444.30357142857144\n"
     ]
    }
   ],
   "source": [
    "top_10, coverage, serendipity, avg_rank = get_all_metrics(predict_df_50, out_50, ratings_train_final_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10, coverage, serendipity, avg_rank = get_all_metrics(predict_df_100, out_100, ratings_train_final_100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 3: User Average Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get state average rating\n",
    "user_avg_20 = pd.DataFrame(ratings_train_20.groupby(\"user_id\").rating.mean())\n",
    "user_avg_20.columns = ['user_avg']\n",
    "user_avg_20 = ratings_train_20.merge(user_avg_20, on = \"user_id\")\n",
    "\n",
    "user_avg_50 = pd.DataFrame(ratings_train_50.groupby(\"user_id\").rating.mean())\n",
    "user_avg_50.columns = ['user_avg']\n",
    "user_avg_50 = ratings_train_50.merge(user_avg_50, on = \"user_id\")\n",
    "\n",
    "user_avg_100 = pd.DataFrame(ratings_train_100.groupby(\"user_id\").rating.mean())\n",
    "user_avg_100.columns = ['user_avg']\n",
    "user_avg_100 = ratings_train_100.merge(user_avg_100, on = \"user_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user additional info: user average\n",
    "user_info_20 = user_avg_20.loc[:,['user_id','user_avg']]\n",
    "user_info_20.columns = ['UserId','state_avg']\n",
    "\n",
    "user_info_50 = user_avg_50.loc[:,['user_id','user_avg']]\n",
    "user_info_50.columns = ['UserId','state_avg']\n",
    "\n",
    "user_info_100 = user_avg_100.loc[:,['user_id','user_avg']]\n",
    "user_info_100.columns = ['UserId','state_avg']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "tune_3 = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_main = [0.5, 5.0, 10.0] # weight assign to the MRSE in factorization of the ratings matrix\n",
    "w_user = [0.5, 5.0, 10.0][::-1] # weight assign to the MRSE in factorization of the user attributes matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "  Objective function value: 0.912842\n",
      "  Number of iterations: 463\n",
      "  Number of functions evaluations: 530\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "  Objective function value: 0.912821\n",
      "  Number of iterations: 378\n",
      "  Number of functions evaluations: 436\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.912564\n",
      "  Number of iterations: 131\n",
      "  Number of functions evaluations: 147\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
      "  Objective function value: 6.144692\n",
      "  Number of iterations: 1000\n",
      "  Number of functions evaluations: 1085\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
      "  Objective function value: 6.126369\n",
      "  Number of iterations: 1000\n",
      "  Number of functions evaluations: 1064\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
      "  Objective function value: 6.111398\n",
      "  Number of iterations: 1000\n",
      "  Number of functions evaluations: 1046\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
      "  Objective function value: 8.808755\n",
      "  Number of iterations: 1000\n",
      "  Number of functions evaluations: 1096\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
      "  Objective function value: 8.702769\n",
      "  Number of iterations: 1000\n",
      "  Number of functions evaluations: 1061\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
      "  Objective function value: 8.629791\n",
      "  Number of iterations: 1000\n",
      "  Number of functions evaluations: 1034\n"
     ]
    }
   ],
   "source": [
    "# tuning\n",
    "for m in w_main:\n",
    "    for i in w_user:\n",
    "        model = CMF(w_main = m, w_user = i, random_seed = 1)\n",
    "        model.fit(ratings = deepcopy(X_train_20), user_info = deepcopy(user_info_20))\n",
    "        prediction = model.predict(X_val_20.UserId, X_val_20.ItemId)\n",
    "        X_val_20['pred_rating'] = prediction\n",
    "        tune_3[m,i] = np.sqrt(np.mean((X_val_20.pred_rating - X_val_20.Rating)**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0.5, 10.0): 1.4093796110241372,\n",
       " (0.5, 5.0): 1.4093675138007682,\n",
       " (0.5, 0.5): 1.409379510028695,\n",
       " (5.0, 10.0): 1.3243942755866573,\n",
       " (5.0, 5.0): 1.3248028150484914,\n",
       " (5.0, 0.5): 1.3249520550165859,\n",
       " (10.0, 10.0): 1.3290478291921621,\n",
       " (10.0, 5.0): 1.3281606768811247,\n",
       " (10.0, 0.5): 1.327849756600441}"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the best param: w_main = 5.0, w_user = 10.0\n",
    "tune_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset_50 = ratings_holdout_50.iloc[:, 0:3]\n",
    "testset_50.columns = ['userID', 'itemID','rating']\n",
    "\n",
    "X_test_50 = testset_50\n",
    "X_test_50.columns = ['UserId','ItemId','Rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_20 = X_test_20.loc[X_test_20.ItemId.isin(X_train_20.ItemId)]\n",
    "X_test_50 = X_test_50.loc[X_test_50.ItemId.isin(X_train_50.ItemId)]\n",
    "X_test_100 = X_test_100.loc[X_test_100.ItemId.isin(X_train_100.ItemId)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
      "  Objective function value: 6.150842\n",
      "  Number of iterations: 1000\n",
      "  Number of functions evaluations: 1098\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<cmfrec.CMF at 0x1bf451cac8>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 20%\n",
    "model = CMF(w_main = 5.0, w_user = 10.0, random_seed = 1)\n",
    "start_time = time.time()\n",
    "model.fit(ratings = deepcopy(X_train_20), user_info = deepcopy(user_info_20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 825.6145222187042 seconds ---\n"
     ]
    }
   ],
   "source": [
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE (with 20% data):  1.349372260486216\n",
      "R^2 (with 20% data):  0.1869517480867452\n",
      "MAE (with 20% data):  1.1194434259908603\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "user_prediction_20 = model.predict(X_test_20.UserId, X_test_20.ItemId)\n",
    "X_test_20['pred_rating'] = user_prediction_20\n",
    "print('RMSE (with 20% data): ', np.sqrt(np.mean((X_test_20.pred_rating - X_test_20.Rating)**2)))\n",
    "print('R^2 (with 20% data): ', r2_score(X_test_20.Rating , X_test_20.pred_rating))\n",
    "print('MAE (with 20% data): ', mean_absolute_error(X_test_20.Rating , X_test_20.pred_rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.562385082244873 seconds ---\n"
     ]
    }
   ],
   "source": [
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
      "  Objective function value: 7.326553\n",
      "  Number of iterations: 1000\n",
      "  Number of functions evaluations: 1096\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<cmfrec.CMF at 0x1b85f566a0>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 50%\n",
    "model = CMF(w_main = 5.0, w_user = 10.0, random_seed = 1)\n",
    "start_time = time.time()\n",
    "model.fit(ratings = deepcopy(X_train_50), user_info = deepcopy(user_info_50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1636.16885304451 seconds ---\n"
     ]
    }
   ],
   "source": [
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_50 = X_test_50.loc[X_test_50.ItemId.isin(X_train_50.ItemId)]\n",
    "X_test_100 = X_test_100.loc[X_test_100.ItemId.isin(X_train_100.ItemId)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE (with 50% data):  1.3721383633420057\n",
      "R^2 (with 50% data):  0.17824736263395613\n",
      "MAE (with 50% data):  1.152321186693606\n"
     ]
    }
   ],
   "source": [
    "user_prediction_50 = model.predict(X_test_50.UserId, X_test_50.ItemId)\n",
    "start_time = time.time()\n",
    "X_test_50['pred_rating'] = user_prediction_50\n",
    "print('RMSE (with 50% data): ', np.sqrt(np.mean((X_test_50.pred_rating - X_test_50.Rating)**2)))\n",
    "print('R^2 (with 50% data): ', r2_score(X_test_50.Rating , X_test_50.pred_rating))\n",
    "print('MAE (with 50% data): ', mean_absolute_error(X_test_50.Rating , X_test_50.pred_rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.28719615936279297 seconds ---\n"
     ]
    }
   ],
   "source": [
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100%\n",
    "model = CMF(w_main = 5.0, w_item = 10.0, random_seed = 1)\n",
    "start_time = time.time()\n",
    "model.fit(ratings = deepcopy(X_train_100), user_info = deepcopy(user_info_100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prediction_100 = model.predict(X_test_100.user_id, X_test_100.business_id)\n",
    "X_test_100['pred_rating'] = user_prediction_100\n",
    "print('RMSE (with 100% data): ', np.sqrt(np.mean((X_test_100.pred_rating - X_test_100.rating)**2)))\n",
    "print('R^2 (with 100% data): ', r2_score(X_test_100.rating - X_test_100.pred_rating))\n",
    "print('MAE (with 100% data): ', mean_absolute_error((X_test_100.rating - X_test_100.pred_rating))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
      "  Objective function value: 6.141467\n",
      "  Number of iterations: 1000\n",
      "  Number of functions evaluations: 1066\n"
     ]
    }
   ],
   "source": [
    "model = CMF(w_main = 5.0, w_user = 10.0, random_seed = 1)\n",
    "model.fit(ratings = deepcopy(X_train_20), user_info = deepcopy(user_info_20))\n",
    "predict_df_20['predictions'] = model.predict(predict_df_20.user_id, predict_df_20.business_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
      "  Objective function value: 7.326606\n",
      "  Number of iterations: 1000\n",
      "  Number of functions evaluations: 1080\n"
     ]
    }
   ],
   "source": [
    "model = CMF(w_main = 5.0, w_user = 10.0, random_seed = 1)\n",
    "model.fit(ratings = deepcopy(X_train_50), user_info = deepcopy(user_info_50))\n",
    "predict_df_50['predictions'] = model.predict(predict_df_50.user_id, predict_df_50.business_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1357142857142857 0.2580952380952381 0.9699999999999993 470.53333333333336\n"
     ]
    }
   ],
   "source": [
    "top_10, coverage, serendipity, avg_rank = get_all_metrics(predict_df_20, out_20, ratings_train_final_20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18035714285714285 0.20553571428571435 0.9794642857142847 440.3589285714286\n"
     ]
    }
   ],
   "source": [
    "top_10, coverage, serendipity, avg_rank = get_all_metrics(predict_df_50, out_50, ratings_train_final_50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
