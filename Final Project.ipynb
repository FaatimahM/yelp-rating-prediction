{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yelp Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset Documentation: <br>\n",
    "https://www.yelp.com/dataset/documentation/main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tarfile\n",
    "from tqdm import tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "?rw-r--r-- daniellg/users  138279749 2018-11-15 11:22:39 business.json \n",
      "?rw-r--r-- daniellg/users  408807658 2018-11-15 11:25:00 checkin.json \n",
      "?rw-r--r-- daniellg/users 5347475638 2018-11-15 11:35:37 review.json \n",
      "?rw-r--r-- daniellg/users  244535478 2018-11-15 11:26:18 tip.json \n",
      "?rw-r--r-- daniellg/users 2485747393 2018-11-15 11:24:48 user.json \n",
      "?rw-r--r-- daniellg/users   25661152 2019-01-11 19:06:09 photo.json \n",
      "?rw-r--r-- daniellg/users     101186 2019-01-14 11:31:35 Dataset_Challenge_Dataset_Agreement.pdf \n",
      "?rw-r--r-- daniellg/users     111822 2019-01-14 11:35:09 Yelp_Dataset_Challenge_Round_13.pdf \n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-9e2a3a38cd06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mzf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'yelp_dataset.tar'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#df = pd.read_csv(zf.open('intfile.csv'))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "zf = tarfile.open('yelp_dataset.tar') \n",
    "#df = pd.read_csv(zf.open('intfile.csv'))\n",
    "for name in zf.list():\n",
    "    print (name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feel free to extract more files here\n",
    "#zf.extract(\"review.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6685900/6685900 [01:08<00:00, 97704.32it/s] \n"
     ]
    }
   ],
   "source": [
    "line_count = len(open(\"review.json\").readlines())\n",
    "user_ids, business_ids, stars, dates, texts = [], [], [], [], []\n",
    "with open(\"review.json\") as f:\n",
    "    for line in tqdm(f, total=line_count):\n",
    "        blob = json.loads(line)\n",
    "        user_ids += [blob[\"user_id\"]]\n",
    "        business_ids += [blob[\"business_id\"]]\n",
    "        stars += [blob[\"stars\"]]\n",
    "        dates += [blob[\"date\"]]\n",
    "        texts += [blob[\"text\"]]\n",
    "ratings = pd.DataFrame(\n",
    "    {\"user_id\": user_ids, \"business_id\": business_ids, \"rating\": stars, \"date\": dates, \"text\": texts}\n",
    ")\n",
    "user_counts = ratings[\"user_id\"].value_counts()\n",
    "active_users = user_counts.loc[user_counts >= 5].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CxDOIDnH8gp9KXzpBHJYXw',\n",
       " 'bLbSNkLggFnqwNNzzq-Ijw',\n",
       " 'PKEzKWv_FktMm2mGPjwd0Q',\n",
       " 'ELcQDlf69kb-ihJfxZyL0A',\n",
       " 'DK57YibC5ShBmqQl97CKog']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "active_users[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hG7b0MtEbXx5QzbzE6C_VA</td>\n",
       "      <td>ujmEBvifdJM6h6RLv4wQIg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013-05-07 04:34:36</td>\n",
       "      <td>Total bill for this horrible service? Over $8G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yXQM5uF2jS6es16SJzNHfg</td>\n",
       "      <td>NZnhc2sEQy3RmzKTZnqtwQ</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2017-01-14 21:30:33</td>\n",
       "      <td>I *adore* Travis at the Hard Rock's new Kelly ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>n6-Gk65cPZL6Uz8qRm3NYw</td>\n",
       "      <td>WTqjgwHlXbSFevF32_DJVw</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2016-11-09 20:09:03</td>\n",
       "      <td>I have to say that this office really has it t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dacAIZ6fTM6mqwW5uxkskg</td>\n",
       "      <td>ikCg8xy5JIg_NGPx-MSIDA</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2018-01-09 20:56:38</td>\n",
       "      <td>Went in for a lunch. Steak sandwich was delici...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ssoyf2_x0EQMed6fgHeMyQ</td>\n",
       "      <td>b1b1eb3uo-w561D0ZfCEiQ</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-01-30 23:07:38</td>\n",
       "      <td>Today was my second out of three sessions I ha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  user_id             business_id  rating  \\\n",
       "0  hG7b0MtEbXx5QzbzE6C_VA  ujmEBvifdJM6h6RLv4wQIg     1.0   \n",
       "1  yXQM5uF2jS6es16SJzNHfg  NZnhc2sEQy3RmzKTZnqtwQ     5.0   \n",
       "2  n6-Gk65cPZL6Uz8qRm3NYw  WTqjgwHlXbSFevF32_DJVw     5.0   \n",
       "3  dacAIZ6fTM6mqwW5uxkskg  ikCg8xy5JIg_NGPx-MSIDA     5.0   \n",
       "4  ssoyf2_x0EQMed6fgHeMyQ  b1b1eb3uo-w561D0ZfCEiQ     1.0   \n",
       "\n",
       "                  date                                               text  \n",
       "0  2013-05-07 04:34:36  Total bill for this horrible service? Over $8G...  \n",
       "1  2017-01-14 21:30:33  I *adore* Travis at the Hard Rock's new Kelly ...  \n",
       "2  2016-11-09 20:09:03  I have to say that this office really has it t...  \n",
       "3  2018-01-09 20:56:38  Went in for a lunch. Steak sandwich was delici...  \n",
       "4  2018-01-30 23:07:38  Today was my second out of three sessions I ha...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6685900, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Users: 1637138, unique restaurants: 192606\n"
     ]
    }
   ],
   "source": [
    "n_users = len(ratings.user_id.unique())\n",
    "n_restaurants = len(ratings.business_id.unique())\n",
    "print('Unique Users: {0}, unique restaurants: {1}'.format(n_users, n_restaurants))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "\n",
    "1. Baseline:\n",
    "User based (Bowen)\n",
    "ALS (later)\n",
    "\n",
    "\n",
    "1. Cold start: (<5 reviews)\n",
    "content based (Nearest neighbors on review text, metadata tex) (Zhongling)\n",
    "\n",
    "\n",
    "2. Main model\n",
    "Field-aware factorization machine (James)\n",
    "Locality Sensitive Hashing (Ujjwal)\n",
    "Collective Matrix Factorization (Bowen)\n",
    "\n",
    "\n",
    "Hybrid approach\n",
    "3. Metrics\n",
    "TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train / Holdout "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rating dataset has ~6.6 million rows and is time consuming to perform group by & aggregation operations, which is required for constructing holdout set. Therefore, I randomly subsample 1/10 rows in order to make code run through more quickly. Note that this is not an optimal practice, I did it solely because I want to speed up the data pre-processing and modeling cycle. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratings_sample = ratings.sample(frac= 1/10, replace=False, random_state=1)\n",
    "# Downsample by users\n",
    "user_id_unique = ratings.user_id.unique()\n",
    "user_id_sample = pd.DataFrame(user_id_unique, columns=['unique_user_id']) \\\n",
    "                    .sample(frac= 1/10, replace=False, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  user_id             business_id  rating  \\\n",
      "0  w31MKYsNFMrjhWxxAb5wIw  eU_713ec6fTGNO4BegRaww     4.0   \n",
      "1  sG_h0dIzTKWa3Q6fmb4u-g  b2jN2mm9Wf3RcrZCgfo1cg     2.0   \n",
      "2  sG_h0dIzTKWa3Q6fmb4u-g  3FG0ZCPkHzDxP8UOmoEyiQ     1.0   \n",
      "3  sG_h0dIzTKWa3Q6fmb4u-g  4IBXNxLsEcfUIx6LUM2Aqw     2.0   \n",
      "4  sG_h0dIzTKWa3Q6fmb4u-g  oq9bF1KUzSldObMSQ_aalQ     5.0   \n",
      "\n",
      "                  date                                               text  \n",
      "0  2013-01-20 13:25:59  I'll be the first to admit that I was not exci...  \n",
      "1  2015-01-18 14:04:18  I was really looking forward to visiting after...  \n",
      "2  2016-07-09 22:57:25  Went there to buy a car today. Walked around t...  \n",
      "3  2016-01-10 19:25:08  55 min wait for takeout and a $7 draft beer se...  \n",
      "4  2017-01-20 18:31:41  Best Philly Cheese Steak outside of Philly. Be...  \n",
      "(658169, 5)\n"
     ]
    }
   ],
   "source": [
    "ratings_sample = ratings.merge(user_id_sample, left_on='user_id', right_on='unique_user_id') \\\n",
    "                    .drop(['unique_user_id'], axis=1)\n",
    "print(ratings_sample.head())\n",
    "print(ratings_sample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ratings_sample.to_csv('ratings_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hold out last review\n",
    "ratings_user_date = ratings_sample.loc[:, ['user_id', 'date']]\n",
    "index_holdout = ratings_user_date.groupby(['user_id'], sort=False)['date'].transform(max) == ratings_user_date['date']\n",
    "ratings_holdout = ratings_sample[index_holdout]\n",
    "ratings_train = ratings_sample[~index_holdout]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 279080 rows, 5 columns in training set.\n",
      "There are 389510 rows, 5 columns in holdout set.\n"
     ]
    }
   ],
   "source": [
    "print('There are {0} rows, {1} columns in training set.'.format(ratings_train.shape[0], ratings_train.shape[1]))\n",
    "print('There are {0} rows, {1} columns in holdout set.'.format(ratings_holdout.shape[0], ratings_holdout.shape[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deeplearning0]",
   "language": "python",
   "name": "conda-env-deeplearning0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
