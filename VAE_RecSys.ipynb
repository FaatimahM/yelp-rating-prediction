{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/jiangzl2016/yelp-rating-prediction/blob/master/VAE_RecSys.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7a0PQGQjwC1B"
   },
   "source": [
    "## Deep Learning Models\n",
    "#### DeepFM\n",
    "\n",
    "![DeepFM Model Architecture](https://d2l.ai/_images/rec-deepfm.svg)\n",
    "\n",
    "It is a model which integrates the feature representation learning of a neural network with factorization machines.\n",
    "\n",
    "Adding nonlinear transformation layers to factorization machines gives it the capability to model both low-order feature combinations and high-order feature combinations. Moreover, non-linear inherent structures from inputs can also be captured with neural networks.\n",
    "\n",
    "#### Wide and Deep Learning\n",
    "\n",
    "![Wide and Deep Model](https://2.bp.blogspot.com/-wkrmRibw_GM/V3Mg3O3Q0-I/AAAAAAAABG0/Jm3Nl4-VcYIJ44dA5nSz6vpTyCKF2KWQgCKgB/s640/image03.png)\n",
    "\n",
    "The Wide part of the model tries to capture the co-occurrence of a query-item feature pair correlates with the target label. The Deep model generalizes the query-item interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "NW95ttnU-3ed",
    "outputId": "94725c12-71ea-43d4-8909-9521c4574006"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 700
    },
    "colab_type": "code",
    "id": "OSPql3L9d3qx",
    "outputId": "1a0153e1-6880-4390-ffb0-630df19e2c76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: deepctr[gpu] in /usr/local/lib/python3.6/dist-packages (0.7.0)\n",
      "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from deepctr[gpu]) (2.21.0)\n",
      "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from deepctr[gpu]) (2.8.0)\n",
      "Requirement already satisfied, skipping upgrade: tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\" in /usr/local/lib/python3.6/dist-packages (from deepctr[gpu]) (2.0.0)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->deepctr[gpu]) (2019.11.28)\n",
      "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->deepctr[gpu]) (1.24.3)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->deepctr[gpu]) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->deepctr[gpu]) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from h5py->deepctr[gpu]) (1.17.4)\n",
      "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from h5py->deepctr[gpu]) (1.12.0)\n",
      "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (1.11.2)\n",
      "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (0.8.1)\n",
      "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (0.8.1)\n",
      "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: tensorflow-estimator<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (2.0.1)\n",
      "Requirement already satisfied, skipping upgrade: tensorboard<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (2.0.2)\n",
      "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (0.33.6)\n",
      "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (3.1.0)\n",
      "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (1.0.8)\n",
      "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (0.1.8)\n",
      "Requirement already satisfied, skipping upgrade: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (0.2.2)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (3.10.0)\n",
      "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (0.4.1)\n",
      "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (0.16.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (42.0.2)\n",
      "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (1.10.0)\n",
      "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (3.1.1)\n",
      "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (0.2.7)\n",
      "Requirement already satisfied, skipping upgrade: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (4.0)\n",
      "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (4.0.0)\n",
      "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (3.1.0)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (0.4.8)\n",
      "Requirement already up-to-date: scikit-learn in /usr/local/lib/python3.6/dist-packages (0.22)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (0.14.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.17.4)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.3.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U deepctr[gpu]\n",
    "!pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j4lubeylyJLF"
   },
   "source": [
    "The GPU being used for the deep learning models is a Tesla P100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "RIgViUOV9WQl",
    "outputId": "af7467cf-1309-4ca3-8790-74c29c5c6ce8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Dec 20 04:37:44 2019       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.44       Driver Version: 418.67       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   35C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C1j6rJwyyOzN"
   },
   "source": [
    "#### Reading the dataset ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "pICvjmggcnoI",
    "outputId": "5792b515-6cc8-4a85-bbff-154387663a9b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "## data handling\n",
    "# setup libraries and env\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sn\n",
    "sn.set()\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from deepctr.models import DeepFM, CCPM, FNN, PNN, WDL, MLR, NFM, AFM, DCN, DIN, DIEN, DSIN, xDeepFM, AutoInt, NFFM, FGCNN, FiBiNET\n",
    "from deepctr.inputs import SparseFeat,get_feature_names\n",
    "\n",
    "import itertools as it\n",
    "\n",
    "training =  pd.read_csv('/content/drive/My Drive/final_project_datasets/ratings_sample_train_100(1).csv', index_col = 0)\n",
    "validation = pd.read_csv('/content/drive/My Drive/final_project_datasets/ratings_sample_cv_100.csv', index_col = 0)\n",
    "test = pd.read_csv('/content/drive/My Drive/final_project_datasets/ratings_sample_holdout_100.csv', index_col = 0)\n",
    "\n",
    "businesses = pd.read_csv('/content/drive/My Drive/final_project_datasets/businesses.csv')\n",
    "users = pd.read_csv('/content/drive/My Drive/final_project_datasets/active_users.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "slD0osLPVmN1"
   },
   "outputs": [],
   "source": [
    "# training.dropna(inplace = True)\n",
    "# validation.dropna(inplace = True)\n",
    "# test.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jajtKWzSySTR"
   },
   "source": [
    "##### Include cities as a feature in the deep learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8fFyOfYm_Stb"
   },
   "outputs": [],
   "source": [
    "businesses['business_city_state'] = businesses['business_city'] + businesses['business_state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "W90pYEhiVCxo",
    "outputId": "28f8c64e-1741-471a-e926-a995b62d7323"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3965887, 5) (286165, 5) (286126, 5)\n"
     ]
    }
   ],
   "source": [
    "print(training.shape, validation.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "58mUcfi7BFyY"
   },
   "outputs": [],
   "source": [
    "training = training.merge(right = businesses[['business_id', 'business_city_state']], how = 'left', on = 'business_id')\n",
    "validation = validation.merge(right = businesses[['business_id', 'business_city_state']], how = 'left', on = 'business_id')\n",
    "test = test.merge(right = businesses[['business_id', 'business_city_state']], how = 'left', on = 'business_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NJmXuQftBuz9"
   },
   "outputs": [],
   "source": [
    "column_sequence = ['user_id', 'business_id', 'business_city_state', 'text', 'rating', 'date']\n",
    "training = training[column_sequence]\n",
    "validation = validation[column_sequence]\n",
    "test = test[column_sequence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "Yk_DkOyO8A3V",
    "outputId": "43fa8320-d5e7-414e-ab22-458e434cb906"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>business_city_state</th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wNyiw6GfVfn5Kphqmux1gw</td>\n",
       "      <td>5OZlLXjU0FXUbrw8Scja6g</td>\n",
       "      <td>GlendaleAZ</td>\n",
       "      <td>They keep there appointments on time and are p...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-02-01 19:01:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zFYFuufYWQSPj0r5lrKQKg</td>\n",
       "      <td>wJj1EwYcXHdvA9zKqmb5hQ</td>\n",
       "      <td>Las VegasNV</td>\n",
       "      <td>I called the number provided and same day they...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2018-10-04 11:20:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HQlMQTF9wckTGfKG9Ljtvg</td>\n",
       "      <td>DmuU3QC1AM9LPb_J8L2FGA</td>\n",
       "      <td>SolonOH</td>\n",
       "      <td>Cutest little dive bar in the city! Chill vibe...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2018-08-04 20:32:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OuRmjIT8yj8w04XsLX1tlg</td>\n",
       "      <td>9mIm1ef-NVDQHFE39Faxxg</td>\n",
       "      <td>TempeAZ</td>\n",
       "      <td>Hey....i just want to say, everytime I eat her...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2018-08-04 20:36:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UF32lXb79D29HIk0BWdqWA</td>\n",
       "      <td>qfBp53c7Z2DpqUrGhV80zg</td>\n",
       "      <td>PittsburghPA</td>\n",
       "      <td>Best Thai food ever! Love the mango curry espe...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2018-07-17 00:36:37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  user_id             business_id  ... rating                 date\n",
       "0  wNyiw6GfVfn5Kphqmux1gw  5OZlLXjU0FXUbrw8Scja6g  ...    1.0  2018-02-01 19:01:16\n",
       "1  zFYFuufYWQSPj0r5lrKQKg  wJj1EwYcXHdvA9zKqmb5hQ  ...    5.0  2018-10-04 11:20:42\n",
       "2  HQlMQTF9wckTGfKG9Ljtvg  DmuU3QC1AM9LPb_J8L2FGA  ...    5.0  2018-08-04 20:32:55\n",
       "3  OuRmjIT8yj8w04XsLX1tlg  9mIm1ef-NVDQHFE39Faxxg  ...    5.0  2018-08-04 20:36:55\n",
       "4  UF32lXb79D29HIk0BWdqWA  qfBp53c7Z2DpqUrGhV80zg  ...    5.0  2018-07-17 00:36:37\n",
       "\n",
       "[5 rows x 6 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert object to datetime\n",
    "# training.date = pd.to_datetime(training.date)\n",
    "# validation.date = pd.to_datetime(validation.date)\n",
    "# test.date = pd.to_datetime(test.date)\n",
    "\n",
    "# find hour from datetime\n",
    "# training['hour'] = training.date.dt.hour\n",
    "# validation['hour'] = validation.date.dt.hour\n",
    "# test['hour'] = test.date.dt.hour\n",
    "\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_IXUwUgTyb4R"
   },
   "source": [
    "##### Data Quality check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "v0viHy3k8EFt",
    "outputId": "e4dd17e5-f2ad-4cf4-8517-5f0889c22f05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# quality check\n",
    "print(len(set(test.user_id) - set(training.user_id)))\n",
    "print(len(set(validation.user_id) - set(training.user_id)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BetkE-yUgym-"
   },
   "outputs": [],
   "source": [
    "test = test.loc[test.business_id.isin(training.business_id)]\n",
    "validation = validation.loc[validation.business_id.isin(training.business_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1vkFO-bV4rJb"
   },
   "outputs": [],
   "source": [
    "# map each user_id, business_id to an index\n",
    "# user_mapping = {}\n",
    "# for n,i in enumerate(training.user_id.unique()):\n",
    "#   user_mapping[i] = n\n",
    "\n",
    "# business_mapping = {}\n",
    "# for n,i in enumerate(training.business_id.unique()):\n",
    "#   business_mapping[i] = n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vwqf8DZ66Z8r"
   },
   "outputs": [],
   "source": [
    "# for training\n",
    "# training['user_id'] = training['user_id'].map(user_mapping)\n",
    "# training['business_id'] = training['business_id'].map(business_mapping)\n",
    "# for validation\n",
    "# validation['user_id'] = validation['user_id'].map(user_mapping)\n",
    "# validation['business_id'] = validation['business_id'].map(business_mapping)\n",
    "# for test\n",
    "# test['user_id'] = test['user_id'].map(user_mapping)\n",
    "# test['business_id'] = test['business_id'].map(business_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "ZCTJonRY6j7s",
    "outputId": "ac8ea740-30c8-4083-d8be-408132791b9f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>business_city_state</th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wNyiw6GfVfn5Kphqmux1gw</td>\n",
       "      <td>5OZlLXjU0FXUbrw8Scja6g</td>\n",
       "      <td>GlendaleAZ</td>\n",
       "      <td>They keep there appointments on time and are p...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-02-01 19:01:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zFYFuufYWQSPj0r5lrKQKg</td>\n",
       "      <td>wJj1EwYcXHdvA9zKqmb5hQ</td>\n",
       "      <td>Las VegasNV</td>\n",
       "      <td>I called the number provided and same day they...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2018-10-04 11:20:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HQlMQTF9wckTGfKG9Ljtvg</td>\n",
       "      <td>DmuU3QC1AM9LPb_J8L2FGA</td>\n",
       "      <td>SolonOH</td>\n",
       "      <td>Cutest little dive bar in the city! Chill vibe...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2018-08-04 20:32:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OuRmjIT8yj8w04XsLX1tlg</td>\n",
       "      <td>9mIm1ef-NVDQHFE39Faxxg</td>\n",
       "      <td>TempeAZ</td>\n",
       "      <td>Hey....i just want to say, everytime I eat her...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2018-08-04 20:36:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UF32lXb79D29HIk0BWdqWA</td>\n",
       "      <td>qfBp53c7Z2DpqUrGhV80zg</td>\n",
       "      <td>PittsburghPA</td>\n",
       "      <td>Best Thai food ever! Love the mango curry espe...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2018-07-17 00:36:37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  user_id             business_id  ... rating                 date\n",
       "0  wNyiw6GfVfn5Kphqmux1gw  5OZlLXjU0FXUbrw8Scja6g  ...    1.0  2018-02-01 19:01:16\n",
       "1  zFYFuufYWQSPj0r5lrKQKg  wJj1EwYcXHdvA9zKqmb5hQ  ...    5.0  2018-10-04 11:20:42\n",
       "2  HQlMQTF9wckTGfKG9Ljtvg  DmuU3QC1AM9LPb_J8L2FGA  ...    5.0  2018-08-04 20:32:55\n",
       "3  OuRmjIT8yj8w04XsLX1tlg  9mIm1ef-NVDQHFE39Faxxg  ...    5.0  2018-08-04 20:36:55\n",
       "4  UF32lXb79D29HIk0BWdqWA  qfBp53c7Z2DpqUrGhV80zg  ...    5.0  2018-07-17 00:36:37\n",
       "\n",
       "[5 rows x 6 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vAW_-RGWlge5"
   },
   "outputs": [],
   "source": [
    "# validation = validation.loc[~validation.business_id.isin(['WpC53SqwoCY5AuYIFr_1eA'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W9rQWXdEyhPj"
   },
   "source": [
    "#### Preparation for input into deep learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UPZ-2X6hj_e6"
   },
   "outputs": [],
   "source": [
    "# 1.Label Encoding for sparse features,and do simple Transformation for dense features\n",
    "training = training.loc[training.business_city_state.apply(type) != float]\n",
    "training_deep = training.copy()\n",
    "validation_deep = validation.copy()\n",
    "test_deep = test.copy()\n",
    "\n",
    "sparse_features = [\"user_id\", \"business_id\", \"business_city_state\"]#, \"hour\"]\n",
    "target = ['rating']\n",
    "for feat in sparse_features:\n",
    "  lbe = LabelEncoder()\n",
    "  training_deep[feat] = lbe.fit_transform(training_deep[feat])\n",
    "  validation_deep[feat] = lbe.transform(validation_deep[feat])\n",
    "  test_deep[feat] = lbe.transform(test_deep[feat])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1EneZP-byvEy"
   },
   "source": [
    "##### Grid Search - Hyperparameter Tuning\n",
    "\n",
    "We have tuned 3 parameters for both the models,\n",
    "1. Embedding dimension - 8, 16, 31\n",
    "2. Hidden Units - (128, 128), (256, 256), (256, 128)\n",
    "3. Dropout - 0.1, 0.3, 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c73rkdvjI70c"
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'embedding_dim' : [8, 16, 32],\n",
    "    'dnn_hidden_units': [(128, 128), (256, 256), (256, 128)],\n",
    "    'dnn_dropout': [0.1, 0.3, 0.5]\n",
    "}\n",
    "allNames = sorted(params)\n",
    "combinations = it.product(*(params[Name] for Name in allNames))\n",
    "\n",
    "best_params = None\n",
    "best_mse = 1000\n",
    "\n",
    "# grid search for DeepFM\n",
    "for i in list(combinations):\n",
    "  dropout, dnn_hidden_units, embedding_dim = i\n",
    "\n",
    "  # 2.count #unique features for each sparse field\n",
    "  fixlen_feature_columns = [SparseFeat(feat, training_deep[feat].nunique(), embedding_dim = embedding_dim) for feat in sparse_features]\n",
    "  linear_feature_columns = fixlen_feature_columns\n",
    "  dnn_feature_columns = fixlen_feature_columns\n",
    "  feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns)\n",
    "  \n",
    "  # 3.define model inputs   \n",
    "  train_model_input = {name:training_deep[name].values for name in feature_names}\n",
    "  valid_model_input = {name:validation_deep[name].values for name in feature_names}\n",
    "  test_model_input = {name:test_deep[name].values for name in feature_names}\n",
    "\n",
    "  # 4.Define Model,train,predict and evaluate\n",
    "  model = DeepFM(linear_feature_columns, dnn_feature_columns, fm_group=['business_city_state'], task='regression', dnn_hidden_units = dnn_hidden_units, dnn_dropout = dropout, l2_reg_embedding=1e-05, l2_reg_dnn=1e-05, l2_reg_linear=1e-05, seed = 42)\n",
    "  model.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "  # only one epoch because it overfits after the first epoch\n",
    "  history = model.fit(train_model_input, training_deep[target].values, batch_size=256, epochs=1, verbose=2, validation_data= (valid_model_input, validation[target].values))\n",
    "\n",
    "  validation_predictions = model.predict(valid_model_input, batch_size=256)\n",
    "  val_mse = mean_squared_error(validation_deep[target].values, validation_predictions)\n",
    "  print(\"validation MSE\", round(val_mse, 4))\n",
    "  if val_mse < best_mse:\n",
    "    best_mse = val_mse\n",
    "    best_params = [dropout, dnn_hidden_units, embedding_dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kRBnLR47PGW4"
   },
   "outputs": [],
   "source": [
    "best_mse, best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QIIAcVo4PSON"
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'embedding_dim' : [8, 16, 32],\n",
    "    'dnn_hidden_units': [(128, 128), (256, 256), (256, 128)],\n",
    "    'dnn_dropout': [0.1, 0.3, 0.5]\n",
    "}\n",
    "allNames = sorted(params)\n",
    "combinations = it.product(*(params[Name] for Name in allNames))\n",
    "\n",
    "best_params_wdl = None\n",
    "best_mse_wdl = 1000\n",
    "\n",
    "# grid search for WDL\n",
    "for i in list(combinations):\n",
    "  dropout, dnn_hidden_units, embedding_dim = i\n",
    "\n",
    "  # 2.count #unique features for each sparse field\n",
    "  fixlen_feature_columns = [SparseFeat(feat, training_deep[feat].nunique(), embedding_dim = embedding_dim) for feat in sparse_features]\n",
    "  linear_feature_columns = fixlen_feature_columns\n",
    "  dnn_feature_columns = fixlen_feature_columns\n",
    "  feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns)\n",
    "  \n",
    "  # 3.define model inputs   \n",
    "  train_model_input = {name:training_deep[name].values for name in feature_names}\n",
    "  valid_model_input = {name:validation_deep[name].values for name in feature_names}\n",
    "  test_model_input = {name:test_deep[name].values for name in feature_names}\n",
    "\n",
    "  # 4.Define Model,train,predict and evaluate\n",
    "  model = WDL(linear_feature_columns, dnn_feature_columns, task='regression', dnn_hidden_units = dnn_hidden_units, dnn_dropout = dropout, l2_reg_embedding=1e-05, l2_reg_dnn=1e-05, l2_reg_linear=1e-05, seed = 42)\n",
    "  model.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "  # only one epoch because it overfits after the first epoch\n",
    "  history = model.fit(train_model_input, training_deep[target].values, batch_size=256, epochs=1, verbose=2, validation_data= (valid_model_input, validation[target].values))\n",
    "\n",
    "  validation_predictions = model.predict(valid_model_input, batch_size=256)\n",
    "  val_mse = mean_squared_error(validation_deep[target].values, validation_predictions)\n",
    "  print(\"validation MSE\", round(val_mse, 4))\n",
    "  if val_mse < best_mse_wdl:\n",
    "    best_mse_wdl = val_mse\n",
    "    best_params_wdl = [dropout, dnn_hidden_units, embedding_dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6uXv2eFIPSL8"
   },
   "outputs": [],
   "source": [
    "best_mse_wdl, best_params_wdl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g-iSvuv1zGS3"
   },
   "source": [
    "#### Refitting the model on the best parameters for each of the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "colab_type": "code",
    "id": "4YwMQt-8pIPT",
    "outputId": "f486ab47-ad90-4c4d-e9d7-c985d005973f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4249168 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4249168/4249168 - 829s - loss: 1.6306 - mse: 1.5621\n",
      "Train on 4249168 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4249168/4249168 - 834s - loss: 1.6294 - mse: 1.5612\n"
     ]
    }
   ],
   "source": [
    "# 1.Label Encoding for sparse features,and do simple Transformation for dense features\n",
    "training_combined = pd.concat([training, validation], axis = 0)\n",
    "training_combined_deep = training_combined.copy()\n",
    "test_deep = test.copy()\n",
    "\n",
    "sparse_features = [\"user_id\", \"business_id\", \"business_city_state\"]#, \"hour\"]\n",
    "target = ['rating']\n",
    "\n",
    "for feat in sparse_features:\n",
    "  lbe = LabelEncoder()\n",
    "  training_combined_deep[feat] = lbe.fit_transform(training_combined_deep[feat])\n",
    "  test_deep[feat] = lbe.transform(test_deep[feat])\n",
    "\n",
    "# best DeepFM Model\n",
    "dropout_deepfm = 0.1\n",
    "dnn_hidden_units_deepfm = (128, 128)\n",
    "embedding_dim_deepfm = 8\n",
    "\n",
    "# 2.count #unique features for each sparse field\n",
    "fixlen_feature_columns = [SparseFeat(feat, training_combined_deep[feat].nunique(), embedding_dim = embedding_dim_deepfm) for feat in sparse_features]\n",
    "linear_feature_columns = fixlen_feature_columns\n",
    "dnn_feature_columns = fixlen_feature_columns\n",
    "feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns)\n",
    "\n",
    "# 3.define model inputs   \n",
    "train_model_input = {name:training_combined_deep[name].values for name in feature_names}\n",
    "test_model_input = {name:test_deep[name].values for name in feature_names}\n",
    "\n",
    "# 4.Define Model,train,predict and evaluate\n",
    "model_deepfm = DeepFM(linear_feature_columns, dnn_feature_columns, fm_group=['business_city_state'], task='regression', dnn_hidden_units = dnn_hidden_units_deepfm, dnn_dropout = dropout_deepfm, l2_reg_embedding=1e-05, l2_reg_dnn=1e-05, l2_reg_linear=1e-05, seed = 42)\n",
    "model_deepfm.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "# only one epoch because it overfits after the first epoch\n",
    "history = model_deepfm.fit(train_model_input, training_combined_deep[target].values, batch_size=256, epochs=1, verbose=2)\n",
    "\n",
    "test_predictions_deepfm = model_deepfm.predict(test_model_input, batch_size=255)\n",
    "test_mse_deepfm = mean_squared_error(test_deep[target].values, test_predictions_deepfm)\n",
    "\n",
    "\n",
    "# best WDL Model\n",
    "dropout_wdl = 0.3\n",
    "dnn_hidden_units_wdl = (256, 256)\n",
    "embedding_dim_wdl = 8\n",
    "\n",
    "# 2.count #unique features for each sparse field\n",
    "fixlen_feature_columns = [SparseFeat(feat, training_combined_deep[feat].nunique(), embedding_dim = embedding_dim_wdl) for feat in sparse_features]\n",
    "linear_feature_columns = fixlen_feature_columns\n",
    "dnn_feature_columns = fixlen_feature_columns\n",
    "feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns)\n",
    "\n",
    "# 3.define model inputs   \n",
    "train_model_input = {name:training_combined_deep[name].values for name in feature_names}\n",
    "test_model_input = {name:test_deep[name].values for name in feature_names}\n",
    "\n",
    "# 4.Define Model,train,predict and evaluate\n",
    "model_wdl = WDL(linear_feature_columns, dnn_feature_columns, task='regression', dnn_hidden_units = dnn_hidden_units_wdl, dnn_dropout = dropout_wdl, l2_reg_embedding=1e-05, l2_reg_dnn=1e-05, l2_reg_linear=1e-05, seed = 42)\n",
    "model_wdl.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "# only one epoch because it overfits after the first epoch\n",
    "history = model_wdl.fit(train_model_input, training_combined_deep[target].values, batch_size=256, epochs=1, verbose=2)\n",
    "\n",
    "test_predictions_wdl = model_wdl.predict(test_model_input, batch_size=256)\n",
    "test_mse_wdl = mean_squared_error(test_deep[target].values, test_predictions_wdl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "m9r7HJH_u_qc",
    "outputId": "89d71a39-9718-46b9-da51-8fd60e241bb2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.8560476634242056, 1.8562657588626623)"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_mse_deepfm, test_mse_wdl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4ntPEspLzQfk"
   },
   "source": [
    "#### R2 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "3gxa_XCvQHPO",
    "outputId": "9ba285be-86aa-4395-a40d-ab8cbf83a751"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: 0.195\n",
      "R2 Score: 0.195\n"
     ]
    }
   ],
   "source": [
    "print(\"R2 Score: %0.3f\" %r2_score(y_true = test_deep[target], y_pred = test_predictions_deepfm))\n",
    "print(\"R2 Score: %0.3f\" %r2_score(y_true = test_deep[target], y_pred = test_predictions_wdl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WAPdjZHTzT9L"
   },
   "source": [
    "#### Mean Absolute Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "eXVSUJR1FtIQ",
    "outputId": "033b9cf9-3a3f-4379-a025-1ed776cedd99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 1.134\n",
      "Mean Absolute Error: 1.115\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean Absolute Error: %0.3f\" %mean_absolute_error(y_true = test_deep[target], y_pred = test_predictions_deepfm))\n",
    "print(\"Mean Absolute Error: %0.3f\" %mean_absolute_error(y_true = test_deep[target], y_pred = test_predictions_wdl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vq62aTXfzWKX"
   },
   "source": [
    "#### Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "Mx18EHNdFtsy",
    "outputId": "b99d88f4-005e-4a51-eb21-e82211352e3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Square Error: 1.362\n",
      "Root Mean Square Error: 1.362\n"
     ]
    }
   ],
   "source": [
    "print(\"Root Mean Square Error: %0.3f\" %mean_squared_error(y_true = test_deep[target], y_pred = test_predictions_deepfm, squared = False))\n",
    "print(\"Root Mean Square Error: %0.3f\" %mean_squared_error(y_true = test_deep[target], y_pred = test_predictions_wdl, squared = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HviC2U69-cvT"
   },
   "source": [
    "#### Rest of the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KJaZIbgdFtx4"
   },
   "outputs": [],
   "source": [
    "def process(df):\n",
    "    # df = df.drop(df.columns[0], axis =1)\n",
    "    df['date']  = pd.to_datetime(df['date'])\n",
    "    df['week_day'] = df['date'].dt.weekday\n",
    "    df['month'] = df['date'].dt.month\n",
    "    df['hour'] = df['date'].dt.hour\n",
    "    df = df.merge(users, on = 'user_id')\n",
    "    df = df.merge(businesses, on = 'business_id')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-AgdF0vOFtwd"
   },
   "outputs": [],
   "source": [
    "ratings_train = process(training.copy())\n",
    "ratings_validation = process(validation.copy())\n",
    "ratings_test = process(test.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "44J-_bemFtqn"
   },
   "outputs": [],
   "source": [
    "ratings_train_final = ratings_train.append(ratings_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R3wqepVHQC54"
   },
   "outputs": [],
   "source": [
    "unique_city_businesses = ratings_train_final[['business_city','business_id']].drop_duplicates()\n",
    "unique_cities = unique_city_businesses.groupby('business_city').count()['business_id']\n",
    "unique_cities = unique_cities[unique_cities > 100]\n",
    "out = pd.DataFrame()\n",
    "for city in unique_cities.index:\n",
    "    tmp = ratings_train_final[(ratings_train_final['business_city'] ==city) &\n",
    "                              (ratings_train_final['rating'] >ratings_train_final['average_stars'])]\n",
    "    if len(tmp['user_id'].unique())>4:\n",
    "        np.random.seed(42)\n",
    "        ###this weird sampling technique is to ensure we dont' sample the same user twice in a same city\n",
    "        five_users = np.random.choice(tmp['user_id'].unique(),5, replace = False)\n",
    "        row = tmp[tmp['user_id'].isin(five_users)].groupby('user_id', group_keys=False).apply(lambda df: df.sample(1))\n",
    "        out = out.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "XbttGKw7i4OF",
    "outputId": "7aa4c406-4bf1-4ed8-88e3-31b5c80fb1a6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all(out.groupby('business_city').count()['user_id']==5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nJ2MUDxni4TG"
   },
   "outputs": [],
   "source": [
    "predict_df = out[['user_id','business_city','business_state']]\n",
    "predict_df = predict_df.merge(unique_city_businesses, on = 'business_city')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "2rWcE5DHi4Ri",
    "outputId": "3aa5d0f8-bbca-40c4-914c-81eadc26bf84"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all(predict_df.groupby('business_city')['user_id'].nunique()==5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HIB3gLs1mzaS"
   },
   "outputs": [],
   "source": [
    "# remove businesses not in training\n",
    "predict_df = predict_df.loc[predict_df.business_id.isin(training.business_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "colab_type": "code",
    "id": "87I2AzH2i4Lp",
    "outputId": "3dfdfea0-ee5d-4a84-aba8-4b7724c33127"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B7Baf7gCAFDtC9zjBsYP4Q</td>\n",
       "      <td>Gq5Hb2yr2O3_jLWY4XXcZg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B7Baf7gCAFDtC9zjBsYP4Q</td>\n",
       "      <td>u2ePX4axL3npfgtg_K9hUA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B7Baf7gCAFDtC9zjBsYP4Q</td>\n",
       "      <td>NnqSq_t2Fb6UrJefp_ELYQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B7Baf7gCAFDtC9zjBsYP4Q</td>\n",
       "      <td>YnGf7asAct4nVyWbSQl8eA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B7Baf7gCAFDtC9zjBsYP4Q</td>\n",
       "      <td>2fzvsqTtnrwkamOLjcVToQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859080</th>\n",
       "      <td>wehs_brEeBx2-PZfN56M9g</td>\n",
       "      <td>-lSQaSb2EPM3Jnr1zQCtCQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859081</th>\n",
       "      <td>wehs_brEeBx2-PZfN56M9g</td>\n",
       "      <td>JbEnJHxuzXUbGSIl2BgEVA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859082</th>\n",
       "      <td>wehs_brEeBx2-PZfN56M9g</td>\n",
       "      <td>9H3YiU0ByZWQbslsEZGeYw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859083</th>\n",
       "      <td>wehs_brEeBx2-PZfN56M9g</td>\n",
       "      <td>ae--hb1dWeEZUFGYifGhHg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859084</th>\n",
       "      <td>wehs_brEeBx2-PZfN56M9g</td>\n",
       "      <td>NTpPNS12eW0YlJn3frvPYw</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>859085 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       user_id             business_id\n",
       "0       B7Baf7gCAFDtC9zjBsYP4Q  Gq5Hb2yr2O3_jLWY4XXcZg\n",
       "1       B7Baf7gCAFDtC9zjBsYP4Q  u2ePX4axL3npfgtg_K9hUA\n",
       "2       B7Baf7gCAFDtC9zjBsYP4Q  NnqSq_t2Fb6UrJefp_ELYQ\n",
       "3       B7Baf7gCAFDtC9zjBsYP4Q  YnGf7asAct4nVyWbSQl8eA\n",
       "4       B7Baf7gCAFDtC9zjBsYP4Q  2fzvsqTtnrwkamOLjcVToQ\n",
       "...                        ...                     ...\n",
       "859080  wehs_brEeBx2-PZfN56M9g  -lSQaSb2EPM3Jnr1zQCtCQ\n",
       "859081  wehs_brEeBx2-PZfN56M9g  JbEnJHxuzXUbGSIl2BgEVA\n",
       "859082  wehs_brEeBx2-PZfN56M9g  9H3YiU0ByZWQbslsEZGeYw\n",
       "859083  wehs_brEeBx2-PZfN56M9g  ae--hb1dWeEZUFGYifGhHg\n",
       "859084  wehs_brEeBx2-PZfN56M9g  NTpPNS12eW0YlJn3frvPYw\n",
       "\n",
       "[859085 rows x 2 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_df[['user_id', 'business_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mm_osHNri4KK"
   },
   "outputs": [],
   "source": [
    "predict_df['business_city_state'] = predict_df['business_city'] + predict_df['business_state']\n",
    "metric_test_deep = predict_df[['user_id', 'business_id', 'business_city_state']].copy()\n",
    "\n",
    "for feat in sparse_features:\n",
    "  lbe = LabelEncoder()\n",
    "  lbe.fit(training[feat])\n",
    "  metric_test_deep[feat] = lbe.transform(metric_test_deep[feat])\n",
    "  \n",
    "metric_test_input = {name:metric_test_deep[name].values for name in feature_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qIGGwTB5i4Ev"
   },
   "outputs": [],
   "source": [
    "metric_test_predictions_deepfm = model_deepfm.predict(metric_test_input, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RVpeNfgFBAJO"
   },
   "outputs": [],
   "source": [
    "metric_test_predictions_wdl = model_wdl.predict(metric_test_input, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y_y1tyX2qnci"
   },
   "outputs": [],
   "source": [
    "predict_df['predictions'] = metric_test_predictions_wdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FyT-eH8Zi4CD"
   },
   "outputs": [],
   "source": [
    "top_10_recs = predict_df.groupby(['user_id','business_city'])['predictions'].nlargest(10).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "c-OQeKTKqu0c",
    "outputId": "41770bcc-42de-4bf5-f3e9-ba4c862a6af0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 56,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all(top_10_recs.groupby('business_city')['user_id'].count()==50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fSLYCDXIqxxz"
   },
   "outputs": [],
   "source": [
    "cnt =0\n",
    "serendipity = 0\n",
    "for row in out.iterrows():\n",
    "    row_values = row[1]\n",
    "    top_10 = predict_df.loc[top_10_recs[top_10_recs['user_id'] == row_values['user_id']].level_2]['business_id']\n",
    "    ###In top 10\n",
    "    if row_values['business_id'] in top_10.values:\n",
    "        cnt+=1\n",
    "    user_history = ratings_train_final[ratings_train_final['user_id'] == row_values['user_id']]    \n",
    "    been_there = [i for i in top_10.values if i in  user_history.business_id.values]\n",
    "    serendipity += 1-len(been_there)/10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2ylHkaMQzpo0"
   },
   "source": [
    "##### Inclusion of Last Review in Top 10 Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "3qnqgccSqz8N",
    "outputId": "7933849f-f59b-49d5-ee05-8e753afcd798"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1967479674796748"
      ]
     },
     "execution_count": 58,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt/len(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-npOsGnLzylw"
   },
   "source": [
    "#### Novelty(% of new restaurants in top 10 recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "nLVvzmSgq0F3",
    "outputId": "21a2d4cb-31ad-4ea7-ed39-52adcca88b65"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9634146341463387"
      ]
     },
     "execution_count": 59,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serendipity/len(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OdU5aij8q0Jz"
   },
   "outputs": [],
   "source": [
    "predict_df = predict_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "OhWnlJlRq0D0",
    "outputId": "cf6ca08b-377a-4e0e-b929-5d965cb4b533"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['level_0', 'index', 'user_id', 'business_city', 'business_state',\n",
       "       'business_id', 'business_city_state', 'predictions', 'rankings'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 61,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "colab_type": "code",
    "id": "d8NoYo-_q0BZ",
    "outputId": "d006ceaa-38cd-4061-9a38-073a0927aa99"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_city</th>\n",
       "      <th>level_2</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-038R5cSkXqsYl_bVdT3XQ</td>\n",
       "      <td>Pittsburgh</td>\n",
       "      <td>627574</td>\n",
       "      <td>5.056846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  user_id business_city  level_2  predictions\n",
       "0  -038R5cSkXqsYl_bVdT3XQ    Pittsburgh   627574     5.056846"
      ]
     },
     "execution_count": 62,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_10_recs.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "colab_type": "code",
    "id": "x_3vNgyZqz_b",
    "outputId": "ad7d40a6-6b40-433f-8130-f6b6d7293e79"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_city</th>\n",
       "      <th>business_state</th>\n",
       "      <th>business_id</th>\n",
       "      <th>business_city_state</th>\n",
       "      <th>predictions</th>\n",
       "      <th>rankings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>B7Baf7gCAFDtC9zjBsYP4Q</td>\n",
       "      <td>Airdrie</td>\n",
       "      <td>AB</td>\n",
       "      <td>Gq5Hb2yr2O3_jLWY4XXcZg</td>\n",
       "      <td>AirdrieAB</td>\n",
       "      <td>3.712724</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   level_0  index  ... predictions rankings\n",
       "0        0      0  ...    3.712724     74.0\n",
       "\n",
       "[1 rows x 9 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VINNqvNPrDMZ"
   },
   "outputs": [],
   "source": [
    "analysis_df = predict_df.merge(top_10_recs, left_on = ['user_id','business_city','index'], right_on = ['user_id','business_city','level_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "lI8JXFnqrDjc",
    "outputId": "6564169c-6a3e-4c63-fa32-03ba1fd7161b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 65,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all(analysis_df.groupby('business_city')['business_id'].count() ==50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1BzHo5qVz33g"
   },
   "source": [
    "#### Coverage(% of unique recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "_zvl2iWirD0Q",
    "outputId": "21fe4808-a654-4a87-dcfa-aac7f69c99de"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20325203252032523"
      ]
     },
     "execution_count": 66,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(analysis_df.groupby('business_city')['business_id'].nunique()/50).values.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZwJxLq7frD37"
   },
   "outputs": [],
   "source": [
    "predict_df['rankings']=predict_df.groupby(['business_city','user_id'])['predictions'].rank(\"first\",ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zqBgeEyJrDyS"
   },
   "outputs": [],
   "source": [
    "running_rankings =0\n",
    "for row in out.iterrows():\n",
    "    row_values = row[1]\n",
    "    user_recs = predict_df[(predict_df['user_id']==row_values['user_id'])\n",
    "                        &(predict_df['business_city']==row_values['business_city'])\n",
    "                         & (predict_df['business_id']==row_values['business_id'])\n",
    "                          ]\n",
    "    assert len(user_recs)==1\n",
    "    running_rankings += user_recs['rankings'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K2LHBqYGz6sh"
   },
   "source": [
    "#### Average Ranking of Last Positive Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "g5xr4-MorDwG",
    "outputId": "19051946-8e4a-4270-ecc2-3e9f689b1859"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "453.1268292682927"
      ]
     },
     "execution_count": 69,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "running_rankings / len(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7wb0n8qfrDtc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n-mj7Wj5rDq1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Uo_CQ3G8rDpP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uPG9zj1HrDn4"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "VAE_RecSys.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
