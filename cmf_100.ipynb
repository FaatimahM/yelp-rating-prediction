{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yelp Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset Documentation: <br>\n",
    "https://www.yelp.com/dataset/documentation/main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from cmfrec import CMF\n",
    "import pycmf\n",
    "\n",
    "import time\n",
    "from copy import deepcopy\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from surprise import SVD\n",
    "from surprise import accuracy\n",
    "from surprise import Reader\n",
    "from surprise.model_selection import GridSearchCV\n",
    "from surprise import Dataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tarfile\n",
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 192609/192609 [00:02<00:00, 72168.99it/s]\n"
     ]
    }
   ],
   "source": [
    "# load business.json\n",
    "# 192609 unique businesses?\n",
    "line_count = len(open(\"./yelp_dataset/business.json\").readlines())\n",
    "business_ids, cities, states, latitudes, longitudes, stars, review_counts, attributes, categories = [], [], [], [], [], [], [], [], []\n",
    "with open(\"./yelp_dataset/business.json\") as f:\n",
    "    for line in tqdm(f, total=line_count):\n",
    "        blob = json.loads(line)\n",
    "        business_ids += [blob[\"business_id\"]]\n",
    "        cities += [blob[\"city\"]]\n",
    "        states += [blob[\"state\"]]\n",
    "        latitudes += [blob[\"latitude\"]]\n",
    "        longitudes += [blob[\"longitude\"]]\n",
    "        stars += [blob[\"stars\"]]\n",
    "        review_counts += [blob[\"review_count\"]]\n",
    "        attributes += [blob[\"attributes\"]]\n",
    "        categories += [blob[\"categories\"]]\n",
    "        \n",
    "businesses = pd.DataFrame(\n",
    "    {\"business_id\": business_ids, \"city\": cities, \"state\": states, \"latitude\": latitudes, \"longitude\": longitudes, \"stars\": stars, \"review_counts\": review_counts, \"attributes\": attributes, \"categories\":categories }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1637138/1637138 [00:21<00:00, 75685.86it/s]\n"
     ]
    }
   ],
   "source": [
    "# load user.json\n",
    "# 1637138 unique users?\n",
    "line_count = len(open(\"./yelp_dataset/user.json\").readlines())\n",
    "users, review_counts, elites, average_stars, friends = [], [], [], [], []\n",
    "with open(\"./yelp_dataset/user.json\") as f:\n",
    "    for line in tqdm(f, total=line_count):\n",
    "        blob = json.loads(line)\n",
    "        users += [blob[\"user_id\"]]\n",
    "        review_counts += [blob[\"review_count\"]]\n",
    "        elites += [blob[\"elite\"]]\n",
    "        average_stars += [blob[\"average_stars\"]]\n",
    "        friends += [blob[\"friends\"]]\n",
    "        \n",
    "users = pd.DataFrame(\n",
    "    {\"user_id\": users, \"review_count\": review_counts,\"elite\": elites, \"average_stars\": average_stars, \"friends\": friends}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6685900/6685900 [00:58<00:00, 113366.86it/s]\n"
     ]
    }
   ],
   "source": [
    "# load review.json\n",
    "# 6685900 unique reviews?\n",
    "line_count = len(open(\"./yelp_dataset/review.json\").readlines())\n",
    "user_ids, business_ids, stars, dates, texts = [], [], [], [], []\n",
    "with open(\"./yelp_dataset/review.json\") as f:\n",
    "    for line in tqdm(f, total=line_count):\n",
    "        blob = json.loads(line)\n",
    "        user_ids += [blob[\"user_id\"]]\n",
    "        business_ids += [blob[\"business_id\"]]\n",
    "        stars += [blob[\"stars\"]]\n",
    "        dates += [blob[\"date\"]]\n",
    "        texts += [blob[\"text\"]]\n",
    "reviews = pd.DataFrame(\n",
    "    {\"user_id\": user_ids, \"business_id\": business_ids, \"rating\": stars, \"date\": dates, \"text\": texts}\n",
    ")\n",
    "user_counts = reviews[\"user_id\"].value_counts()\n",
    "active_users = user_counts.loc[user_counts >= 5].index.tolist()\n",
    "reviews = reviews.loc[reviews.user_id.isin(active_users)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(df):\n",
    "    df = df.drop(df.columns[0], axis =1)\n",
    "    df['date']  = pd.to_datetime(df['date'])\n",
    "    df['week_day'] = df['date'].dt.weekday\n",
    "    df['month'] = df['date'].dt.month\n",
    "    df['hour'] = df['date'].dt.hour\n",
    "    df = df.merge(users, on = 'user_id')\n",
    "    df = df.merge(businesses, on = 'business_id')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data: 20%, 50%, 100%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bowenzhou/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3049: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "ratings_holdout_20 = pd.read_csv('data/ratings_sample_holdout_20.csv')\n",
    "ratings_train_20 = pd.read_csv('data/ratings_sample_train_20.csv')\n",
    "ratings_val_20 = pd.read_csv('data/ratings_sample_cv_20.csv')\n",
    "\n",
    "ratings_holdout_50 = pd.read_csv('data/ratings_sample_holdout_50.csv')\n",
    "ratings_val_50 = pd.read_csv('data/ratings_sample_cv_50.csv')\n",
    "ratings_train_50 = pd.read_csv('data/ratings_sample_train_50.csv')\n",
    "\n",
    "ratings_holdout_100 = pd.read_csv('data/ratings_sample_holdout_100.csv')\n",
    "ratings_train_100 = pd.read_csv('data/ratings_sample_train_100.csv')\n",
    "ratings_val_100 = pd.read_csv('data/ratings_sample_cv_100.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_train_20 = process(ratings_train_20.copy())\n",
    "ratings_holdout_20 = process(ratings_holdout_20.copy())\n",
    "ratings_val_20 = process(ratings_val_20.copy())\n",
    "\n",
    "ratings_train_50 = process(ratings_train_50.copy())\n",
    "ratings_holdout_50 = process(ratings_holdout_50.copy())\n",
    "ratings_val_50 = process(ratings_val_50.copy())\n",
    "\n",
    "ratings_val_100 = process(ratings_val_100.copy())\n",
    "ratings_train_100 = process(ratings_train_100.copy())\n",
    "ratings_holdout_100 = process(ratings_holdout_100.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_test_20 = ratings_holdout_20.loc[ratings_holdout_20.business_id.isin(ratings_train_20.business_id)]\n",
    "ratings_val_20 = ratings_val_20.loc[ratings_val_20.business_id.isin(ratings_train_20.business_id)]\n",
    "\n",
    "ratings_test_50 = ratings_holdout_50.loc[ratings_holdout_50.business_id.isin(ratings_train_50.business_id)]\n",
    "ratings_val_50 = ratings_val_50.loc[ratings_val_50.business_id.isin(ratings_train_50.business_id)]\n",
    "\n",
    "ratings_test_100 = ratings_holdout_100.loc[ratings_holdout_100.business_id.isin(ratings_train_100.business_id)]\n",
    "ratings_val_100 = ratings_val_100.loc[ratings_val_100.business_id.isin(ratings_train_100.business_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset_20 = ratings_train_20.iloc[:,0:3]\n",
    "trainset_20.columns = ['userID', 'itemID','rating']\n",
    "valset_20 = ratings_val_20.iloc[:, 0:3]\n",
    "valset_20.columns = ['userID', 'itemID','rating']\n",
    "testset_20 = ratings_holdout_20.iloc[:, 0:3]\n",
    "testset_20.columns = ['userID', 'itemID','rating']\n",
    "\n",
    "trainset_50 = ratings_train_50.iloc[:,0:3]\n",
    "trainset_50.columns = ['userID', 'itemID','rating']\n",
    "valset_50 = ratings_val_50.iloc[:, 0:3]\n",
    "valset_50.columns = ['userID', 'itemID','rating']\n",
    "testset_50 = ratings_holdout_50.iloc[:, 0:3]\n",
    "testset_50.columns = ['userID', 'itemID','rating']\n",
    "\n",
    "trainset_100 = ratings_train_100.iloc[:,0:3]\n",
    "trainset_100.columns = ['userID', 'itemID','rating']\n",
    "valset_100 = ratings_val_100.iloc[:, 0:3]\n",
    "valset_100.columns = ['userID', 'itemID','rating']\n",
    "testset_100 = ratings_holdout_100.iloc[:, 0:3]\n",
    "testset_100.columns = ['userID', 'itemID','rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_train_final_20 = ratings_train_20.append(ratings_val_20)\n",
    "ratings_train_final_50 = ratings_train_50.append(ratings_val_50)\n",
    "ratings_train_final_100 = ratings_train_100.append(ratings_val_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_entire_df_20 = ratings_train_20.append(ratings_val_20).append(ratings_holdout_20)\n",
    "ratings_entire_df_50 = ratings_train_50.append(ratings_val_50).append(ratings_holdout_50)\n",
    "ratings_entire_df_100 = ratings_train_100.append(ratings_val_100).append(ratings_holdout_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_city_businesses_20 = ratings_entire_df_20[['city','business_id']].drop_duplicates()\n",
    "unique_cities_20 = unique_city_businesses_20.groupby('city').count()['business_id']\n",
    "unique_cities_20 = unique_cities_20[unique_cities_20 > 100]\n",
    "out_20 = pd.DataFrame()\n",
    "for city in unique_cities_20.index:\n",
    "    tmp = ratings_holdout_20[(ratings_holdout_20['city'] ==city) &\n",
    "                              (ratings_holdout_20['rating'] >ratings_holdout_20['average_stars'])]\n",
    "    if len(tmp['user_id'].unique())>4:\n",
    "        \n",
    "        ###this weird sampling technique is to ensure we dont' sample the same user twice in a same city\n",
    "        five_users = np.random.choice(tmp['user_id'].unique(),5, replace = False)\n",
    "        row = tmp[tmp['user_id'].isin(five_users)].groupby('user_id', group_keys=False).apply(lambda df: df.sample(1))\n",
    "        out_20 = out_20.append(row)\n",
    "        \n",
    "unique_city_businesses_50 = ratings_entire_df_50[['city','business_id']].drop_duplicates()\n",
    "unique_cities_50 = unique_city_businesses_50.groupby('city').count()['business_id']\n",
    "unique_cities_50 = unique_cities_50[unique_cities_50 > 100]\n",
    "out_50 = pd.DataFrame()\n",
    "for city in unique_cities_50.index:\n",
    "    tmp = ratings_holdout_50[(ratings_holdout_50['city'] ==city) &\n",
    "                              (ratings_holdout_50['rating'] >ratings_holdout_50['average_stars'])]\n",
    "    if len(tmp['user_id'].unique())>4:\n",
    "        \n",
    "        ###this weird sampling technique is to ensure we dont' sample the same user twice in a same city\n",
    "        five_users = np.random.choice(tmp['user_id'].unique(),5, replace = False)\n",
    "        row = tmp[tmp['user_id'].isin(five_users)].groupby('user_id', group_keys=False).apply(lambda df: df.sample(1))\n",
    "        out_50 = out_50.append(row)\n",
    "        \n",
    "unique_city_businesses_100 = ratings_entire_df_100[['city','business_id']].drop_duplicates()\n",
    "unique_cities_100 = unique_city_businesses_100.groupby('city').count()['business_id']\n",
    "unique_cities_100 = unique_cities_100[unique_cities_100 > 100]\n",
    "out_100 = pd.DataFrame()\n",
    "for city in unique_cities_100.index:\n",
    "    tmp = ratings_holdout_100[(ratings_holdout_100['city'] ==city) &\n",
    "                              (ratings_holdout_100['rating'] >ratings_holdout_100['average_stars'])]\n",
    "    if len(tmp['user_id'].unique())>4:\n",
    "        \n",
    "        ###this weird sampling technique is to ensure we dont' sample the same user twice in a same city\n",
    "        five_users = np.random.choice(tmp['user_id'].unique(),5, replace = False)\n",
    "        row = tmp[tmp['user_id'].isin(five_users)].groupby('user_id', group_keys=False).apply(lambda df: df.sample(1))\n",
    "        out_100 = out_100.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_df_20 = out_20[['user_id','city','state']]\n",
    "predict_df_20 = predict_df_20.merge(unique_city_businesses_20, on = 'city')\n",
    "predict_df_20['predictions'] = 25\n",
    "\n",
    "predict_df_50 = out_50[['user_id','city','state']]\n",
    "predict_df_50 = predict_df_50.merge(unique_city_businesses_50, on = 'city')\n",
    "predict_df_50['predictions'] = 25\n",
    "\n",
    "predict_df_100 = out_50[['user_id','city','state']]\n",
    "predict_df_100 = predict_df_100.merge(unique_city_businesses_100, on = 'city')\n",
    "predict_df_100['predictions'] = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for cmfrec package\n",
    "# universal X_train_20, 50, 100\n",
    "X_train_20 = trainset_20\n",
    "X_train_20.columns = ['UserId','ItemId','Rating']\n",
    "\n",
    "X_train_50 = trainset_50\n",
    "X_train_50.columns = ['UserId','ItemId','Rating']\n",
    "\n",
    "X_train_100 = trainset_100\n",
    "X_train_100.columns = ['UserId','ItemId','Rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# universal X_test_20, 50, 100\n",
    "X_test_20 = testset_20\n",
    "X_test_20.columns = ['UserId','ItemId','Rating']\n",
    "\n",
    "\n",
    "X_test_50 = testset_50\n",
    "X_train_50.columns = ['UserId','ItemId','Rating']\n",
    "\n",
    "X_test_100 = testset_100\n",
    "X_train_100.columns = ['UserId','ItemId','Rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# universal X_val_20\n",
    "X_val_20 = valset_20\n",
    "X_val_20.columns = ['UserId','ItemId','Rating']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. State Average Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get state average rating\n",
    "state_avg_20 = pd.DataFrame(ratings_train_20.groupby(\"state\").rating.mean())\n",
    "state_avg_20.columns = ['state_avg']\n",
    "train_state_avg_20 = ratings_train_20.merge(state_avg_20, on = \"state\")\n",
    "\n",
    "state_avg_50 = pd.DataFrame(ratings_train_50.groupby(\"state\").rating.mean())\n",
    "state_avg_50.columns = ['state_avg']\n",
    "train_state_avg_50 = ratings_train_50.merge(state_avg_50, on = \"state\")\n",
    "\n",
    "state_avg_100 = pd.DataFrame(ratings_train_100.groupby(\"state\").rating.mean())\n",
    "state_avg_100.columns = ['state_avg']\n",
    "train_state_avg_100 = ratings_train_100.merge(state_avg_100, on = \"state\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# item additional info: state average\n",
    "item_avg_20 = train_state_avg_20.loc[:,['business_id','state_avg']]\n",
    "item_avg_20.columns = ['ItemId','state_avg']\n",
    "\n",
    "item_avg_50 = train_state_avg_50.loc[:,['business_id','state_avg']]\n",
    "item_avg_50.columns = ['ItemId','state_avg']\n",
    "\n",
    "item_avg_100 = train_state_avg_100.loc[:,['business_id','state_avg']]\n",
    "item_avg_100.columns = ['ItemId','state_avg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "tune = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_main = [0.5, 5.0, 10.0] # weight assign to the MRSE in factorization of the ratings matrix\n",
    "w_item = [0.5, 5.0, 10.0][::-1] # weight assign to the MRSE in factorization of the item attributes matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "  Objective function value: 0.951550\n",
      "  Number of iterations: 378\n",
      "  Number of functions evaluations: 429\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "  Objective function value: 0.951519\n",
      "  Number of iterations: 307\n",
      "  Number of functions evaluations: 351\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.950972\n",
      "  Number of iterations: 99\n",
      "  Number of functions evaluations: 110\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
      "  Objective function value: 6.175318\n",
      "  Number of iterations: 1000\n",
      "  Number of functions evaluations: 1077\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
      "  Objective function value: 6.163224\n",
      "  Number of iterations: 1000\n",
      "  Number of functions evaluations: 1067\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
      "  Objective function value: 6.151421\n",
      "  Number of iterations: 1000\n",
      "  Number of functions evaluations: 1050\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
      "  Objective function value: 8.763368\n",
      "  Number of iterations: 1000\n",
      "  Number of functions evaluations: 1060\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
      "  Objective function value: 8.714961\n",
      "  Number of iterations: 1000\n",
      "  Number of functions evaluations: 1053\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
      "  Objective function value: 8.669455\n",
      "  Number of iterations: 1000\n",
      "  Number of functions evaluations: 1043\n"
     ]
    }
   ],
   "source": [
    "# tuning\n",
    "for m in w_main:\n",
    "    for i in w_item:\n",
    "        model = CMF(w_main = m, w_item = i, random_seed = 1)\n",
    "        model.fit(ratings = deepcopy(X_train_20), item_info = deepcopy(item_avg_20))\n",
    "        prediction = model.predict(X_val_20.UserId, X_val_20.ItemId)\n",
    "        X_val_20['pred_rating'] = prediction\n",
    "        tune[m,i] = np.sqrt(np.mean((X_val_20.pred_rating - X_val_20.Rating)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0.5, 10.0): 1.4095315793715344,\n",
       " (0.5, 5.0): 1.4095280852831702,\n",
       " (0.5, 0.5): 1.4095288030679354,\n",
       " (5.0, 10.0): 1.325081092000988,\n",
       " (5.0, 5.0): 1.3249653813051294,\n",
       " (5.0, 0.5): 1.325319757480712,\n",
       " (10.0, 10.0): 1.3303194326966257,\n",
       " (10.0, 5.0): 1.3291943801778212,\n",
       " (10.0, 0.5): 1.329444185787565}"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Best param: w_main = 5.0, w_item = 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bowenzhou/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gradients_impl.py:107: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 123108660 elements. This may consume a large amount of memory.\n",
      "  num_elements)\n"
     ]
    }
   ],
   "source": [
    "# 100%\n",
    "model = CMF(w_main = 5.0, w_item = 5.0, random_seed = 1)\n",
    "start_time = time.time()\n",
    "model.fit(ratings = deepcopy(X_train_100), item_info = deepcopy(item_avg_100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_prediction_100 = model.predict(X_test_100.UserId, X_test_100.ItemId)\n",
    "X_test_100['pred_rating'] = state_prediction_100\n",
    "print('RMSE (with 100% data): ', np.sqrt(np.mean((X_test_100.pred_rating - X_test_100.Rating)**2)))\n",
    "print('R^2 (with 100% data): ', r2_score(X_test_100.Rating , X_test_100.pred_rating))\n",
    "print('MAE (with 100% data): ', mean_absolute_error(X_test_100.Rating , X_test_100.pred_rating))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CMF(w_main = m, w_item = i, random_seed = 1)\n",
    "model.fit(ratings = deepcopy(X_train_100), item_info = deepcopy(item_avg_100))\n",
    "predict_df_100['predictions'] = model.predict(predict_df_100.user_id, predict_df_100.business_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10, coverage, serendipity, avg_rank = get_all_metrics(predict_df_100, out_100, ratings_train_final_100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. State Location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Transforming Data and Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encode\n",
    "df_state_20 = pd.get_dummies(ratings_train_20.state)\n",
    "df_state_50 = pd.get_dummies(ratings_train_50.state)\n",
    "df_state_100 = pd.get_dummies(ratings_train_100.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_loc_20 = ratings_train_20.loc[:,['business_id']]\n",
    "state_loc_20.columns = ['ItemId']\n",
    "state_loc_20 = state_loc_20.join(df_state_20)\n",
    "\n",
    "state_loc_50 = ratings_train_50.loc[:,['business_id']]\n",
    "state_loc_50.columns = ['ItemId']\n",
    "state_loc_50 = state_loc_50.join(df_state_50)\n",
    "\n",
    "state_loc_100 = ratings_train_100.loc[:,['business_id']]\n",
    "state_loc_100.columns = ['ItemId']\n",
    "state_loc_100 = state_loc_100.join(df_state_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "tune_2 = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_main = [0.5, 5.0, 10.0] # weight assign to the MRSE in factorization of the ratings matrix\n",
    "w_item = [0.5, 5.0, 10.0][::-1] # weight assign to the MRSE in factorization of the item attributes matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 1.502233\n",
      "  Number of iterations: 48\n",
      "  Number of functions evaluations: 59\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 1.345407\n",
      "  Number of iterations: 49\n",
      "  Number of functions evaluations: 61\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.946406\n",
      "  Number of iterations: 46\n",
      "  Number of functions evaluations: 58\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
      "  Objective function value: 6.707548\n",
      "  Number of iterations: 1000\n",
      "  Number of functions evaluations: 1050\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
      "  Objective function value: 6.544841\n",
      "  Number of iterations: 1000\n",
      "  Number of functions evaluations: 1054\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
      "  Objective function value: 6.147314\n",
      "  Number of iterations: 1000\n",
      "  Number of functions evaluations: 1050\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
      "  Objective function value: 9.238955\n",
      "  Number of iterations: 1000\n",
      "  Number of functions evaluations: 1047\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
      "  Objective function value: 9.068397\n",
      "  Number of iterations: 1000\n",
      "  Number of functions evaluations: 1045\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
      "  Objective function value: 8.660084\n",
      "  Number of iterations: 1000\n",
      "  Number of functions evaluations: 1044\n"
     ]
    }
   ],
   "source": [
    "# tuning\n",
    "for m in w_main:\n",
    "    for i in w_item:\n",
    "        model = CMF(w_main = m, w_item = i, random_seed = 1)\n",
    "        model.fit(ratings = deepcopy(X_train_20), item_info = deepcopy(state_loc_20),\\\n",
    "            cols_bin_item=[cl for cl in state_loc_20.columns if cl != 'ItemId'])\n",
    "        prediction = model.predict(X_val_20.UserId, X_val_20.ItemId)\n",
    "        X_val_20['pred_rating'] = prediction\n",
    "        tune_2[m,i] = np.sqrt(np.mean((X_val_20.pred_rating - X_val_20.Rating)**2))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0.5, 10.0): 1.4091453521706512,\n",
       " (0.5, 5.0): 1.4093103607696387,\n",
       " (0.5, 0.5): 1.4096837868418028,\n",
       " (5.0, 10.0): 1.3255848781332549,\n",
       " (5.0, 5.0): 1.3253454951331827,\n",
       " (5.0, 0.5): 1.3255074066479042,\n",
       " (10.0, 10.0): 1.3287372061500575,\n",
       " (10.0, 5.0): 1.3285188529615481,\n",
       " (10.0, 0.5): 1.3288867514741107}"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the best param: w_main = 5.0, w_item = 5.0\n",
    "tune_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100%\n",
    "model = CMF(w_main = 5.0, w_item = 5.0, random_seed = 1)\n",
    "start_time = time.time()\n",
    "model.fit(ratings = deepcopy(X_train_100), item_info = deepcopy(state_loc_100),\\\n",
    "            cols_bin_item=[cl for cl in state_loc_100.columns if cl != 'ItemId'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_prediction_100 = model.predict(X_test_100.UserId, X_test_100.ItemId)\n",
    "X_test_100['pred_rating'] = loc_prediction_100\n",
    "print('RMSE (with 100% data): ', np.sqrt(np.mean((X_test_100.pred_rating - X_test_100.Rating)**2)))\n",
    "print('R^2 (with 100% data): ', r2_score(X_test_100.Rating , X_test_100.pred_rating))\n",
    "print('MAE (with 100% data): ', mean_absolute_error(X_test_100.Rating , X_test_100.pred_rating))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-8de69cb1a395>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCMF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw_main\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_item\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m model.fit(ratings = deepcopy(X_train_20), item_info = deepcopy(state_loc_20),\\\n\u001b[1;32m      3\u001b[0m             cols_bin_item=[cl for cl in state_loc_20.columns if cl != 'ItemId'])\n\u001b[1;32m      4\u001b[0m \u001b[0mpredict_df_20\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'predictions'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict_df_20\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_df_20\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbusiness_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'm' is not defined"
     ]
    }
   ],
   "source": [
    "model = CMF(w_main = 5.0, w_item = 5.0, random_seed = 1)\n",
    "model.fit(ratings = deepcopy(X_train_100), item_info = deepcopy(state_loc_100),\\\n",
    "            cols_bin_item=[cl for cl in state_loc_100.columns if cl != 'ItemId'])\n",
    "predict_df_100['predictions'] = model.predict(predict_df_100.user_id, predict_df_100.business_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10, coverage, serendipity, avg_rank = get_all_metrics(predict_df_100, out_100, ratings_train_final_100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. User Average Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get state average rating\n",
    "user_avg_20 = pd.DataFrame(ratings_train_20.groupby(\"user_id\").rating.mean())\n",
    "user_avg_20.columns = ['user_avg']\n",
    "user_avg_20 = ratings_train_20.merge(user_avg_20, on = \"user_id\")\n",
    "\n",
    "user_avg_50 = pd.DataFrame(ratings_train_50.groupby(\"user_id\").rating.mean())\n",
    "user_avg_50.columns = ['user_avg']\n",
    "user_avg_50 = ratings_train_50.merge(user_avg_50, on = \"user_id\")\n",
    "\n",
    "user_avg_100 = pd.DataFrame(ratings_train_100.groupby(\"user_id\").rating.mean())\n",
    "user_avg_100.columns = ['user_avg']\n",
    "user_avg_100 = ratings_train_100.merge(user_avg_100, on = \"user_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user additional info: user average\n",
    "user_info_20 = user_avg_20.loc[:,['user_id','user_avg']]\n",
    "user_info_20.columns = ['UserId','state_avg']\n",
    "\n",
    "user_info_50 = user_avg_50.loc[:,['user_id','user_avg']]\n",
    "user_info_50.columns = ['UserId','state_avg']\n",
    "\n",
    "user_info_100 = user_avg_100.loc[:,['user_id','user_avg']]\n",
    "user_info_100.columns = ['UserId','state_avg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "tune_3 = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_main = [0.5, 5.0, 10.0] # weight assign to the MRSE in factorization of the ratings matrix\n",
    "w_user = [0.5, 5.0, 10.0][::-1] # weight assign to the MRSE in factorization of the user attributes matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "  Objective function value: 0.912842\n",
      "  Number of iterations: 463\n",
      "  Number of functions evaluations: 530\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "  Objective function value: 0.912821\n",
      "  Number of iterations: 378\n",
      "  Number of functions evaluations: 436\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.912564\n",
      "  Number of iterations: 131\n",
      "  Number of functions evaluations: 147\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
      "  Objective function value: 6.144692\n",
      "  Number of iterations: 1000\n",
      "  Number of functions evaluations: 1085\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
      "  Objective function value: 6.126369\n",
      "  Number of iterations: 1000\n",
      "  Number of functions evaluations: 1064\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
      "  Objective function value: 6.111398\n",
      "  Number of iterations: 1000\n",
      "  Number of functions evaluations: 1046\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
      "  Objective function value: 8.808755\n",
      "  Number of iterations: 1000\n",
      "  Number of functions evaluations: 1096\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
      "  Objective function value: 8.702769\n",
      "  Number of iterations: 1000\n",
      "  Number of functions evaluations: 1061\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
      "  Objective function value: 8.629791\n",
      "  Number of iterations: 1000\n",
      "  Number of functions evaluations: 1034\n"
     ]
    }
   ],
   "source": [
    "# tuning\n",
    "for m in w_main:\n",
    "    for i in w_user:\n",
    "        model = CMF(w_main = m, w_user = i, random_seed = 1)\n",
    "        model.fit(ratings = deepcopy(X_train_20), user_info = deepcopy(user_info_20))\n",
    "        prediction = model.predict(X_val_20.UserId, X_val_20.ItemId)\n",
    "        X_val_20['pred_rating'] = prediction\n",
    "        tune_3[m,i] = np.sqrt(np.mean((X_val_20.pred_rating - X_val_20.Rating)**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0.5, 10.0): 1.4093796110241372,\n",
       " (0.5, 5.0): 1.4093675138007682,\n",
       " (0.5, 0.5): 1.409379510028695,\n",
       " (5.0, 10.0): 1.3243942755866573,\n",
       " (5.0, 5.0): 1.3248028150484914,\n",
       " (5.0, 0.5): 1.3249520550165859,\n",
       " (10.0, 10.0): 1.3290478291921621,\n",
       " (10.0, 5.0): 1.3281606768811247,\n",
       " (10.0, 0.5): 1.327849756600441}"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the best param: w_main = 5.0, w_user = 10.0\n",
    "tune_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 50%\n",
    "model = CMF(w_main = 5.0, w_user = 10.0, random_seed = 1)\n",
    "start_time = time.time()\n",
    "model.fit(ratings = deepcopy(X_train_50), item_info = deepcopy(user_info_50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_50 = X_test_50.loc[X_test_50.ItemId.isin(X_train_50.ItemId)]\n",
    "X_test_100 = X_test_100.loc[X_test_100.ItemId.isin(X_train_100.ItemId)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prediction_50 = model_1_tune.predict(X_test_50.UserId, X_test_50.ItemId)\n",
    "X_test_50['pred_rating'] = user_prediction_50\n",
    "print('RMSE (with 50% data): ', np.sqrt(np.mean((X_test_50.pred_rating - X_test_50.rating)**2)))\n",
    "print('R^2 (with 50% data): ', r2_score(X_test_50.Rating , X_test_50.pred_rating))\n",
    "print('MAE (with 50% data): ', mean_absolute_error(X_test_50.Rating , X_test_50.pred_rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100%\n",
    "model = CMF(w_main = 5.0, w_user = 10.0, random_seed = 1)\n",
    "start_time = time.time()\n",
    "model.fit(ratings = deepcopy(X_train_100), item_info = deepcopy(user_info_100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prediction_100 = model.predict(X_test_100.UserId, X_test_100.ItemId)\n",
    "X_test_100['pred_rating'] = user_prediction_100\n",
    "print('RMSE (with 100% data): ', np.sqrt(np.mean((X_test_100.pred_rating - X_test_100.rating)**2)))\n",
    "print('R^2 (with 100% data): ', r2_score(X_test_100.Rating , X_test_100.pred_rating))\n",
    "print('MAE (with 100% data): ', mean_absolute_error(X_test_100.Rating , X_test_100.pred_rating))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CMF(w_main = 5.0, w_user = 10.0, random_seed = 1)\n",
    "model.fit(ratings = deepcopy(X_train_50), user_info = deepcopy(user_info_50))\n",
    "predict_df_50['predictions'] = model.predict(predict_df_50.user_id, predict_df_50.business_id)\n",
    "\n",
    "model = CMF(w_main = 5.0, w_user = 10.0, random_seed = 1)\n",
    "model.fit(ratings = deepcopy(X_train_100), user_info = deepcopy(user_info_100))\n",
    "predict_df_100['predictions'] = model.predict(predict_df_100.user_id, predict_df_100.business_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1357142857142857 0.2580952380952381 0.9699999999999993 470.53333333333336\n"
     ]
    }
   ],
   "source": [
    "top_10, coverage, serendipity, avg_rank = get_all_metrics(predict_df_50, out_50, ratings_train_final_50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10, coverage, serendipity, avg_rank = get_all_metrics(predict_df_100, out_100, ratings_train_final_100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
