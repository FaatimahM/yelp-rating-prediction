{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yelp Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset Documentation: <br>\n",
    "https://www.yelp.com/dataset/documentation/main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tarfile\n",
    "from tqdm import tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "?rw-r--r-- daniellg/users  138279749 2018-11-15 11:22:39 business.json \n",
      "?rw-r--r-- daniellg/users  408807658 2018-11-15 11:25:00 checkin.json \n",
      "?rw-r--r-- daniellg/users 5347475638 2018-11-15 11:35:37 review.json \n",
      "?rw-r--r-- daniellg/users  244535478 2018-11-15 11:26:18 tip.json \n",
      "?rw-r--r-- daniellg/users 2485747393 2018-11-15 11:24:48 user.json \n",
      "?rw-r--r-- daniellg/users   25661152 2019-01-11 19:06:09 photo.json \n",
      "?rw-r--r-- daniellg/users     101186 2019-01-14 11:31:35 Dataset_Challenge_Dataset_Agreement.pdf \n",
      "?rw-r--r-- daniellg/users     111822 2019-01-14 11:35:09 Yelp_Dataset_Challenge_Round_13.pdf \n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-51f9ab60ecd7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mzf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'yelp_dataset.tar'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#df = pd.read_csv(zf.open('intfile.csv'))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "zf = tarfile.open('yelp_dataset.tar') \n",
    "#df = pd.read_csv(zf.open('intfile.csv'))\n",
    "for name in zf.list():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feel free to extract more files here\n",
    "zf.extract(\"review.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6685900/6685900 [01:37<00:00, 68835.62it/s]\n"
     ]
    }
   ],
   "source": [
    "line_count = len(open(\"review.json\").readlines())\n",
    "user_ids, business_ids, stars, dates, texts = [], [], [], [], []\n",
    "with open(\"review.json\") as f:\n",
    "    for line in tqdm(f, total=line_count):\n",
    "        blob = json.loads(line)\n",
    "        user_ids += [blob[\"user_id\"]]\n",
    "        business_ids += [blob[\"business_id\"]]\n",
    "        stars += [blob[\"stars\"]]\n",
    "        dates += [blob[\"date\"]]\n",
    "        texts += [blob[\"text\"]]\n",
    "ratings = pd.DataFrame(\n",
    "    {\"user_id\": user_ids, \"business_id\": business_ids, \"rating\": stars, \"date\": dates, \"text\": texts}\n",
    ")\n",
    "user_counts = ratings[\"user_id\"].value_counts()\n",
    "active_users = user_counts.loc[user_counts >= 5].index.tolist()\n",
    "ratings = ratings.loc[ratings.user_id.isin(active_users)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CxDOIDnH8gp9KXzpBHJYXw',\n",
       " 'bLbSNkLggFnqwNNzzq-Ijw',\n",
       " 'PKEzKWv_FktMm2mGPjwd0Q',\n",
       " 'ELcQDlf69kb-ihJfxZyL0A',\n",
       " 'DK57YibC5ShBmqQl97CKog']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "active_users[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hG7b0MtEbXx5QzbzE6C_VA</td>\n",
       "      <td>ujmEBvifdJM6h6RLv4wQIg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013-05-07 04:34:36</td>\n",
       "      <td>Total bill for this horrible service? Over $8G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>n6-Gk65cPZL6Uz8qRm3NYw</td>\n",
       "      <td>WTqjgwHlXbSFevF32_DJVw</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2016-11-09 20:09:03</td>\n",
       "      <td>I have to say that this office really has it t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>jlu4CztcSxrKx56ba1a5AQ</td>\n",
       "      <td>3fw2X5bZYeW9xCz_zGhOHg</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2016-05-07 01:21:02</td>\n",
       "      <td>Tracy dessert had a big name in Hong Kong and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>d6xvYpyzcfbF_AZ8vMB7QA</td>\n",
       "      <td>zvO-PJCpNk4fgAVUnExYAA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2010-10-05 19:12:35</td>\n",
       "      <td>This place has gone down hill.  Clearly they h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sG_h0dIzTKWa3Q6fmb4u-g</td>\n",
       "      <td>b2jN2mm9Wf3RcrZCgfo1cg</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2015-01-18 14:04:18</td>\n",
       "      <td>I was really looking forward to visiting after...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  user_id             business_id  rating  \\\n",
       "0  hG7b0MtEbXx5QzbzE6C_VA  ujmEBvifdJM6h6RLv4wQIg     1.0   \n",
       "2  n6-Gk65cPZL6Uz8qRm3NYw  WTqjgwHlXbSFevF32_DJVw     5.0   \n",
       "6  jlu4CztcSxrKx56ba1a5AQ  3fw2X5bZYeW9xCz_zGhOHg     3.0   \n",
       "7  d6xvYpyzcfbF_AZ8vMB7QA  zvO-PJCpNk4fgAVUnExYAA     1.0   \n",
       "8  sG_h0dIzTKWa3Q6fmb4u-g  b2jN2mm9Wf3RcrZCgfo1cg     2.0   \n",
       "\n",
       "                  date                                               text  \n",
       "0  2013-05-07 04:34:36  Total bill for this horrible service? Over $8G...  \n",
       "2  2016-11-09 20:09:03  I have to say that this office really has it t...  \n",
       "6  2016-05-07 01:21:02  Tracy dessert had a big name in Hong Kong and ...  \n",
       "7  2010-10-05 19:12:35  This place has gone down hill.  Clearly they h...  \n",
       "8  2015-01-18 14:04:18  I was really looking forward to visiting after...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4538272, 5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Users: 286130, unique restaurants: 185723\n"
     ]
    }
   ],
   "source": [
    "n_users = len(ratings.user_id.unique())\n",
    "n_restaurants = len(ratings.business_id.unique())\n",
    "print('Unique Users: {0}, unique restaurants: {1}'.format(n_users, n_restaurants))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "\n",
    "1. Baseline:\n",
    "User based (Bowen)\n",
    "ALS (later)\n",
    "\n",
    "\n",
    "1. Cold start: (<5 reviews)\n",
    "content based (Nearest neighbors on review text, metadata tex) (Zhongling)\n",
    "\n",
    "\n",
    "2. Main model\n",
    "Field-aware factorization machine (James)\n",
    "Locality Sensitive Hashing (Ujjwal)\n",
    "Collective Matrix Factorization (Bowen)\n",
    "\n",
    "\n",
    "Hybrid approach\n",
    "3. Metrics\n",
    "TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train / Holdout "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rating dataset has ~6.6 million rows and is time consuming to perform group by & aggregation operations, which is required for constructing holdout set. Therefore, I randomly subsample 1/10 of users in order to speed up testing. Since we have filtered out inactive users earlier, downsampling will not result in new inactive users. Note that this is not an optimal practice, I did it solely because I want to speed up the data pre-processing and modeling cycle. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratings_sample = ratings.sample(frac= 1/10, replace=False, random_state=1)\n",
    "# Downsample by users\n",
    "user_id_unique = ratings.user_id.unique()\n",
    "user_id_sample = pd.DataFrame(user_id_unique, columns=['unique_user_id']) \\\n",
    "                    .sample(frac= 1/10, replace=False, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  user_id             business_id  rating  \\\n",
      "0  n6-Gk65cPZL6Uz8qRm3NYw  WTqjgwHlXbSFevF32_DJVw     5.0   \n",
      "1  n6-Gk65cPZL6Uz8qRm3NYw  hk5wpV-_pi5jmDDVPeG8DA     5.0   \n",
      "2  n6-Gk65cPZL6Uz8qRm3NYw  30Q5xBagQHmkwp8Q9I1FCg     5.0   \n",
      "3  n6-Gk65cPZL6Uz8qRm3NYw  UtWngqS-WloIY_A53W5K-Q     5.0   \n",
      "4  n6-Gk65cPZL6Uz8qRm3NYw  dU-Nt1-LjV9mAgFOVcdAJw     5.0   \n",
      "\n",
      "                  date                                               text  \n",
      "0  2016-11-09 20:09:03  I have to say that this office really has it t...  \n",
      "1  2018-09-14 18:50:19  I highly recommend Arizona Pet Mortuary, David...  \n",
      "2  2018-02-03 23:27:43  First time at this restaurant our server \"Ramo...  \n",
      "3  2016-02-18 06:42:16  Such an amazing hospital with friendly staff, ...  \n",
      "4  2018-08-15 22:14:18  Went for my yearly GYN exam and was seen by Lo...  \n",
      "(463277, 5)\n"
     ]
    }
   ],
   "source": [
    "ratings_sample = ratings.merge(user_id_sample, left_on='user_id', right_on='unique_user_id') \\\n",
    "                    .drop(['unique_user_id'], axis=1)\n",
    "print(ratings_sample.head())\n",
    "print(ratings_sample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ratings_sample.to_csv('ratings_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hold out last review\n",
    "ratings_user_date = ratings_sample.loc[:, ['user_id', 'date']]\n",
    "ratings_user_date.date = pd.to_datetime(ratings_user_date.date)\n",
    "index_holdout = ratings_user_date.groupby(['user_id'], sort=False)['date'].transform(max) == ratings_user_date['date']\n",
    "ratings_holdout = ratings_sample[index_holdout]\n",
    "ratings_traincv = ratings_sample[~index_holdout]\n",
    "\n",
    "ratings_user_date = ratings_traincv.loc[:, ['user_id', 'date']]\n",
    "index_holdout = ratings_user_date.groupby(['user_id'], sort=False)['date'].transform(max) == ratings_user_date['date']\n",
    "ratings_cv = ratings_traincv[index_holdout]\n",
    "ratings_train = ratings_traincv[~index_holdout]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_cv = ratings_cv[~ratings_cv.user_id.isin(['HiT9sg9pvDiEVMFHJYihXg'])]\n",
    "ratings_holdout = ratings_holdout[~ratings_holdout.user_id.isin(['HiT9sg9pvDiEVMFHJYihXg'])]\n",
    "ratings_holdout.to_csv('ratings_sample_holdout.csv')\n",
    "ratings_cv.to_csv('ratings_sample_cv.csv')\n",
    "ratings_train.to_csv('ratings_sample_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 406042 rows, 5 columns in training set.\n",
      "There are 28615 rows, 5 columns in training set.\n",
      "There are 28612 rows, 5 columns in holdout set.\n"
     ]
    }
   ],
   "source": [
    "print('There are {0} rows, {1} columns in training set.'.format(ratings_train.shape[0], ratings_train.shape[1]))\n",
    "print('There are {0} rows, {1} columns in training set.'.format(ratings_cv.shape[0], ratings_cv.shape[1]))\n",
    "print('There are {0} rows, {1} columns in holdout set.'.format(ratings_holdout.shape[0], ratings_holdout.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
