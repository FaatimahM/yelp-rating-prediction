{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yelp Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset Documentation: <br>\n",
    "https://www.yelp.com/dataset/documentation/main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from cmfrec import CMF\n",
    "import pycmf\n",
    "\n",
    "from surprise import SVD\n",
    "from surprise import accuracy\n",
    "from surprise import Reader\n",
    "from surprise.model_selection import GridSearchCV\n",
    "from surprise import Dataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tarfile\n",
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 192609/192609 [00:02<00:00, 72760.51it/s]\n"
     ]
    }
   ],
   "source": [
    "# load business.json\n",
    "# 192609 unique businesses?\n",
    "line_count = len(open(\"./yelp_dataset/business.json\").readlines())\n",
    "business_ids, cities, states, latitudes, longitudes, stars, review_counts, attributes, categories = [], [], [], [], [], [], [], [], []\n",
    "with open(\"./yelp_dataset/business.json\") as f:\n",
    "    for line in tqdm(f, total=line_count):\n",
    "        blob = json.loads(line)\n",
    "        business_ids += [blob[\"business_id\"]]\n",
    "        cities += [blob[\"city\"]]\n",
    "        states += [blob[\"state\"]]\n",
    "        latitudes += [blob[\"latitude\"]]\n",
    "        longitudes += [blob[\"longitude\"]]\n",
    "        stars += [blob[\"stars\"]]\n",
    "        review_counts += [blob[\"review_count\"]]\n",
    "        attributes += [blob[\"attributes\"]]\n",
    "        categories += [blob[\"categories\"]]\n",
    "        \n",
    "businesses = pd.DataFrame(\n",
    "    {\"business_id\": business_ids, \"city\": cities, \"state\": states, \"latitude\": latitudes, \"longitude\": longitudes, \"stars\": stars, \"review_counts\": review_counts, \"attributes\": attributes, \"categories\":categories }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1637138/1637138 [00:20<00:00, 79512.69it/s] \n"
     ]
    }
   ],
   "source": [
    "# load user.json\n",
    "# 1637138 unique users?\n",
    "line_count = len(open(\"./yelp_dataset/user.json\").readlines())\n",
    "users, review_counts, elites, average_stars, friends = [], [], [], [], []\n",
    "with open(\"./yelp_dataset/user.json\") as f:\n",
    "    for line in tqdm(f, total=line_count):\n",
    "        blob = json.loads(line)\n",
    "        users += [blob[\"user_id\"]]\n",
    "        review_counts += [blob[\"review_count\"]]\n",
    "        elites += [blob[\"elite\"]]\n",
    "        average_stars += [blob[\"average_stars\"]]\n",
    "        friends += [blob[\"friends\"]]\n",
    "        \n",
    "users = pd.DataFrame(\n",
    "    {\"user_id\": users, \"review_count\": review_counts,\"elite\": elites, \"average_stars\": average_stars, \"friends\": friends}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6685900/6685900 [00:55<00:00, 120458.76it/s]\n"
     ]
    }
   ],
   "source": [
    "# load review.json\n",
    "# 6685900 unique reviews?\n",
    "line_count = len(open(\"./yelp_dataset/review.json\").readlines())\n",
    "user_ids, business_ids, stars, dates, texts = [], [], [], [], []\n",
    "with open(\"./yelp_dataset/review.json\") as f:\n",
    "    for line in tqdm(f, total=line_count):\n",
    "        blob = json.loads(line)\n",
    "        user_ids += [blob[\"user_id\"]]\n",
    "        business_ids += [blob[\"business_id\"]]\n",
    "        stars += [blob[\"stars\"]]\n",
    "        dates += [blob[\"date\"]]\n",
    "        texts += [blob[\"text\"]]\n",
    "reviews = pd.DataFrame(\n",
    "    {\"user_id\": user_ids, \"business_id\": business_ids, \"rating\": stars, \"date\": dates, \"text\": texts}\n",
    ")\n",
    "user_counts = reviews[\"user_id\"].value_counts()\n",
    "active_users = user_counts.loc[user_counts >= 5].index.tolist()\n",
    "reviews = reviews.loc[reviews.user_id.isin(active_users)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(df):\n",
    "    df = df.drop(df.columns[0], axis =1)\n",
    "    df['date']  = pd.to_datetime(df['date'])\n",
    "    df['week_day'] = df['date'].dt.weekday\n",
    "    df['month'] = df['date'].dt.month\n",
    "    df['hour'] = df['date'].dt.hour\n",
    "    df = df.merge(users, on = 'user_id')\n",
    "    df = df.merge(businesses, on = 'business_id')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline: SVD as Matrix Factorization\n",
    "\n",
    "As a CF algorithm. A matrix factorization technique that reduces the number of features of a data set by reducing space dimensions from N to K where K < N. Thus, in our context, we are finding 2 matrices whose product is the original matrix. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and Transforming\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tunning sets\n",
    "ratings_holdout_20 = pd.read_csv('data/ratings_sample_holdout_20.csv')\n",
    "ratings_train_20 = pd.read_csv('data/ratings_sample_train_20.csv')\n",
    "ratings_val_20 = pd.read_csv('data/ratings_sample_cv_20.csv')\n",
    "\n",
    "ratings_holdout_50 = pd.read_csv('data/ratings_sample_holdout_50.csv')\n",
    "ratings_val_50 = pd.read_csv('data/ratings_sample_val_50.csv')\n",
    "ratings_train_50 = pd.read_csv('data/ratings_sample_train_50.csv')\n",
    "\n",
    "ratings_holdout = pd.read_csv('data/ratings_sample_holdout.csv')\n",
    "ratings_train = pd.read_csv('data/ratings_sample_train.csv')\n",
    "ratings_val = pd.read_csv('data/ratings_sample_cv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_train_20 = process(ratings_train_20.copy())\n",
    "ratings_holdout_20 = process(ratings_holdout_20.copy())\n",
    "ratings_val_20 = process(ratings_val_20.copy())\n",
    "\n",
    "ratings_train_50 = process(ratings_train_50.copy())\n",
    "ratings_holdout_50 = process(ratings_holdout_50.copy())\n",
    "ratings_val_50 = process(ratings_val_50.copy())\n",
    "\n",
    "ratings_val = process(ratings_val.copy())\n",
    "ratings_train = process(ratings_train.copy())\n",
    "ratings_holdout = process(ratings_holdout.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_test_20 = ratings_holdout_20.loc[ratings_holdout_20.business_id.isin(ratings_train_20.business_id)]\n",
    "ratings_val_20 = ratings_val_20.loc[ratings_val_20.business_id.isin(ratings_train_20.business_id)]\n",
    "\n",
    "ratings_test_50 = ratings_holdout_50.loc[ratings_holdout_50.business_id.isin(ratings_train_50.business_id)]\n",
    "ratings_val_50 = ratings_val_50.loc[ratings_val_50.business_id.isin(ratings_train_50.business_id)]\n",
    "\n",
    "ratings_test = ratings_holdout.loc[ratings_holdout.business_id.isin(ratings_train.business_id)]\n",
    "ratings_val = ratings_val.loc[ratings_val.business_id.isin(ratings_train.business_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset_20 = ratings_train_20.iloc[:,0:3]\n",
    "trainset_20.columns = ['userID', 'itemID','rating']\n",
    "valset_20 = ratings_val_20.iloc[:, 0:3]\n",
    "valset_20.columns = ['userID', 'itemID','rating']\n",
    "testset_20 = ratings_holdout_20.iloc[:, 0:3]\n",
    "testset_20.columns = ['userID', 'itemID','rating']\n",
    "\n",
    "trainset_50 = ratings_train_50.iloc[:,0:3]\n",
    "trainset_50.columns = ['userID', 'itemID','rating']\n",
    "valset_50 = ratings_val_50.iloc[:, 0:3]\n",
    "valset_50.columns = ['userID', 'itemID','rating']\n",
    "testset_50 = ratings_holdout_50.iloc[:, 0:3]\n",
    "testset_50.columns = ['userID', 'itemID','rating']\n",
    "\n",
    "trainset = ratings_train.iloc[:,0:3]\n",
    "trainset.columns = ['userID', 'itemID','rating']\n",
    "valset = ratings_val.iloc[:, 0:3]\n",
    "valset.columns = ['userID', 'itemID','rating']\n",
    "testset = ratings_holdout.iloc[:, 0:3]\n",
    "testset.columns = ['userID', 'itemID','rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform to work with surprise, 20%, 50% and full dataset\n",
    "reader = Reader(rating_scale = (0.0, 5.0))\n",
    "train_data_20 = Dataset.load_from_df(trainset_20[['userID','itemID','rating']], reader)\n",
    "val_data_20 = Dataset.load_from_df(valset_20[['userID','itemID','rating']], reader)\n",
    "test_data_20 = Dataset.load_from_df(testset_20[['userID','itemID','rating']], reader)\n",
    "\n",
    "train_data_50 = Dataset.load_from_df(trainset_50[['userID','itemID','rating']], reader)\n",
    "val_data_50 = Dataset.load_from_df(valset_50[['userID','itemID','rating']], reader)\n",
    "test_data_50 = Dataset.load_from_df(testset_50[['userID','itemID','rating']], reader)\n",
    "\n",
    "train_data = Dataset.load_from_df(trainset[['userID','itemID','rating']], reader)\n",
    "val_data = Dataset.load_from_df(valset[['userID','itemID','rating']], reader)\n",
    "test_data = Dataset.load_from_df(testset[['userID','itemID','rating']], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sr_20 = train_data_20.build_full_trainset()\n",
    "val_sr_before_20 = val_data_20.build_full_trainset()\n",
    "val_sr_20 = val_sr_before_20.build_testset()\n",
    "test_sr_before_20 = test_data_20.build_full_trainset()\n",
    "test_sr_20 = test_sr_before_20.build_testset()\n",
    "\n",
    "train_sr_50 = train_data_50.build_full_trainset()\n",
    "val_sr_before_50 = val_data_20.build_full_trainset()\n",
    "val_sr_50 = val_sr_before_20.build_testset()\n",
    "test_sr_before_50 = test_data_50.build_full_trainset()\n",
    "test_sr_50 = test_sr_before_50.build_testset()\n",
    "\n",
    "train_sr = train_data.build_full_trainset()\n",
    "val_sr_before = val_data.build_full_trainset()\n",
    "val_sr = val_sr_before.build_testset()\n",
    "test_sr_before = test_data.build_full_trainset()\n",
    "test_sr = test_sr_before.build_testset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE_tune = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = [5, 7, 10]  # the number of iteration of the SGD procedure\n",
    "lr_all = [0.002, 0.003, 0.005] # the learning rate for all parameters\n",
    "reg_all =  [0.4, 0.5, 0.6] # the regularization term for all parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.4159\n",
      "RMSE: 1.4173\n",
      "RMSE: 1.4174\n",
      "RMSE: 1.4012\n",
      "RMSE: 1.4016\n",
      "RMSE: 1.4032\n",
      "RMSE: 1.3798\n",
      "RMSE: 1.3807\n",
      "RMSE: 1.3821\n",
      "RMSE: 1.4042\n",
      "RMSE: 1.4047\n",
      "RMSE: 1.4058\n",
      "RMSE: 1.3873\n",
      "RMSE: 1.3885\n",
      "RMSE: 1.3900\n",
      "RMSE: 1.3650\n",
      "RMSE: 1.3665\n",
      "RMSE: 1.3672\n",
      "RMSE: 1.3895\n",
      "RMSE: 1.3903\n",
      "RMSE: 1.3918\n",
      "RMSE: 1.3714\n",
      "RMSE: 1.3735\n",
      "RMSE: 1.3747\n",
      "RMSE: 1.3497\n",
      "RMSE: 1.3508\n",
      "RMSE: 1.3527\n"
     ]
    }
   ],
   "source": [
    "for n in n_epochs:\n",
    "    for l in lr_all:\n",
    "        for r in reg_all:\n",
    "            algo = SVD(n_epochs = n, lr_all = l, reg_all = r)\n",
    "            algo.fit(train_sr_20)\n",
    "            predictions = algo.test(val_sr_20)\n",
    "            RMSE_tune[n,l,r] = accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(5, 0.002, 0.4): 1.415933676012248,\n",
       " (5, 0.002, 0.5): 1.4173365973852405,\n",
       " (5, 0.002, 0.6): 1.417370198820145,\n",
       " (5, 0.003, 0.4): 1.4011758726577428,\n",
       " (5, 0.003, 0.5): 1.4016120313912452,\n",
       " (5, 0.003, 0.6): 1.4031618552800484,\n",
       " (5, 0.005, 0.4): 1.3798484285012471,\n",
       " (5, 0.005, 0.5): 1.3806636393067282,\n",
       " (5, 0.005, 0.6): 1.3821350022120953,\n",
       " (7, 0.002, 0.4): 1.4042009585091328,\n",
       " (7, 0.002, 0.5): 1.4047180140602467,\n",
       " (7, 0.002, 0.6): 1.405780300835095,\n",
       " (7, 0.003, 0.4): 1.3872838266494933,\n",
       " (7, 0.003, 0.5): 1.3885483890855905,\n",
       " (7, 0.003, 0.6): 1.3900448377490269,\n",
       " (7, 0.005, 0.4): 1.3649676001324043,\n",
       " (7, 0.005, 0.5): 1.3665228974538999,\n",
       " (7, 0.005, 0.6): 1.3671758260897764,\n",
       " (10, 0.002, 0.4): 1.3894940834924787,\n",
       " (10, 0.002, 0.5): 1.3903377177304177,\n",
       " (10, 0.002, 0.6): 1.3917867965697626,\n",
       " (10, 0.003, 0.4): 1.3714281812046991,\n",
       " (10, 0.003, 0.5): 1.3734950396997587,\n",
       " (10, 0.003, 0.6): 1.3746840315086657,\n",
       " (10, 0.005, 0.4): 1.3497144262970868,\n",
       " (10, 0.005, 0.5): 1.3507892432826967,\n",
       " (10, 0.005, 0.6): 1.3527005637847467}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RMSE_tune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%% time\n",
    "# so the best is when n_epochs = 10, lr_all = 0.005, reg_all = 0.5,\n",
    "# and the RMSE score is 1.3497\n",
    "# train and test on the optimal parameter\n",
    "start_time = time.time()\n",
    "algo_real = SVD(n_epochs = 10, lr_all = 0.005, reg_all = 0.5)\n",
    "algo.fit(train_sr_20)\n",
    "predictions = algo.test(test_sr_20)\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%% time\n",
    "# so the best is when n_epochs = 10, lr_all = 0.005, reg_all = 0.5,\n",
    "# and the RMSE score is 1.3497\n",
    "# train and test on the optimal parameter\n",
    "start_time = time.time()\n",
    "algo_real = SVD(n_epochs = 10, lr_all = 0.005, reg_all = 0.5)\n",
    "algo.fit(train_sr_50)\n",
    "predictions = algo.test(test_sr_50)\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.4168\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.4167680096618858"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%% time\n",
    "# so the best is when n_epochs = 10, lr_all = 0.005, reg_all = 0.5,\n",
    "# and the RMSE score is 1.3497\n",
    "# train and test on the optimal parameter\n",
    "start_time = time.time()\n",
    "algo_real = SVD(n_epochs = 10, lr_all = 0.005, reg_all = 0.5)\n",
    "algo.fit(train_sr)\n",
    "predictions = algo.test(test_sr)\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
